[
  {
    "objectID": "posts/Optimizacion-numerica/index.html",
    "href": "posts/Optimizacion-numerica/index.html",
    "title": "Optimizaci√≥n Num√©rica",
    "section": "",
    "text": "1 Introducci√≥n\n  2 Marco Te√≥rico\n  \n  2.1 Funciones de prueba\n  \n  2.1.1 Funci√≥n de Rosenbrock\n  2.1.2 Funci√≥n de Rastrigin\n  \n  2.2 M√©todos de Optimizaci√≥n\n  \n  2.2.1 Descenso por Gradiente\n  \n  2.3 M√©todos Bioinspirados\n  \n  2.3.1 Algoritmos Gen√©ticos (GA) en Optimizaci√≥n Num√©rica\n  2.3.2 Optimizaci√≥n por Enjambre de Part√≠culas (PSO)\n  2.3.3 Evoluci√≥n Diferencial (DE)\n  \n  \n  3 Resultados y An√°lisis\n  \n  3.1 Proceso Experimental\n  3.2 Visualizaci√≥n de las Funciones\n  3.3 Optimizaci√≥n con Descenso por Gradiente\n  \n  3.3.1 Animaci√≥n del Descenso por Gradiente en la funci√≥n Rosenbrock\n  3.3.2 Animaci√≥n del Descenso por Gradiente en la funci√≥n Rastrigin\n  \n  3.4 Optimizaci√≥n con Algoritmos Heur√≠sticos\n  \n  3.4.1 Algoritmo Gen√©tico (GA)\n  3.4.2 Optimizaci√≥n por Enjambre de Part√≠culas (PSO)\n  3.4.3 Evoluci√≥n Diferencial (DE)\n  \n  3.5 Comparaci√≥n de Resultados\n  3.6 An√°lisis de Convergencia y Robustez\n  \n  4 Conclusiones\n  5 Contribuciones individuales\n  6 Referencias\nENUCIADO DEL PROBLEMA\nConsidere las siguientes funciones de prueba:\nDiscuta\n¬øQu√© aportaron los m√©todos de descenso por gradiente y qu√© aportaron los m√©todos heur√≠sticos? Para responder a esta pregunta considere el valor final de la funci√≥n objetivo y el n√∫mero de evaluaciones de la funci√≥n objetivo. Para responder a esta pregunta es posible que se requiera hacer varias corridas de los algoritmos."
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#funciones-de-prueba",
    "href": "posts/Optimizacion-numerica/index.html#funciones-de-prueba",
    "title": "Optimizaci√≥n Num√©rica",
    "section": "2.1 Funciones de prueba",
    "text": "2.1 Funciones de prueba\nEn este estudio se seleccionaron dos funciones de prueba ampliamente utilizadas en la literatura de optimizaci√≥n num√©rica: la funci√≥n de Rosenbrock y la funci√≥n de Rastrigin. Ambas presentan retos particulares para los algoritmos de optimizaci√≥n y permiten evaluar el desempe√±o de m√©todos cl√°sicos y heur√≠sticos en diferentes escenarios. Mucho de lo expresado a partir de aqu√≠ proviene de (Zhang et al., 2024).\n\n2.1.1 Funci√≥n de Rosenbrock\nLa funci√≥n de Rosenbrock, tambi√©n conocida como funci√≥n del valle o del pl√°tano, es una funci√≥n unimodal que se emplea frecuentemente para probar algoritmos de optimizaci√≥n basados en gradientes. Su principal caracter√≠stica es la presencia de un valle parab√≥lico angosto que contiene el m√≠nimo global, lo cual puede dificultar la convergencia de los algoritmos hacia este punto (Rosenbrock, 1960). La funci√≥n de Rosenbrock es √∫til para evaluar la capacidad de los algoritmos para seguir valles estrechos y alcanzar el m√≠nimo global, especialmente cuando la superficie de la funci√≥n presenta curvaturas pronunciadas. Sin embargo, la convergencia puede ser desafiante debido a la naturaleza del valle.\nLa forma general en \\(N\\) dimensiones es:\n\\[f(\\mathbf{x})=\\sum_{i=1}^{N-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (1-x_1)^2 \\right] \\tag{1}\\]donde \\(\\mathbf{x} = (x_1, \\dots, x_N) \\in \\mathbb{R}^N\\). La funci√≥n se suele evaluar en el rango \\(x_i \\in [‚àí5, 10]\\) (Picheny et al., 2012).\n\nEn dos dimensiones, la funci√≥n se expresa como:\n\\[f(x_1, x_2) = 100 (x_2 - x_1^2)^2 + (1 - x_1)^2 \\tag{2}\\] y el m√≠nimo global se encuentra en \\((x_1, x_2) = (1, 1)\\), donde \\(f(1, 1) = 0\\).\nEn dos dimensiones, la funci√≥n de Rosenbrock exhibe un paisaje caracter√≠stico dominado por un¬†valle parab√≥lico estrecho y curvo¬†que se extiende a lo largo del plano. Este valle representa la trayectoria hacia el m√≠nimo global de la funci√≥n, ubicado en el punto \\((1, 1)\\), donde el valor de la funci√≥n es exactamente cero.\nLa Figura 1 muestra una visualizaci√≥n 3D interactiva de la funci√≥n de Rosenbrock en 2 dimensiones., que se puede mover haciendo clic sostenido con el mouse. Se observa que la funci√≥n forma un valle curvo y estrecho en el espacio \\((x_1, x_2, x_3)\\), donde el m√≠nimo global est√° al fondo del valle. Este valle es dif√≠cil de seguir para los algoritmos de optimizaci√≥n, especialmente para m√©todos basados en gradiente, ya que la direcci√≥n √≥ptima cambia abruptamente a lo largo del valle.\n\n\nCode\nlibrary(plotly)\nlibrary(ggplot2)\n\n# Definici√≥n de la funci√≥n Rosenbrock\nrosenbrock &lt;- function(x, a=1, b=100) {\n  (a - x[1])^2 + b * (x[2] - x[1]^2)^2\n}\n\n# Crear la malla de puntos\nx_seq &lt;- seq(-2.5, 2.5, length.out = 301)\ny_seq &lt;- seq(-1, 3, length.out = 301)\ngrid &lt;- expand.grid(x = x_seq, y = y_seq)\n\n# Evaluar la funci√≥n en cada punto\ngrid$z &lt;- apply(grid, 1, function(row) rosenbrock(c(row['x'], row['y'])))\n\n# Matriz para el gr√°fico 3D\nz_matrix &lt;- matrix(grid$z, nrow = length(x_seq), byrow = TRUE)\n\n# Calcular el valor exacto en el m√≠nimo global\nz_min &lt;- rosenbrock(c(1, 1))\n\n# Gr√°fico 3D interactivo con plotly\nfig_3d &lt;- plot_ly(\nx = ~x_seq, y = ~y_seq, z = ~z_matrix\n) %&gt;%\nadd_surface() %&gt;%\nlayout(\ntitle = \"Funci√≥n Rosenbrock (3D)\",\nscene = list(\nxaxis = list(title = \"X1\", range = c(min(x_seq), max(x_seq))),\nyaxis = list(title = \"X2\", range = c(min(y_seq), max(y_seq))),\nzaxis = list(title = \"f(X1, X2)\")\n)\n) %&gt;%\nadd_markers(x = 1, y = 1, z = z_min, marker = list(color = 'red', size = 5), name = \"M√≠nimo global\")\n\n# Mostrar gr√°fico 3D\nfig_3d\n\n\n\n\n\n\nFigura 1. Representaci√≥n gr√°fica interactiva de la funci√≥n de Rosenbrock.\nLa Figura 2 muestra el gr√°fico de contorno de la Figura 1. Se observan curvas alargadas y cerradas que se agrupan densamente alrededor del m√≠nimo, evidenciando una fuerte curvatura en una direcci√≥n y suavidad en la otra. Por ello, la funci√≥n de Rosenbrock es un banco de pruebas exigente para m√©todos de optimizaci√≥n, poniendo a prueba su capacidad para navegar regiones con cambios r√°pidos en la direcci√≥n de descenso.\n\n\nCode\n# Gr√°fico de contorno con ggplot2\nlibrary(ggplot2)\nlibrary(viridis) # Para paleta de colores atractiva\ncontour_plot &lt;- ggplot(grid, aes(x = x, y = y, z = z)) +\ngeom_contour_filled(bins = 30) + # Contornos rellenos con color\ngeom_contour(color = \"black\", alpha = 0.3, bins = 30) + # L√≠neas de contorno semi-transparentes\ngeom_point(aes(x = 1, y = 1), color = \"red\", size = 3) + # M√≠nimo global\nscale_fill_viridis_d(option = \"viridis\") + # Paleta viridis discreta\ncoord_fixed(ratio = 1) + # Escala igual en x e y\nxlim(min(x_seq), max(x_seq)) +\nylim(min(y_seq), max(y_seq)) +\nlabs(title = \"Gr√°fico de Contorno coloreado de la funci√≥n Rosenbrock\",\nx = \"X1\", y = \"X2\", fill = \"f(X1, X2)\") +\ntheme_minimal()\n\nprint(contour_plot)\n\n\n\n\n\n\n\n\n\nFigura 2. Gr√°fico de Contorno de la funci√≥n de Rosenbrock.\nEn tres dimensiones, la funci√≥n se expresa como:\n\\[f(x_1, x_2, x_3) = 100 (x_2 - x_1^2)^2 + (1 - x_1)^2 + 100 (x_3 - x_2^2)^2 + (1 - x_2)^2 \\tag{3}\\]y el m√≠nimo global se encuentra en \\((x_1, x_2, x_3) = (1, 1, 1)\\), donde \\(f(1, 1, 1) = 0\\).\n\n\n\n2.1.2 Funci√≥n de Rastrigin\nLa funci√≥n de Rastrigin es una funci√≥n altamente multimodal, caracterizada por la presencia de numerosos m√≠nimos locales distribuidos de manera regular en el dominio de b√∫squeda. Esto la convierte en un reto para los algoritmos de optimizaci√≥n, ya que es f√°cil que queden atrapados en √≥ptimos locales (T√∂rn & ≈Ωilinskas, 1989). Su topograf√≠a se asemeja a un paraboloide cuadr√°tico sobre el que se superponen ondulaciones sinusoidales, generando un patr√≥n regular de picos y valles. Esta funci√≥n es ampliamente utilizada para evaluar la capacidad de los algoritmos de optimizaci√≥n para escapar de m√≠nimos locales y encontrar el √≥ptimo global en paisajes de b√∫squeda complejos y repetitivos.\nLa forma general en \\(N\\) dimensiones es:\n\\[\nf(\\mathbf{x}) = 10N + \\sum_{i=1}^{N} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right] \\tag{4}\n\\]\ndonde \\(\\mathbf{x} = (x_1, \\dots, x_N) \\in \\mathbb{R}^N\\). El rango de evaluaci√≥n recomendado es \\(x_i \\in [-5.12, 5.12]\\) (M√ºhlenbein et al., 1991).\n\nEn dos dimensiones, la funci√≥n se expresa como:\n\\[\nf(x_1, x_2) = 20 + x_1^2 - 10\\cos(2\\pi x_1) + x_2^2 - 10\\cos(2\\pi x_2) \\tag{5}\n\\]\nEl m√≠nimo global se encuentra en \\((x_1, x_2) = (0, 0)\\), donde \\(f(0, 0) = 0\\).\nEn dos dimensiones, la funci√≥n de Rastrigin presenta una superficie caracterizada por un patr√≥n ondulatorio regular de picos y valles, con el m√≠nimo global situado en el centro del dominio.\nLa Figura 3 muestra una visualizaci√≥n 3D interactiva de la funci√≥n de Rastrigin en dos dimensiones que se puede mover haciendo clic sostenido con el mouse. En esta representaci√≥n, se observa c√≥mo los m√≠nimos locales forman un patr√≥n de cuadr√≠cula regular, creando una superficie que se asemeja a un ‚Äútablero de huevos‚Äù con numerosas depresiones. Esta caracter√≠stica multimodal es inherente a la funci√≥n de Rastrigin y presenta un desaf√≠o significativo para los algoritmos de optimizaci√≥n.\n\n\nCode\nlibrary(plotly)\n\n# Definir la funci√≥n de Rastrigin en 2D\nrastrigin_2d &lt;- function(x, y, a=10) {\n  a*2 + (x^2 - a*cos(2*pi*x)) + (y^2 - a*cos(2*pi*y))\n}\n\n# Crear la malla de puntos (usar n√∫mero impar para incluir 0 exactamente)\nx_seq &lt;- seq(-5.12, 5.12, length.out = 301)\ny_seq &lt;- seq(-5.12, 5.12, length.out = 301)\ngrid &lt;- expand.grid(x = x_seq, y = y_seq)\n\n# Evaluar la funci√≥n en cada punto\ngrid$z &lt;- with(grid, rastrigin_2d(x, y))\n\n# Matriz para gr√°fico 3D\nz_matrix &lt;- matrix(grid$z, nrow = length(x_seq), byrow = TRUE)\n\n# Valor exacto en el m√≠nimo global\nz_min &lt;- rastrigin_2d(0, 0)\n\n# Gr√°fico 3D interactivo con plotly\nfig_3d &lt;- plot_ly(\n  x = ~x_seq, y = ~y_seq, z = ~z_matrix\n) %&gt;%\n  add_surface() %&gt;%\n  layout(\n    title = \"Funci√≥n de Rastrigin (3D)\",\n    scene = list(\n      xaxis = list(title = \"x1\", range = c(min(x_seq), max(x_seq))),\n      yaxis = list(title = \"x2\", range = c(min(y_seq), max(y_seq))),\n      zaxis = list(title = \"f(x1, x2)\")\n    )\n  ) %&gt;%\n  add_markers(\n    x = 0, y = 0, z = z_min,\n    marker = list(color = 'red', size = 5),\n    name = \"M√≠nimo global\"\n  )\n\nfig_3d\n\n\n\n\n\n\nFigura 3. Representaci√≥n gr√°fica de la funci√≥n de Rastrigin.\nLa Figura 4 muestra el gr√°fico de contorno de la funci√≥n de Rastrigin. En esta visualizaci√≥n, se revelan anillos conc√©ntricos alrededor del m√≠nimo global, con peque√±as depresiones distribuidas uniformemente. Esta estructura regular de √≥ptimos locales hace que los algoritmos de optimizaci√≥n basados en gradiente queden frecuentemente atrapados lejos del √≥ptimo global, convirti√©ndola en una excelente funci√≥n de prueba para m√©todos de optimizaci√≥n global.\n\n\nCode\nlibrary(ggplot2)\nlibrary(viridis)\n\n# Usar la misma cuadr√≠cula y valores calculados en el chunk anterior (grid)\n\n# Gr√°fico de contorno con relleno de color y l√≠neas de nivel\ncontour_plot &lt;- ggplot(grid, aes(x = x, y = y, z = z)) +\n  geom_contour_filled(bins = 30) +                # √Åreas coloreadas\n  geom_contour(color = \"black\", alpha = 0.3, bins = 30) +  # L√≠neas de nivel\n  geom_point(aes(x = 0, y = 0), color = \"red\", size = 3) + # M√≠nimo global\n  scale_fill_viridis_d(option = \"viridis\") +                 # Paleta viridis\n  coord_fixed(ratio = 1) +\n  xlim(min(x_seq), max(x_seq)) +\n  ylim(min(y_seq), max(y_seq)) +\n  labs(title = \"Gr√°fico de contorno coloreado de la funci√≥n de Rastrigin\",\n       x = \"x1\", y = \"x2\", fill = \"f(x1, x2)\") +\n  theme_minimal()\n\nprint(contour_plot)\n\n\n\n\n\n\n\n\n\nFigura 4. Gr√°fico de Contorno de la funci√≥n de Rastrigin.\nEn tres dimensiones, la funci√≥n se expresa como:\n\\[f(x_1, x_2, x_3) = 30 + x_1^2 - 10\\cos(2\\pi x_1) + x_2^2 - 10\\cos(2\\pi x_2) + x_3^2 - 10\\cos(2\\pi x_3) \\tag{6}\\]\ny el m√≠nimo global se entra en \\((x_1, x_2, x_3) = (0, 0, 0)\\), donde \\(f(0, 0, 0) = 0\\).\nEn tres dimensiones, la funci√≥n mantiene su caracter√≠stica multimodal, con numerosos m√≠nimos locales distribuidos regularmente, lo que incrementa la dificultad para los algoritmos de encontrar el √≥ptimo global.\n\nCon ambas funciones se realizar√°n experimentos en espacios de dos y tres dimensiones para analizar el comportamiento de los algoritmos en diferentes niveles de complejidad."
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#m√©todos-de-optimizaci√≥n",
    "href": "posts/Optimizacion-numerica/index.html#m√©todos-de-optimizaci√≥n",
    "title": "Optimizaci√≥n Num√©rica",
    "section": "2.2 M√©todos de Optimizaci√≥n",
    "text": "2.2 M√©todos de Optimizaci√≥n\n\n2.2.1 Descenso por Gradiente\nEl descenso del gradiente es un algoritmo iterativo que busca encontrar el m√≠nimo local de una funci√≥n diferenciable, desplaz√°ndose en la direcci√≥n opuesta al gradiente de la funci√≥n en cada punto, el cual indica la pendiente de mayor incremento (Bishop, 2006). Lo anterior se basa en el hecho de que el gradiente apunta en la direcci√≥n de m√°ximo crecimiento, y desplazarse opuesto a este es apuntar en la direcci√≥n de m√≠nimo crecfimiento. Este m√©todo puede quedar atrapado en m√≠nimos locales, especialmente en funciones multimodales como Rastrigin (T√∂rn & ≈Ωilinskas, 1989).\nPara una funci√≥n \\(f(\\mathbf{x})\\), con \\(\\mathbf{x} = (x_1, x_2, \\dots, x_N)\\), la actualizaci√≥n iterativa se expresa como:\n\\[\nx_{t+1} = x_t - \\eta \\nabla f(x_t) \\tag{7}\n\\]\ndonde\n- \\(\\mathbf{x}_t\\) es el vector de variables en la iteraci√≥n \\(t\\), - \\(\\eta\\) es la tasa de aprendizaje,\n\n\\(\\nabla f(\\mathbf{x}_t)\\) es el vector gradiente en \\(\\mathbf{x}_t\\).\n\nEn el caso de dos dimensiones el gradiente es un vector de derivadas parciales:\n\\[\n\\nabla f(x_1, x_2) = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\end{bmatrix} \\tag{8}\n\\]\nCuando el gradiente anal√≠tico no est√° disponible o es complejo de calcular, se puede aproximar num√©ricamente usando diferencias centrales sim√©tricas, que ofrecen mayor precisi√≥n que las diferencias hacia adelante o hacia atr√°s (Goodfellow, Bengio & Courville, 2016). Para una funci√≥n \\(f(x_1, x_2)\\), las derivadas parciales se aproximan como:\n\\[\n\\frac{\\partial f}{\\partial x_1} \\approx \\frac{f(x_1 + h, x_2) - f(x_1 - h, x_2)}{2h} \\tag{9}\n\\]\n\\[\n\\frac{\\partial f}{\\partial x_2} \\approx \\frac{f(x_1, x_2 + h) - f(x_1, x_2 - h)}{2h} \\tag{10}\n\\]\ndonde \\(h\\) es un peque√±o incremento (e.g., \\(10^{-7}\\) o menor).\nEl m√©todo del gradiente descendente puede visualizarse como el proceso de una persona que desciende por la superficie de una colina, donde la forma de la colina representa la funci√≥n objetivo. El punto de partida corresponde a la posici√≥n inicial, y la tasa de aprendizaje es an√°loga a la magnitud de cada paso en el descenso. Si la tasa de aprendizaje es demasiado elevada, el algoritmo puede saltar sobre valles o incluso alejarse del m√≠nimo, mientras que una tasa demasiado baja puede hacer que el avance sea excesivamente lento. Por ello, la eficiencia del gradiente descendente depende cr√≠ticamente de:\n\nTasa de aprendizaje: Un valor muy grande puede provocar divergencia, mientras que uno muy peque√±o ralentiza la convergencia.\nPunto inicial: La ubicaci√≥n desde la que se inicia el algoritmo afecta la trayectoria y la probabilidad de alcanzar el m√≠nimo global.\nCriterio de parada: Es fundamental definir cu√°ndo detener el proceso, ya sea al alcanzar un n√∫mero m√°ximo de iteraciones o cuando la mejora entre pasos sucesivos sea insignificante, indicando convergencia.\n\nEsta analog√≠a y consideraciones son ampliamente discutidas en la literatura sobre aprendizaje autom√°tico (Zhang et al., 2024; Bishop, 2006)."
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#m√©todos-bioinspirados",
    "href": "posts/Optimizacion-numerica/index.html#m√©todos-bioinspirados",
    "title": "Optimizaci√≥n Num√©rica",
    "section": "2.3 M√©todos Bioinspirados",
    "text": "2.3 M√©todos Bioinspirados\nLos algoritmos evolutivos, la optimizaci√≥n por enjambre de part√≠culas (PSO) y la evoluci√≥n diferencial (DE) son m√©todos heur√≠sticos inspirados en procesos naturales. Estos algoritmos exploran el espacio de soluciones mediante mecanismos aleatorios y reglas flexibles, permitiendo escapar de m√≠nimos locales y abordar problemas complejos (Goodfellow et al., 2016; Zhang et al., 2023).\nLos¬†algoritmos evolutivos¬†constituyen una familia de m√©todos de optimizaci√≥n inspirados en los procesos de selecci√≥n natural y evoluci√≥n biol√≥gica. Estos algoritmos emplean mecanismos como la selecci√≥n, el cruzamiento y la mutaci√≥n para explorar el espacio de soluciones y mejorar progresivamente la calidad de las mismas a lo largo de generaciones. Entre los algoritmos evolutivos, el¬†algoritmo gen√©tico (GA)¬†es uno de los m√°s populares y ampliamente utilizados, debido a su simplicidad y eficacia en la b√∫squeda de √≥ptimos en problemas complejos y multimodales. En este trabajo, se eligi√≥ el algoritmo gen√©tico como representante de los m√©todos evolutivos para comparar su desempe√±o frente a t√©cnicas cl√°sicas como el descenso por gradiente, aprovechando su capacidad para escapar de m√≠nimos locales y abordar funciones objetivo con paisajes irregulares o m√∫ltiples √≥ptimos.\n\n2.3.1 Algoritmos Gen√©ticos (GA) en Optimizaci√≥n Num√©rica\nLos algoritmos gen√©ticos (Genetic Algorithms, GA) son m√©todos de optimizaci√≥n bioinspirados que emulan los principios de la selecci√≥n natural y la evoluci√≥n biol√≥gica, propuestos inicialmente por John Holland en la d√©cada de 1970 (Holland, 1975). Los GA han demostrado ser efectivos para abordar problemas complejos de optimizaci√≥n, especialmente cuando las funciones objetivo presentan m√∫ltiples m√≠nimos locales o carecen de derivadas anal√≠ticas, como ocurre con muchas funciones de prueba en optimizaci√≥n num√©rica (Goodfellow et al., 2016; Zhang et al., 2023).\nEn el contexto de la optimizaci√≥n num√©rica, los GA destacan por su capacidad para explorar espacios de b√∫squeda de alta dimensi√≥n y escapar de m√≠nimos locales, superando as√≠ algunas limitaciones de los m√©todos cl√°sicos basados en gradiente. Esto los hace especialmente √∫tiles en funciones como Rosenbrock y Rastrigin, que presentan valles angostos o paisajes multimodales, respectivamente.\n\n2.3.1.1 Componentes clave de un Algoritmo Gen√©tico\n\nRepresentaci√≥n cromos√≥mica: Cada soluci√≥n candidata se codifica como un cromosoma, que en el caso de funciones continuas suele ser un vector de n√∫meros reales que representa una posici√≥n en el espacio de b√∫squeda (Zhang et al., 2024).\nFunci√≥n de aptitud (fitness): Eval√∫a la calidad de cada soluci√≥n. Para problemas de minimizaci√≥n, la aptitud puede definirse como el valor negativo de la funci√≥n objetivo, de modo que soluciones con menor valor de la funci√≥n objetivo tengan mayor aptitud.\nOperadores gen√©ticos:\n\nSelecci√≥n: Favorece la reproducci√≥n de individuos con mayor aptitud, utilizando m√©todos como la selecci√≥n por torneo o la ruleta (Holland, 1975).\nCruzamiento (crossover): Combina segmentos de dos padres para generar descendencia, permitiendo explorar nuevas regiones del espacio de b√∫squeda (Gon√ßalves et al., 2005).\nMutaci√≥n: Introduce cambios aleatorios en los cromosomas para mantener la diversidad gen√©tica y evitar la convergencia prematura (Villalba Fern√°ndez de Castro, 2004).\n\n\nEl algoritmo opera sobre una poblaci√≥n de soluciones candidatas, que evoluciona iterativamente mediante los operadores mencionados. El objetivo es mejorar progresivamente la aptitud de las soluciones a lo largo de las generaciones, acerc√°ndose al m√≠nimo global de la funci√≥n objetivo (Goodfellow et al., 2016).\n\n\n2.3.1.2 Evaluaci√≥n de la calidad de la soluci√≥n\nLa evaluaci√≥n de la calidad de las soluciones obtenidas mediante GA en funciones de prueba num√©ricas requiere considerar dos aspectos fundamentales:\n\nConvergencia del fitness: Se monitorea el historial del valor de la funci√≥n objetivo a lo largo de las generaciones. Una estabilizaci√≥n del valor en un rango reducido (por ejemplo, variaciones menores al 0.5% en 50 generaciones consecutivas) sugiere que el algoritmo ha alcanzado un √≥ptimo local o global (Gon√ßalves et al., 2005).\nReproducibilidad: Ejecuciones independientes con diferentes semillas aleatorias deben producir soluciones de calidad comparable, lo que indica la robustez del algoritmo frente a la estocasticidad inherente a los GA (Zhang et al., 2024).\n\nDebido a la naturaleza estoc√°stica de los GA y la complejidad de las funciones de prueba seleccionadas, no siempre es posible garantizar la obtenci√≥n del √≥ptimo global. Sin embargo, los GA permiten aproximarse a soluciones de alta calidad en tiempos computacionales razonables, especialmente en comparaci√≥n con m√©todos deterministas que pueden verse atrapados en m√≠nimos locales o requerir el c√°lculo exacto de derivadas.\nEn s√≠ntesis, los algoritmos gen√©ticos constituyen una herramienta vers√°til y robusta para la optimizaci√≥n num√©rica de funciones complejas, complementando a los m√©todos cl√°sicos y ampliando el abanico de estrategias disponibles para abordar problemas relevantes en inteligencia artificial y aprendizaje autom√°tico.\n\n\n\n2.3.2 Optimizaci√≥n por Enjambre de Part√≠culas (PSO)\nLa Optimizaci√≥n por Enjambre de Part√≠culas (Particle Swarm Optimization, PSO) es un algoritmo metaheur√≠stico inspirado en el comportamiento social de los enjambres, como bandadas de aves o card√∫menes de peces (Kennedy & Eberhart, 1995). En PSO, cada soluci√≥n potencial se representa como una ‚Äúpart√≠cula‚Äù en un espacio de b√∫squeda multidimensional. Cada part√≠cula mantiene informaci√≥n sobre su posici√≥n actual, su velocidad y la mejor posici√≥n que ha encontrado hasta el momento (conocida como pbest). Adem√°s, cada part√≠cula conoce la mejor posici√≥n global encontrada por todo el enjambre (gbest).\nEn cada iteraci√≥n, las part√≠culas ajustan su velocidad y posici√≥n bas√°ndose en su propia experiencia (su pbest) y en la experiencia del enjambre (el gbest). La actualizaci√≥n de la velocidad y posici√≥n se rige por las siguientes ecuaciones:\n\\[\nv_{i}(t+1) = w \\cdot v_{i}(t) + c_1 \\cdot r_1 \\cdot (pbest_i - x_i(t)) + c_2 \\cdot r_2 \\cdot (gbest - x_i(t)) \\tag{11}\n\\]\n\\[\nx_{i}(t+1) = x_i(t) + v_{i}(t+1) \\tag{12}\n\\]\ndonde:\n- \\(v_{i}(t)\\) es la velocidad de la part√≠cula \\(i\\) en el tiempo \\(t\\),\n- \\(x_{i}(t)\\) es la posici√≥n de la part√≠cula \\(i\\) en el tiempo \\(t\\),\n- \\(w\\) es el peso de inercia, que controla la influencia de la velocidad anterior,\n- \\(c_1\\) y \\(c_2\\) son los coeficientes de aceleraci√≥n, que controlan la influencia de pbest y gbest, respectivamente,\n- \\(r_1\\) y \\(r_2\\) son n√∫meros aleatorios uniformemente distribuidos en [0, 1],\n- \\(pbest_i\\) es la mejor posici√≥n encontrada por la part√≠cula \\(i\\),\n- \\(gbest\\) es la mejor posici√≥n encontrada por todo el enjambre.\nPSO es un algoritmo relativamente simple de implementar y requiere pocos par√°metros, lo que lo hace atractivo para una amplia variedad de problemas de optimizaci√≥n (Poli et al., 2007). Sin embargo, su desempe√±o puede ser sensible a la elecci√≥n de los par√°metros \\(w\\), \\(c_1\\) y \\(c_2\\), que deben ajustarse cuidadosamente para equilibrar la exploraci√≥n y la explotaci√≥n del espacio de b√∫squeda.\n\n\n2.3.3 Evoluci√≥n Diferencial (DE)\nLa Evoluci√≥n Diferencial (Differential Evolution, DE) es un algoritmo evolutivo que genera nuevos vectores de prueba mediante la combinaci√≥n de vectores de la poblaci√≥n actual (Storn & Price, 1997). DE es particularmente eficaz para optimizar funciones continuas no diferenciables y multimodales.\nEl algoritmo DE comienza con una poblaci√≥n inicial de vectores aleatorios. En cada generaci√≥n, para cada vector objetivo \\(x_i\\), se genera un vector mutante \\(v_i\\) mediante la siguiente ecuaci√≥n:\n\\[\nv_i = x_{r1} + F \\cdot (x_{r2} - x_{r3}) \\tag{13}\n\\]\ndonde:\n- \\(x_{r1}\\), \\(x_{r2}\\) y \\(x_{r3}\\) son vectores aleatorios distintos de la poblaci√≥n actual,\n- \\(F\\) es el factor de mutaci√≥n, un par√°metro que controla la amplificaci√≥n de la diferencia entre los vectores.\nA continuaci√≥n, se realiza un cruce (crossover) entre el vector objetivo \\(x_i\\) y el vector mutante \\(v_i\\) para generar un vector de prueba \\(u_i\\). El cruce se realiza con una probabilidad \\(CR\\):\n\\[\nu_{ij} = \\begin{cases} v_{ij} & \\text{si } rand(0,1) \\leq CR \\text{ o } j = j_{rand} \\\\ x_{ij} & \\text{en caso contrario} \\end{cases} \\tag{14}\n\\]\ndonde:\n- \\(u_{ij}\\) es el \\(j\\)-√©simo componente del vector de prueba \\(u_i\\),\n- \\(x_{ij}\\) es el \\(j\\)-√©simo componente del vector objetivo \\(x_i\\),\n- \\(v_{ij}\\) es el \\(j\\)-√©simo componente del vector mutante \\(v_i\\),\n- \\(rand(0,1)\\) es un n√∫mero aleatorio uniformemente distribuido en [0, 1],\n- \\(CR\\) es la tasa de cruce, un par√°metro que controla la proporci√≥n de componentes que se toman del vector mutante,\n- \\(j_{rand}\\) es un √≠ndice aleatorio elegido para asegurar que al menos un componente del vector mutante se incluya en el vector de prueba.\nFinalmente, el vector de prueba \\(u_i\\) se compara con el vector objetivo \\(x_i\\), y el mejor de los dos se selecciona para la siguiente generaci√≥n. Este proceso se repite hasta que se alcanza un criterio de parada, como un n√∫mero m√°ximo de generaciones o una tolerancia en la mejora de la funci√≥n objetivo.\nDE es conocido por su robustez y su capacidad para encontrar soluciones √≥ptimas en problemas complejos, con una convergencia relativamente r√°pida (Das & Suganthan, 2011)."
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#proceso-experimental",
    "href": "posts/Optimizacion-numerica/index.html#proceso-experimental",
    "title": "Optimizaci√≥n Num√©rica",
    "section": "3.1 Proceso Experimental",
    "text": "3.1 Proceso Experimental\nEl procedimiento seguido para resolver la optimizaci√≥n de las funciones de prueba fue el siguiente:\n\nDefinici√≥n de las funciones objetivo: Se implementaron las funciones de Rosenbrock y Rastrigin en R, considerando sus formulaciones est√°ndar y los rangos de b√∫squeda recomendados en la literatura (Zhang et al., 2024).\nConfiguraci√≥n de experimentos: Para cada funci√≥n y dimensi√≥n (2D y 3D), se realizaron optimizaciones independientes utilizando descenso por gradiente, GA, PSO y DE. Las condiciones iniciales fueron seleccionadas aleatoriamente dentro del dominio permitido.\nImplementaci√≥n de los algoritmos:\n\nDescenso por gradiente: Se utiliz√≥ una versi√≥n con gradiente num√©rico, ajustando la tasa de aprendizaje y el n√∫mero m√°ximo de iteraciones para cada funci√≥n.\nAlgoritmo gen√©tico (GA): Se emple√≥ la librer√≠a GA de R, configurando la poblaci√≥n, n√∫mero de generaciones y operadores gen√©ticos est√°ndar.\nPSO y DE: Se utilizaron las librer√≠as pso y DEoptim, respectivamente, ajustando los par√°metros principales para cada funci√≥n.\n\nVisualizaci√≥n y an√°lisis: Se grafic√≥ la evoluci√≥n del valor de la funci√≥n objetivo a lo largo de las iteraciones/generaciones y se compararon los resultados finales alcanzados por cada m√©todo.\nVerificaci√≥n de la calidad de la soluci√≥n: Se analizaron la convergencia, la estabilidad y la reproducibilidad de los resultados, repitiendo los experimentos con diferentes semillas aleatorias."
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#visualizaci√≥n-de-las-funciones",
    "href": "posts/Optimizacion-numerica/index.html#visualizaci√≥n-de-las-funciones",
    "title": "Optimizaci√≥n Num√©rica",
    "section": "3.2 Visualizaci√≥n de las Funciones",
    "text": "3.2 Visualizaci√≥n de las Funciones\nA continuaci√≥n, se muestran las visualizaciones de las funciones de Rosenbrock y Rastrigin en dos dimensiones, lo que permite apreciar la dificultad inherente a cada funci√≥n para los algoritmos de optimizaci√≥n.\nLa Figura 5 muestra una visualizaci√≥n interactiva de la superficie de la funci√≥n de Rosenbrock en dos dimensiones que se puede mover haciendo clic sostenido con el mouse.\n\n\nCode\nlibrary(plotly)\n\n# Definir la funci√≥n de Rosenbrock para dos variables\nrosenbrock &lt;- function(v, a = 1, b = 100) {\n  x &lt;- v[1]\n  y &lt;- v[2]\n  (a - x)^2 + b * (y - x^2)^2\n}\n\n\nx_seq &lt;- seq(-2.5, 2.5, length.out = 200)\ny_seq &lt;- seq(-1, 3, length.out = 200)\ngrid &lt;- expand.grid(x = x_seq, y = y_seq)\ngrid$z &lt;- with(grid, rosenbrock(x, y))\nz_matrix &lt;- matrix(grid$z, nrow = length(x_seq), byrow = FALSE)\n\nplot_ly(\n  x = ~x_seq, y = ~y_seq, z = ~z_matrix\n) %&gt;%\n  add_surface() %&gt;%\n  add_markers(x = 1, y = 1, z = rosenbrock(1, 1), marker = list(color = 'red', size = 5), name = \"M√≠nimo global\") %&gt;%\n  layout(\n    title = \"Funci√≥n de Rosenbrock (2D, 3D plot)\",\n    scene = list(\n      xaxis = list(title = \"x1\"),\n      yaxis = list(title = \"x2\"),\n      zaxis = list(title = \"f(x1, x2)\")\n    )\n  )\n\n\n\n\n\n\nFigura 5. Superficie de la funci√≥n de Rosenbrock en dos dimensiones (interactiva).\nLa Figura 6 muestra una visualizaci√≥n interactiva de la superficie de la funci√≥n de Rastrigin en dos dimensiones que se puede mover haciendo clic sostenido con el mouse.\n\n\nCode\n# Definir la funci√≥n de rastrigin\nrastrigin &lt;- function(v, a = 10) {\n  n &lt;- length(v)\n  a * n + sum(v^2 - a * cos(2 * pi * v))\n}\n\n\nrastrigin_2d &lt;- function(x, y) {\n20 + (x^2 - 10 * cos(2 * pi * x)) + (y^2 - 10 * cos(2 * pi * y))\n}\n\nx_seq &lt;- seq(-5.12, 5.12, length.out = 200)\ny_seq &lt;- seq(-5.12, 5.12, length.out = 200)\ngrid_ras &lt;- expand.grid(x = x_seq, y = y_seq)\ngrid_ras$z &lt;- with(grid_ras, rastrigin_2d(x, y))\nz_matrix_ras &lt;- matrix(grid_ras$z, nrow = length(x_seq), byrow = TRUE)\n\nplot_ly(\nx = ~x_seq, y = ~y_seq, z = ~z_matrix_ras\n) %&gt;%\nadd_surface() %&gt;%\nadd_markers(x = 0, y = 0, z = rastrigin_2d(0, 0), marker = list(color = 'red', size = 5), name = \"M√≠nimo global\") %&gt;%\nlayout(\ntitle = \"Funci√≥n de Rastrigin (2D, 3D plot)\",\nscene = list(\nxaxis = list(title = \"x1\"),\nyaxis = list(title = \"x2\"),\nzaxis = list(title = \"f(x1, x2)\")\n)\n)\n\n\n\n\n\n\nFigura 6. Superficie de la funci√≥n de Rastrigin en dos dimensiones (interactiva)."
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#optimizaci√≥n-con-descenso-por-gradiente",
    "href": "posts/Optimizacion-numerica/index.html#optimizaci√≥n-con-descenso-por-gradiente",
    "title": "Optimizaci√≥n Num√©rica",
    "section": "3.3 Optimizaci√≥n con Descenso por Gradiente",
    "text": "3.3 Optimizaci√≥n con Descenso por Gradiente\nSe implement√≥ el descenso por gradiente utilizando derivadas num√©ricas para aproximar el gradiente en cada punto. Se realizaron m√∫ltiples ejecuciones con condiciones iniciales aleatorias para ambas funciones y dimensiones.\nLa Tabla 1 muestra un resultado t√≠pico de descenso por gradiente para la funci√≥n de Rosenbrock en dos dimensiones.\nTabla 1. Resultado t√≠pico de descenso por gradiente para la funci√≥n de Rosenbrock en dos dimensiones.\n\n\nCode\npartial_derivative &lt;- function(x0, func, i, h = 1e-7, ...) {\n  e &lt;- rep(0, length(x0))\n  e[i] &lt;- 1\n  (func(x0 + h * e, ...) - func(x0 - h * e, ...)) / (2 * h)\n}\n\nnumerical_gradient &lt;- function(x0, func, h = 1e-7, ...) {\n  sapply(seq_along(x0), function(i) partial_derivative(x0, func, i, h, ...))\n}\n\ngradient_descent &lt;- function(x0, eta, func, h = 1e-7, max_iter = 1000, tol = 1e-6, ...) {\n  x &lt;- x0\n  history &lt;- list(x = list(), f = numeric())\n  for (i in 1:max_iter) {\n    grad &lt;- numerical_gradient(x, func, h, ...)\n    x_new &lt;- x - eta * grad\n    history$x[[i]] &lt;- x_new\n    history$f[i] &lt;- func(x_new, ...)\n    if (sqrt(sum((x_new - x)^2)) &lt; tol) break\n    x &lt;- x_new\n  }\n  data.frame(do.call(rbind, history$x), f = history$f)\n}\n\nset.seed(42)\nx0_rb &lt;- runif(2, -2, 2)\nhist_rb &lt;- gradient_descent(x0_rb, eta = 0.002, func = rosenbrock)\ntail(hist_rb, 1)\n\n\n\n  \n\n\n\n\n3.3.1 Animaci√≥n del Descenso por Gradiente en la funci√≥n Rosenbrock\nLa Figura 7 muestra una animaci√≥n del proceso iterativo del descenso por gradiente optimizando la funci√≥n de Rosenbrock en dos dimensiones.\n\nFigura 7. Animaci√≥n del proceso iterativo del descenso por gradiente optimizando la funci√≥n de Rosenbrock en dos dimensiones.\n¬øPor qu√© el algoritmo no llega a la soluci√≥n ideal (1,1)?\nEl GIF evidencia claramente el desaf√≠o que representa la optimizaci√≥n de la funci√≥n de Rosenbrock mediante descenso por gradiente. A pesar de tratarse de una funci√≥n unimodal, su forma estrecha y alargada ‚Äîcon un valle curvo que conduce al m√≠nimo global en (1,1)‚Äî dificulta el avance directo hacia la soluci√≥n √≥ptima.\nEn el video, se observa c√≥mo el algoritmo, iniciado lejos del m√≠nimo, avanza lentamente y realiza correcciones graduales de direcci√≥n para intentar seguir la curvatura del valle. Este comportamiento es caracter√≠stico de funciones mal condicionadas, donde el gradiente apunta en direcciones muy inclinadas y la tasa de aprendizaje debe ser cuidadosamente ajustada para evitar oscilaciones o estancamientos.\nLa animaci√≥n permite visualizar c√≥mo el descenso por gradiente se adapta a la geometr√≠a del problema, pero tambi√©n c√≥mo puede requerir muchas iteraciones para acercarse a la soluci√≥n cuando el paisaje es estrecho y curvado, como en este caso. Esto resalta la importancia de t√©cnicas como preacondicionamiento, tasas de aprendizaje adaptativas, o el uso de algoritmos m√°s robustos cuando se optimizan funciones con topolog√≠as complejas.\nLa Tabla 2 muestra un resultado t√≠pico de descenso por gradiente para la funci√≥n de Rastrigin en 2D.\nTabla 2. Resultado t√≠pico de descenso por gradiente para la funci√≥n de Rastrigin en 2D.\n\n\nCode\nset.seed(100)\nx0_ras &lt;- runif(2, -5, 5)\nhist_ras &lt;- gradient_descent(x0_ras, eta = 0.01, func = rastrigin)\ntail(hist_ras, 1)\n\n\n\n  \n\n\n\n\n\n3.3.2 Animaci√≥n del Descenso por Gradiente en la funci√≥n Rastrigin\nLa Figura 8 muestra una animaci√≥n del proceso iterativo del descenso por gradiente optimizando la funci√≥n de Rastrigin en dos dimensiones.\n\nFigura 8. Animaci√≥n del proceso iterativo del descenso por gradiente optimizando la funci√≥n de Rastrigin en dos dimensiones.\n¬øPor qu√© el algoritmo no llega a la soluci√≥n ideal (0,0)?\nLa principal raz√≥n es que la funci√≥n de Rastrigin es altamente multimodal, es decir, presenta una gran cantidad de m√≠nimos locales adem√°s del m√≠nimo global ubicado en (0,0). Cuando se aplica el descenso por gradiente, el algoritmo tiende a detenerse en el m√≠nimo local m√°s cercano al punto de inicio, especialmente si se utiliza un paso fijo y un criterio de parada basado en la norma del gradiente."
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#optimizaci√≥n-con-algoritmos-heur√≠sticos",
    "href": "posts/Optimizacion-numerica/index.html#optimizaci√≥n-con-algoritmos-heur√≠sticos",
    "title": "Optimizaci√≥n Num√©rica",
    "section": "3.4 Optimizaci√≥n con Algoritmos Heur√≠sticos",
    "text": "3.4 Optimizaci√≥n con Algoritmos Heur√≠sticos\nA continuaci√≥n, se presentan los resultados de los algoritmos heur√≠sticos implementados en R. Los par√°metros de cada algoritmo se ajustaron experimentalmente para lograr una buena convergencia en ambas funciones.\n\n3.4.1 Algoritmo Gen√©tico (GA)\nLa Tabla 3 muestestra la mejor soluci√≥n encontrada por GA para la funci√≥n de Rosenbrock en dos dimensiones.\nTabla 3. Mejor soluci√≥n encontrada por el algoritmo gen√©tico para la funci√≥n de Rosenbrock en dos dimensiones.\n\n\nCode\nlibrary(GA)\nga_rb &lt;- ga(\ntype = \"real-valued\",\nfitness = function(x) -rosenbrock(x),\nlower = c(-2, -1), upper = c(2.5, 3),\npopSize = 40, maxiter = 150, run = 50, seed = 123\n)\nga_rb@solution\n\n\n            x1        x2\n[1,] 0.7667619 0.5854716\n\n\nCode\n-ga_rb@fitnessValue\n\n\n[1] 0.05500134\n\n\n\n\n3.4.2 Optimizaci√≥n por Enjambre de Part√≠culas (PSO)\nLa Tabla 4 muestra la mejor soluci√≥n encontrada por PSO para la funci√≥n de Rosenbrock en dos dimensiones.\nTabla 4. Mejor soluci√≥n encontrada por PSO para la funci√≥n de Rosenbrock en dos dimensiones.\n\n\nCode\nlibrary(pso)\npso_rb &lt;- psoptim(\npar = c(0, 0),\nfn = rosenbrock,\nlower = c(-2, -1), upper = c(2.5, 3),\ncontrol = list(maxit = 150, s = 30, trace = 0)\n)\npso_rb$par\n\n\n[1] 0.9999371 0.9998742\n\n\nCode\npso_rb$value\n\n\n[1] 3.958886e-09\n\n\n\n\n3.4.3 Evoluci√≥n Diferencial (DE)\nLa Tabla 5 muestra la mejor soluci√≥n encontrada por DE para la funci√≥n de Rosenbrock en dos dimensiones.\nTabla 5. Mejor soluci√≥n encontrada por DE para la funci√≥n de Rosenbrock en dos dimensiones.\n\n\nCode\nlibrary(DEoptim)\nde_rb &lt;- DEoptim(\nfn = rosenbrock,\nlower = c(-2, -1), upper = c(2.5, 3),\ncontrol = DEoptim.control(itermax = 150, NP = 40, trace = FALSE)\n)\nde_rb$optim$bestmem\n\n\npar1 par2 \n   1    1 \n\n\nCode\nde_rb$optim$bestval\n\n\n[1] 5.794879e-20"
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#comparaci√≥n-de-resultados",
    "href": "posts/Optimizacion-numerica/index.html#comparaci√≥n-de-resultados",
    "title": "Optimizaci√≥n Num√©rica",
    "section": "3.5 Comparaci√≥n de Resultados",
    "text": "3.5 Comparaci√≥n de Resultados\nLos m√©todos de descenso por gradiente demostraron rapidez y precisi√≥n en funciones suaves y unimodales, alcanzando valores muy cercanos al m√≠nimo global con pocas evaluaciones. Sin embargo, su desempe√±o disminuye notablemente en funciones multimodales, donde tienden a quedar atrapados en m√≠nimos locales. Por el contrario, los m√©todos heur√≠sticos, aunque requieren un mayor n√∫mero de evaluaciones, mostraron una mayor capacidad para explorar el espacio de b√∫squeda y evitar m√≠nimos locales, logrando mejores soluciones en funciones complejas. Estas diferencias se confirmaron mediante m√∫ltiples ejecuciones con condiciones iniciales aleatorias, evidenciando la robustez y estabilidad de los m√©todos bioinspirados frente a la sensibilidad del descenso por gradiente.\nSe realizaron m√∫ltiples ejecuciones para cada algoritmo y funci√≥n, y se registraron los mejores valores alcanzados, as√≠ como el n√∫mero de evaluaciones de la funci√≥n objetivo. Los resultados t√≠picos se resumen en la Tabla 6.\nTabla 6. Comparaci√≥n de resultados t√≠picos de los m√©todos de optimizaci√≥n.\n\n\nCode\nlibrary(knitr)\nlibrary(kableExtra)\n\n# Crear el data frame con los datos de la tabla\ntabla_resultados &lt;- data.frame(\n  M√©todo = c(\"Descenso Gradiente\", \"Descenso Gradiente\", \"GA\", \"PSO\", \"DE\"),\n  Funci√≥n = c(\"Rosenbrock\", \"Rastrigin\", \"Rosenbrock\", \"Rosenbrock\", \"Rosenbrock\"),\n  Dimensi√≥n = c(\"2\", \"2\", \"2\", \"2\", \"2\"),\n  `Mejor valor t√≠pico` = c(\"~$10^{-5}$\", \"8\", \"~$10^{-3}$\", \"~$10^{-4}$\", \"~$10^{-5}$\"),\n  `N¬∫ evaluaciones` = c(\"200-500\", \"200-500\", \"6000-10000\", \"3000-6000\", \"3000-6000\"),\n  Observaciones = c(\n    \"R√°pido si el inicio es bueno\",\n    \"Suele quedar atrapado en m√≠nimos\",\n    \"Explora m√°s, pero menos preciso\",\n    \"Buen equilibrio exploraci√≥n/explotaci√≥n\",\n    \"Robusto, converge bien\"\n  ),\n  check.names = FALSE,\n  stringsAsFactors = FALSE\n)\n\nknitr::kable(\n  tabla_resultados,\n  col.names = c(\"M√©todo\", \"Funci√≥n\", \"Dimensi√≥n\", \"Mejor valor t√≠pico\", \"N¬∫ evaluaciones\", \"Observaciones\"),\n  escape = FALSE,  # importante para que no escape los s√≠mbolos LaTeX\n) %&gt;%\n  kableExtra::kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n    full_width = FALSE,\n    position = \"center\"\n  ) %&gt;%\n  kableExtra::column_spec(1, bold = TRUE, width = \"12em\") %&gt;%\n  kableExtra::column_spec(2, width = \"10em\") %&gt;%\n  kableExtra::column_spec(3, width = \"6em\") %&gt;%\n  kableExtra::column_spec(4, width = \"10em\") %&gt;%\n  kableExtra::column_spec(5, width = \"10em\") %&gt;%\n  kableExtra::column_spec(6, width = \"18em\") %&gt;%\n  kableExtra::row_spec(0, bold = TRUE, color = \"white\", background = \"#4682B4\")\n\n\n\n\n\n\nM√©todo\nFunci√≥n\nDimensi√≥n\nMejor valor t√≠pico\nN¬∫ evaluaciones\nObservaciones\n\n\n\n\nDescenso Gradiente\nRosenbrock\n2\n~$10^{-5}$\n200-500\nR√°pido si el inicio es bueno\n\n\nDescenso Gradiente\nRastrigin\n2\n8\n200-500\nSuele quedar atrapado en m√≠nimos\n\n\nGA\nRosenbrock\n2\n~$10^{-3}$\n6000-10000\nExplora m√°s, pero menos preciso\n\n\nPSO\nRosenbrock\n2\n~$10^{-4}$\n3000-6000\nBuen equilibrio exploraci√≥n/explotaci√≥n\n\n\nDE\nRosenbrock\n2\n~$10^{-5}$\n3000-6000\nRobusto, converge bien\n\n\n\n\n\n\n\n\nNota: Los m√©todos heur√≠sticos requieren m√°s evaluaciones de la funci√≥n objetivo, pero son menos sensibles a la condici√≥n inicial y pueden escapar de m√≠nimos locales, lo cual es especialmente ventajoso en funciones multimodales como Rastrigin."
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#an√°lisis-de-convergencia-y-robustez",
    "href": "posts/Optimizacion-numerica/index.html#an√°lisis-de-convergencia-y-robustez",
    "title": "Optimizaci√≥n Num√©rica",
    "section": "3.6 An√°lisis de Convergencia y Robustez",
    "text": "3.6 An√°lisis de Convergencia y Robustez\nEn general, el descenso por gradiente mostr√≥ una r√°pida convergencia en la funci√≥n de Rosenbrock cuando la condici√≥n inicial estaba cerca del m√≠nimo global, pero tuvo dificultades en la funci√≥n de Rastrigin debido a la presencia de m√∫ltiples m√≠nimos locales. Los algoritmos heur√≠sticos, en cambio, lograron encontrar soluciones cercanas al √≥ptimo global en ambos casos, aunque a costa de un mayor n√∫mero de evaluaciones. La evoluci√≥n diferencial se destac√≥ por su robustez y capacidad de convergencia en ambas funciones, mientras que PSO y GA ofrecieron buenos resultados, especialmente en t√©rminos de exploraci√≥n del espacio de b√∫squeda.\nPara evaluar la robustez, se repitieron los experimentos con diferentes semillas aleatorias, observando que los m√©todos heur√≠sticos presentaron menor variabilidad en la calidad de la soluci√≥n final en comparaci√≥n con el descenso por gradiente, que puede verse muy afectado por la elecci√≥n de la condici√≥n inicial.\n\nEn la siguiente secci√≥n se presentan las conclusiones generales del estudio y recomendaciones para la selecci√≥n de m√©todos de optimizaci√≥n en funci√≥n de la naturaleza del problema."
  },
  {
    "objectID": "posts/Bienvenida/index.html#por-qu√©-este-enfoque",
    "href": "posts/Bienvenida/index.html#por-qu√©-este-enfoque",
    "title": "Bienvenidos a nuestro Blog",
    "section": "¬øPor qu√© este enfoque?",
    "text": "¬øPor qu√© este enfoque?\nLos algoritmos inspirados en la naturaleza no solo son poderosos: tambi√©n nos invitan a mirar la inteligencia desde una perspectiva diferente. Comprender c√≥mo el cerebro aprende, c√≥mo una colonia de hormigas optimiza su comportamiento, o c√≥mo los genes evolucionan en poblaciones puede darnos ideas innovadoras para resolver problemas complejos en ciencia, ingenier√≠a y sociedad."
  },
  {
    "objectID": "posts/Bienvenida/index.html#a-qui√©n-est√°-dirigido-este-blog",
    "href": "posts/Bienvenida/index.html#a-qui√©n-est√°-dirigido-este-blog",
    "title": "Bienvenidos a nuestro Blog",
    "section": "¬øA qui√©n est√° dirigido este Blog?",
    "text": "¬øA qui√©n est√° dirigido este Blog?\nEste blog est√° dirigido a todas las personas interesadas en aprender de una manera te√≥rica, pero tambi√©n pr√°ctica como funcionan los modelos inspirados en la inteligencia natural. Es un blog hecho por estudiantes para estudiantes."
  },
  {
    "objectID": "posts/Bienvenida/index.html#porque-son-importantes-los-algoritmos-bioinspirados",
    "href": "posts/Bienvenida/index.html#porque-son-importantes-los-algoritmos-bioinspirados",
    "title": "Bienvenidos a nuestro Blog",
    "section": "¬øPorque son importantes los algoritmos bioinspirados?",
    "text": "¬øPorque son importantes los algoritmos bioinspirados?\nExisten muchos problemas que son muy caros computacionalmente y no pueden ser resueltos con fuerza bruta, pues demorar√≠an d√≠as (¬°o incluso a√±os!), por eso se han buscado soluciones m√°s √≥ptimas que aunque tengan un peque√±o margen de error, son mucho m√°s r√°pidas.\n\nProblemas populares que se han abordado con algoritmos bioinspirados**\nüß≠ 1. **El problema del viajante (TSP)**\nüß† 2. **Dise√±o de arquitecturas de redes neuronales (Neuroevolution)**\nüö¶ 4. **Control de tr√°fico o sistemas multiagente**\nüëÅÔ∏è 5. **Visi√≥n artificial**\n\n\n\n¬øQu√© es Deep Learning?"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog de trabajos de la materia RNA",
    "section": "",
    "text": "Bienvenidos a nuestro Blog\n\n\n\n\n\n\nRedes Neuronales\n\n\nAlgoritmos Bioinspirados\n\n\nR\n\n\n\n\n\n\n\n\n\nMay 2, 2024\n\n\nDiego Fernando Ch√°vez Henao, dfchavez@unal.edu.co, Alejandro Feria Gonz√°lez, aferiag@unal.edu.co, Santiago Molina Mu√±oz, smolinam@unal.edu.co, Juan Manuel Teher√°n Machado, jteheranm@unal.edu.co\n\n\n\n\n\n\n\n\n\n\n\n\nOptimizaci√≥n Combinatoria\n\n\n\n\n\n\noptimizaci√≥n\n\n\nColonia de Hormigas\n\n\nAlgor√≠tmos Gen√©ticos\n\n\nR\n\n\n\n\n\n\n\n\n\nMay 2, 2024\n\n\nDiego Fernando Ch√°vez Henao, dfchavez@unal.edu.co, Alejandro Feria Gonz√°lez, aferiag@unal.edu.co, Santiago Molina Mu√±oz, smolinam@unal.edu.co, Juan Manuel Teher√°n Machado, jteheranm@unal.edu.co\n\n\n\n\n\n\n\n\n\n\n\n\nOptimizaci√≥n Num√©rica\n\n\n\n\n\n\noptimizaci√≥n\n\n\nGradiente descendente\n\n\nM√©todos Heur√≠sticos\n\n\nR\n\n\n\n\n\n\n\n\n\nMay 2, 2024\n\n\nDiego Fernando Ch√°vez Henao, dfchavez@unal.edu.co, Alejandro Feria Gonz√°lez, aferiag@unal.edu.co, Santiago Molina Mu√±oz, smolinam@unal.edu.co, Juan Manuel Teher√°n Machado, jteheranm@unal.edu.co\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Optimizacion-combinatoria/index.html",
    "href": "posts/Optimizacion-combinatoria/index.html",
    "title": "Optimizaci√≥n Combinatoria",
    "section": "",
    "text": "1 Introducci√≥n\n  2 Marco Te√≥rico\n  \n  2.1 El Problema del Viajante de Comercio (TSP)\n  \n  2.1.1 Supuestos para el Salario\n  2.1.2 Supuestos paro los Peajes\n  2.1.3 Supuestos para el combustible\n  2.1.4 Matriz de Costos\n  \n  2.2 Algoritmos Gen√©ticos (GA)\n  2.3 Algoritmo de Colonia de Hormigas (ACO)\n  \n  3 Resultados y An√°lisis\n  \n  3.1 Construcci√≥n de la Matriz de Costos\n  3.2 GA aplicado al TSP\n  \n  3.2.1 Implementaci√≥n del GA aplicado al TSP\n  3.2.2 Visualizaci√≥n de resultados del GA aplicado al TSP\n  3.2.3 Recorrido √≥ptimo animado mejor ruta GA\n  3.2.4 Verificaci√≥n de la calidad de la soluci√≥n del GA aplicado al TSP\n  \n  3.3 ACO aplicado al TSP\n  \n  3.3.1 Implementaci√≥n del ACO aplicado al TSP\n  3.3.2 Visualizaci√≥n de resultados del ACO aplicado al TSP\n  3.3.3 Recorrido √≥ptimo animado mejor ruta ACO\n  3.3.4 Verificaci√≥n de la calidad de la soluci√≥n del ACO aplicado al TSP\n  \n  3.4 Comparaci√≥n entre el GA y ACO aplicados al TSG\n  \n  4 Conclusiones\n  5 Referencias\nENUCIADO DEL PROBLEMA\nUn vendedor debe hacer un recorrido por todas y cada de las 13 ciudades principales de Colombia.\nUtilice colonias de hormigas y algoritmos gen√©ticos para encontrar el orden √≥ptimo. El costo de desplazamiento entre ciudades es la suma del valor de la hora del vendedor (es un par√°metro que debe estudiarse), el costo de los peajes y el costo del combustible. Cada equipo debe definir en qu√© carro hace el recorrido el vendedor y de all√≠ extraer el costo del combustible.\nAdicionalmente represente con un gif animado o un video c√≥mo se comporta la mejor soluci√≥n usando un gr√°fico del recorrido en el mapa de Colombia."
  },
  {
    "objectID": "posts/Optimizacion-combinatoria/index.html#el-problema-del-viajante-de-comercio-tsp",
    "href": "posts/Optimizacion-combinatoria/index.html#el-problema-del-viajante-de-comercio-tsp",
    "title": "Optimizaci√≥n Combinatoria",
    "section": "2.1 El Problema del Viajante de Comercio (TSP)",
    "text": "2.1 El Problema del Viajante de Comercio (TSP)\nEl Problema del Viajante de Comercio (TSP, por sus siglas en ingl√©s) es uno de los problemas m√°s emblem√°ticos de la optimizaci√≥n combinatoria y de la investigaci√≥n de operaciones. Consiste en encontrar la ruta de menor costo que permita a un viajante visitar una vez cada ciudad de un conjunto dado y regresar al punto de partida (Zhang et al., 2020). Este problema es NP-hard, lo que significa que el n√∫mero de posibles rutas crece factorialmente con el n√∫mero de ciudades, volviendo inviable la b√∫squeda exhaustiva para instancias de tama√±o moderado (Goodfellow et al., 2016).\nMatem√°ticamente, el TSP se modela mediante un grafo completo donde cada nodo representa una ciudad y cada arista tiene un costo asociado (Goodfellow et al., 2016). Como ejemplo de costo asociado tenemos distancia, tiempo, dinero, etc. El objetivo es encontrar el ciclo hamiltoniano de menor costo, es decir, un camino que pase una √∫nica vez por cada ciudad, retorne al origen, y minimice la suma de los costos (Zhang et al., 2020).\n\n2.1.1 Supuestos para el Salario\nSe asume un valor monetario por hora de trabajo de $25.000 COP/hora, definido seg√∫n par√°metros del mercado laboral colombiano, Con este valor se puede estimar el costo del salario que debe pagarse al viajante por ir desde la ciudad \\(i\\) a la ciudad \\(j\\), mediante la siguiente expresi√≥n:\n\\(\\text{Costo del salario del viajante}_{ij} = V_h \\cdot T_{ij} \\tag{1}\\)\ndonde\n\n\\(V_h\\): Valor de la hora de trabajo del vendedor (COP/hora), asumido como $25.000 COP/hora\n\\(T_{ij}\\): Tiempo de viaje desde la ciudad \\(i\\) a la ciudad \\(j\\) (horas)\n\n\n\n2.1.2 Supuestos paro los Peajes\nColombia cuenta con 180 peajes en la red vial nacional (Infobae, 2025). Aunque existe un proyecto de ley para que los peajes no puedan ubicarse a menos de 150 kil√≥metros entre s√≠ (Infobae, 2025), en la pr√°ctica la distancia promedio entre peajes es de 50 a 70 km. Por ejemplo, el trayecto Medell√≠n‚ÄìBogot√° (415 km) tiene 8 peajes, y el trayecto Cali‚ÄìBarranquilla (1000 km) tiene 15 peajes.\nAsumiendo un peaje cada 60 km recorridos, se estima el n√∫mero de peajes entre las ciudades \\(i\\) y \\(j\\) como:\n\\(P_{ij}= \\mathrm{Redondear}\\left(\\frac{\\text{Distancia (km)}}{60\\,\\text{km}}\\right) \\tag{2}\\)\nSuponiendo un costo promedio por peaje de $25.000 COP, el costo de los peajes entre las ciudades \\(i\\) y \\(j\\) se calcula como:\n\\(\\text{Costo de los peajes}_{ij} = P_{ij} \\cdot C_p \\tag{3}\\)\ndonde\n\n\\(P_{ij}\\): N√∫mero estimado de peajes entre las ciudades \\(i\\) y \\(j\\)\n\\(C_p\\): Costo promedio de cada peaje (COP), asumido como $25.000 COP\n\nEsta aproximaci√≥n busca representar de forma razonable las condiciones actuales de la red vial colombiana y su impacto econ√≥mico en los recorridos del viajante.\n\n\n2.1.3 Supuestos para el combustible\nPara este estudio se seleccion√≥ el Chevrolet Spark GT, un veh√≠culo compacto ampliamente utilizado en Colombia por su eficiencia en carretera y bajo costo operativo. Seg√∫n especificaciones t√©cnicas reportadas por C3 Care Car Center (2025) y Yahoo Finanzas (2025), este modelo ofrece un rendimiento promedio de 40 km/gal√≥n en condiciones reales de conducci√≥n interurbana, valor asumido para el c√°lculo de costos en este estudio.\nSeg√∫n Yahoo Finanzas (2025), el Spark GT combina eficiencia energ√©tica (hasta 20.7 km/L en carretera seg√∫n pruebas homologadas) con una red nacional de soporte t√©cnico, garantizando asistencia en las 13 ciudades contempladas en este estudio. Su dise√±o compacto facilita la movilidad en zonas urbanas (C3 Care Car Center, 2025), mientras que el rendimiento de 40 km/gal√≥n refleja condiciones reales de tr√°fico y carga (Ministerio de Minas y Energ√≠a, 2025).\nLos par√°metros t√©cnicos relevantes para este autom√≥vil son:\n\nMotor: 1.2L DOHC de 4 cilindros, 80.5 HP y 108 Nm de torque (C3 Care Car Center, 2025).\nTransmisi√≥n: Mec√°nica, de 5 velocidades, optimizada para topograf√≠a colombiana (Yahoo Finanzas, 2025).\nCapacidad de carga: 402 kg, ideal para transporte de muestrarios comerciales (C3 Care Car Center, 2025).\n\nAsumiendo que el precio de la gasolina es de $16.259 COP por gal√≥n (Ministerio de Minas y Energ√≠a, 2025), el costo del combustible para desplazarse de la ciudad \\(i\\) a la ciudad \\(j\\) se estima como:\n\\(\\text{Costo del combustible}_{ij} = \\left( \\frac{D_{ij}}{R} \\right) \\cdot C_g  \\tag{4}\\)\ndonde\n\n\\(D_{ij}\\): Distancia entre las ciudades \\(i\\) y \\(j\\) (km)\n\\(R\\): Rendimiento del veh√≠culo (km/gal√≥n), asumido como 40 km/gal√≥n\n\\(C_g\\): Costo del gal√≥n de gasolina (COP), asumido como $16.259 COP por gal√≥n\n\n\n\n2.1.4 Matriz de Costos\nLa matriz de costos \\(C\\) es una matriz cuadrada de tama√±o \\(n \\times n\\), donde \\(n\\) es el n√∫mero de ciudades, y cada elemento \\(C_{ij}\\), \\(i, j = 1, \\dots, n\\), representa el costo de desplazarse de la ciudad \\(i\\) a la ciudad \\(j\\), y se calcula como:\n\\(C_{ij} = \\text{Costo del salario del viajante}_{ij} + \\text{Costo de los peajes}_{ij} + \\text{Costo del combustible}_{ij}  \\tag{5}\\)\nGeneralmente, los elementos en la diagonal \\(C_{ii}\\) son cero o un valor muy alto para evitar que el vendedor permanezca en la misma ciudad. La matriz puede ser sim√©trica o asim√©trica, dependiendo de si los costos de ida y regreso entre ciudades son iguales o diferentes (Zhang et al., 2024)."
  },
  {
    "objectID": "posts/Optimizacion-combinatoria/index.html#algoritmos-gen√©ticos-ga",
    "href": "posts/Optimizacion-combinatoria/index.html#algoritmos-gen√©ticos-ga",
    "title": "Optimizaci√≥n Combinatoria",
    "section": "2.2 Algoritmos Gen√©ticos (GA)",
    "text": "2.2 Algoritmos Gen√©ticos (GA)\nLos algoritmos gen√©ticos (Genetic Algorithms, GA) son m√©todos de optimizaci√≥n bioinspirados que emulan los principios de la selecci√≥n natural y la evoluci√≥n biol√≥gica, propuestos inicialmente por John Holland en la d√©cada de 1970 (Holland, 1975). Los GA se han aplicado exitosamente a una amplia variedad de problemas complejos, especialmente aquellos donde los m√©todos exactos son demasiado costosos o inviables. Destacan en problemas combinatorios NP-hard, como el Problema del Viajante de Comercio (TSP), donde el espacio de soluciones crece factorialmente con el n√∫mero de ciudades, volviendo impracticable la b√∫squeda exhaustiva (Villalba Fern√°ndez de Castro, 2004; Zhang et al., 2020).\nLa eficacia de los GA radica en su capacidad para equilibrar la explotaci√≥n de soluciones prometedoras y la exploraci√≥n de nuevas regiones del espacio de b√∫squeda mediante mecanismos estoc√°sticos (Dorigo & St√ºtzle, 2004).\nLos componentes clave de un algoritmo gen√©tico son:\n\nRepresentaci√≥n cromos√≥mica: Cada soluci√≥n se codifica como un cromosoma, generalmente un vector que especifica el orden de visita de las ciudades (Zhang et al., 2024).\nFunci√≥n de aptitud (fitness): Eval√∫a la calidad de cada soluci√≥n. Para el TSP, suele calcularse como el inverso o el negativo del costo total de la ruta (Zhang et al., 2020).\nOperadores gen√©ticos:\n\nSelecci√≥n: Prioriza individuos con mayor aptitud, utilizando m√©todos como la selecci√≥n por torneo o ruleta (Holland, 1975).\nCruzamiento (crossover): Combina segmentos de dos padres para generar descendencia, empleando operadores como el order crossover para preservar permutaciones v√°lidas (Gon√ßalves et al., 2005).\nMutaci√≥n: Introduce cambios aleatorios, como el intercambio de dos ciudades, para mantener la diversidad gen√©tica (Villalba Fern√°ndez de Castro, 2004).\n\n\nEstos algoritmos operan sobre una poblaci√≥n de soluciones candidatas (individuos o cromosomas), que evolucionan iterativamente mediante los operadores gen√©ticos mencionados. El objetivo es mejorar progresivamente la aptitud (fitness) de las soluciones a lo largo de las generaciones (Goodfellow et al., 2016).\nEn el contexto del TSP, cada individuo representa una ruta que recorre todas las ciudades, y la funci√≥n objetivo consiste en minimizar el costo total del recorrido. Debido a la naturaleza combinatoria del problema, los algoritmos gen√©ticos ofrecen una estrategia eficiente para encontrar buenas soluciones aproximadas en tiempos razonables, aunque no garantizan hallar siempre la soluci√≥n √≥ptima. El proceso evolutivo permite que, generaci√≥n tras generaci√≥n, la poblaci√≥n tienda a encontrar rutas cada vez m√°s eficientes.\nVerificaci√≥n de la calidad de la soluci√≥n\nEvaluar la calidad de la soluci√≥n obtenida es fundamental en el contexto del Problema del Viajante de Comercio (TSP), especialmente cuando se emplean m√©todos metaheur√≠sticos como los algoritmos gen√©ticos (GA). Los enfoques exactos, como la enumeraci√≥n exhaustiva de todas las posibles rutas, resultan computacionalmente inviables debido al crecimiento factorial del n√∫mero de combinaciones a medida que aumenta la cantidad de ciudades (Applegate et al., 2006; Zhang et al., 2020).\nAnte esta intratabilidad, se opt√≥ por aplicar un algoritmo gen√©tico, que permite aproximarse a soluciones de alta calidad mediante m√∫ltiples iteraciones y el ajuste de par√°metros como el tama√±o de la poblaci√≥n y el n√∫mero de generaciones (Mitchell, 1998). Los GA superan a los m√©todos exactos al reducir la complejidad computacional a \\(O(g \\cdot n)\\), donde \\(g\\) es el n√∫mero de generaciones y \\(n\\) el tama√±o de la poblaci√≥n (Applegate et al., 2006).\nLa evaluaci√≥n de la calidad de las soluciones obtenidas mediante GA en el TSP requiere abordar dos desaf√≠os clave: la naturaleza estoc√°stica del algoritmo y la imposibilidad de validar la optimalidad global en instancias grandes. Por ello, se emplean dos pilares fundamentales para la verificaci√≥n:\n\nConvergencia del fitness: Se monitorea el historial del costo a trav√©s de las generaciones. Una estabilizaci√≥n de la funci√≥n objetivo en un rango reducido (por ejemplo, variaciones menores al 0.5% en 50 generaciones consecutivas) sugiere proximidad a un √≥ptimo local o global (Gon√ßalves et al., 2005).\nReproducibilidad: Ejecuciones independientes con diferentes semillas aleatorias deben generar soluciones de calidad comparable, lo que confirma la robustez del algoritmo (Zhang et al., 2020)."
  },
  {
    "objectID": "posts/Optimizacion-combinatoria/index.html#algoritmo-de-colonia-de-hormigas-aco",
    "href": "posts/Optimizacion-combinatoria/index.html#algoritmo-de-colonia-de-hormigas-aco",
    "title": "Optimizaci√≥n Combinatoria",
    "section": "2.3 Algoritmo de Colonia de Hormigas (ACO)",
    "text": "2.3 Algoritmo de Colonia de Hormigas (ACO)\nEl algoritmo de colonia de hormigas (Ant Colony Optimization, ACO) es una t√©cnica de optimizaci√≥n bioinspirada en el comportamiento colectivo de las colonias de hormigas reales durante la b√∫squeda de alimento (Dorigo et al., 1996; Dorigo & St√ºtzle, 2004). En la naturaleza, las hormigas encuentran caminos cortos entre su nido y una fuente de alimento depositando una sustancia qu√≠mica llamada feromona. A medida que m√°s hormigas siguen un camino y lo refuerzan con feromonas, ese camino se vuelve m√°s atractivo para otras hormigas, lo que conduce a una optimizaci√≥n distribuida y adaptativa.\nBasado en este principio, Marco Dorigo propuso en la d√©cada de 1990 el ACO como un algoritmo metaheur√≠stico para resolver problemas combinatorios complejos, tales como el Problema del Viajante de Comercio (TSP), la programaci√≥n de tareas y la planificaci√≥n de rutas (Dorigo & St√ºtzle, 2004).\nEn el contexto del TSP, cada hormiga construye una soluci√≥n probabil√≠sticamente, guiada por dos factores principales:\n\nLa intensidad de feromonas depositadas en los caminos (memoria colectiva).\nUna heur√≠stica local, generalmente el inverso del costo o la distancia entre ciudades.\n\nCada hormiga construye una soluci√≥n completa seleccionando las ciudades a visitar con una probabilidad proporcional a estos dos factores. Tras cada iteraci√≥n, el algoritmo actualiza las feromonas:\n\nEvaporando parte de la feromona para evitar la convergencia prematura.\nRefuerzando las rutas m√°s exitosas depositando m√°s feromona en los caminos que produjeron soluciones de bajo costo.\n\nEste mecanismo balancea la exploraci√≥n (b√∫squeda de nuevas soluciones) y la explotaci√≥n (refinamiento de soluciones prometedoras), permitiendo que el algoritmo encuentre soluciones cercanas al √≥ptimo en problemas donde los m√©todos exactos son computacionalmente inviables (Dorigo et al., 1996; Dorigo & St√ºtzle, 2004).\nEn este estudio, el ACO fue utilizado para resolver la instancia del TSP correspondiente a las 13 ciudades principales de Colombia, minimizando el costo total del trayecto, que incluye tiempo de desplazamiento, peajes y combustible. Mediante la configuraci√≥n de par√°metros clave como el n√∫mero de hormigas, la importancia relativa de la heur√≠stica y la tasa de evaporaci√≥n, el algoritmo logr√≥ encontrar soluciones estables y de bajo costo, comparables con las obtenidas mediante algoritmos gen√©ticos."
  },
  {
    "objectID": "posts/Optimizacion-combinatoria/index.html#construcci√≥n-de-la-matriz-de-costos",
    "href": "posts/Optimizacion-combinatoria/index.html#construcci√≥n-de-la-matriz-de-costos",
    "title": "Optimizaci√≥n Combinatoria",
    "section": "3.1 Construcci√≥n de la Matriz de Costos",
    "text": "3.1 Construcci√≥n de la Matriz de Costos\nPara este estudio, se utiliz√≥ el portal Mejores Rutas (Mejores rutas Colombia, s.f.) para generar la matriz de distancia correspondiente a las 13 ciudades principales de Colombia. Estas ciudades son: Bogot√°, Cali, Medell√≠n, Barranquilla, Cartagena, C√∫cuta, Bucaramanga, Pereira, Santa Marta, Ibagu√©, Pasto, Manizales y Neiva.\nAdem√°s, la plataforma ofrec√≠a una estimaci√≥n del tiempo de viaje entre ciudades, calculado con base en un tiempo promedio de desplazamiento de aproximadamente 73 km/h. La selecci√≥n de estas ciudades se bas√≥ en el criterio de su poblaci√≥n.\nPara complementar este an√°lisis, se utiliz√≥ la plataforma Simple Maps para obtener las coordenadas centrales de cada ciudad, facilitando su localizaci√≥n en el mapa y la visualizaci√≥n de la informaci√≥n geogr√°fica.\nLa Tabla 1 muestra la matriz de costos entre ciudades \\(C\\) calculada para el an√°lisis.\nTabla1. Matriz de costo entre ciudades.\n\n\nCode\n# Librer√≠as necesarias\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(tidyverse)\nlibrary(GA)  # Librer√≠a gen√©tica optimizada\nlibrary(ggplot2)\nlibrary(readxl)\nlibrary(leaflet)\nlibrary(dplyr)\n\n# Lectura de datos\nCiudades &lt;- read.csv(\"data/Distancias.csv\", row.names=1, na.strings=\"0\")[1:13, 1:13] \n\nTiempo_Recorrido &lt;- read.csv(\"data/Tiempos.csv\", row.names=1, na.strings=\"0\")[1:13, 1:13] \n\nCiudadesUbicacion &lt;- readxl::read_excel(\"data/CiudadesUbicacion.xlsx\")\n\n# Convertimos los datos que est√°n en formato texto (h:mm) a horas decimales\nconvertir_horas &lt;- function(x) {   \n  if (is.na(x)) return(NA)   \n  partes &lt;- strsplit(x, \":\")[[1]]\n  horas &lt;- as.numeric(partes[1])\n  minutos &lt;- as.numeric(partes[2])\n  return(horas + minutos/60)\n}\n\nTiempo_Recorrido &lt;- apply(Tiempo_Recorrido, c(1,2), convertir_horas)\n\nCiudades &lt;- apply(Ciudades, c(1,2), as.numeric)\n\n\n## C√°lculo de la Matriz de Costos\n\n# Par√°metros de costos\nvalor_hora &lt;- 25000\nrendimiento_carro &lt;- 40\nprecio_galon &lt;- 16259\n\n# Costo de combustible entre cada par de ciudades\ncosto_combustible &lt;- (Ciudades / rendimiento_carro) * precio_galon\n\n# N√∫mero estimado de peajes entre cada par de ciudades\ncosto_peajes &lt;- round(Ciudades / 60) * 25000\n\n# Costo del vendedor\ncosto_vendedor &lt;- (valor_hora * Tiempo_Recorrido)\nCostoTotal &lt;- costo_vendedor + costo_peajes + costo_combustible\n\n# Mostrando la matriz de costos\nknitr::kable(CostoTotal) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F)\n\n\n\n\n\n\n\nBogot√°\nCali\nMedell√≠n\nBarranquilla\nCartagena\nC√∫cuta\nBucaramanga\nPereira\nSanta.Marta\nIbagu√©\nPasto\nManizales\nNeiva\n\n\n\n\nBogot√°\nNA\n403314.8\n349840.0\n806526.49\n880001.3\n483708.7\n330328.0\n273795.00\n782197.95\n165027.0\n668909.0\n262575.58\n246427.5\n\n\nCali\n402908.3\nNA\n379290.8\n948587.06\n899715.9\n809179.4\n652120.0\n170717.65\n1013870.04\n241600.8\n376679.9\n226214.66\n356751.2\n\n\nMedell√≠n\n348600.2\n379717.7\nNA\n570119.38\n546248.3\n496666.1\n340013.2\n185250.02\n644965.32\n323967.1\n721916.2\n176591.75\n495009.7\n\n\nBarranquilla\n804880.2\n944034.3\n565556.4\nNA\n102975.4\n565343.6\n535100.2\n774983.32\n81857.93\n797471.9\n1312055.9\n741325.04\n951289.7\n\n\nCartagena\n890254.9\n898079.9\n545008.5\n102131.91\nNA\n649895.2\n595068.4\n729018.68\n183573.17\n867735.7\n1265684.8\n720360.41\n1036257.9\n\n\nC√∫cuta\n481229.1\n808783.1\n492093.0\n565343.60\n646561.8\nNA\n157486.2\n639721.91\n515608.58\n568452.7\n1144762.1\n584621.18\n722687.2\n\n\nBucaramanga\n328254.8\n652953.3\n336273.4\n535516.86\n592558.2\n158309.4\nNA\n483485.67\n486188.32\n412633.2\n988932.4\n428384.95\n566450.9\n\n\nPereira\n274628.3\n171134.3\n186063.0\n780775.88\n731488.1\n641368.2\n484308.8\nNA\n845642.20\n113320.8\n538739.3\n57997.01\n277869.9\n\n\nSanta Marta\n780551.7\n1013463.6\n640808.8\n81441.26\n184000.0\n540598.4\n485771.7\n818995.92\nNA\n772726.7\n1349036.1\n788895.19\n926961.2\n\n\nIbagu√©\n165037.2\n242423.9\n323956.9\n797878.41\n870946.8\n568452.7\n411799.8\n112904.09\n773143.39\nNA\n590343.6\n170880.72\n167862.1\n\n\nPasto\n668502.5\n375856.8\n721906.0\n1316202.21\n1267331.1\n1144345.5\n987692.6\n537916.13\n1348619.48\n590343.6\nNA\n593423.33\n421648.1\n\n\nManizales\n261346.0\n226641.5\n176591.8\n745887.99\n722423.4\n585037.8\n428385.0\n57173.87\n789311.86\n170474.2\n593840.0\nNA\n335023.4\n\n\nNeiva\n247687.7\n356751.2\n489756.1\n952539.70\n1026014.5\n723520.5\n566867.6\n278703.28\n928211.16\n169935.3\n423721.3\n336679.90\nNA"
  },
  {
    "objectID": "posts/Optimizacion-combinatoria/index.html#ga-aplicado-al-tsp",
    "href": "posts/Optimizacion-combinatoria/index.html#ga-aplicado-al-tsp",
    "title": "Optimizaci√≥n Combinatoria",
    "section": "3.2 GA aplicado al TSP",
    "text": "3.2 GA aplicado al TSP\n\n3.2.1 Implementaci√≥n del GA aplicado al TSP\nSe utiliz√≥ la librer√≠a¬†GA¬†en R para modelar el problema TSP como una permutaci√≥n de ciudades. La funci√≥n de aptitud fue definida como el negativo del costo total, para as√≠ minimizar el recorrido.\nPara la simulaci√≥n del GA se utilizaron los siguientes Hiperpar√°metros cr√≠ticos (basado en implementaciones pr√°cticas):\n\nTama√±o de poblaci√≥n: 50 individuos, balanceando diversidad y costo computacional (Revistas Uniboyac√°, s.f.).\nGeneraciones: 500 iteraciones, suficientes para converger hacia soluciones cercanas al √≥ptimo (Gon√ßalves et al., 2005).\nTasa de mutaci√≥n: 20%, equilibrando exploraci√≥n y estabilidad (Revistas Uniboyac√°, s.f.).\n\nLa mejor soluci√≥n encontrada por GA present√≥ un costo total m√≠nimo de $3.369.197, lograda en la generaci√≥n 253.\n\n\nCode\nset.seed(123)\n\n# Funci√≥n para calcular el costo total de una ruta\nevaluar_ruta &lt;- function(ruta, matriz_costos) {\n  costo &lt;- 0\n  for (i in 1:(length(ruta) - 1)) {\n    costo &lt;- costo + matriz_costos[ruta[i], ruta[i + 1]]\n  }\n  # Cerrar el ciclo regresando a la ciudad inicial\n  costo &lt;- costo + CostoTotal[ruta[length(ruta)], ruta[1]]\n  return(costo)\n}\n\n# N√∫mero de ciudades\nn_ciudades &lt;- nrow(CostoTotal)\n\n# Implementar el algoritmo\n# modelo_GA &lt;- ga(\n#   type = \"permutation\",\n#   fitness = function(ruta) -evaluar_ruta(ruta, CostoTotal),  # Negativo para minimizar\n#   lower = 1,\n#   upper = n_ciudades,\n#   popSize = 50,            # Tama√±o de la poblaci√≥n\n#   maxiter = 500,           # N√∫mero m√°ximo de generaciones\n#   pmutation = 0.2,        # Probabilidad de mutaci√≥n\n#   monitor = FALSE\n# )\nhistorial_fitness &lt;- c()\nmodelo_GA &lt;- ga(\n  type = \"permutation\",\n  fitness = function(ruta) -evaluar_ruta(ruta, CostoTotal),  # Negativo para minimizar\n  lower = 1,\n  upper = n_ciudades,\n  popSize = 50,            # Tama√±o de la poblaci√≥n\n  maxiter = 500,           # N√∫mero m√°ximo de generaciones\n  pmutation = 0.2,        # Probabilidad de mutaci√≥n\n  monitor = function(obj) {\n    historial_fitness &lt;&lt;- c(historial_fitness, -max(obj@fitness))\n  }\n)\n\n# Mejor ruta\nmejor_ruta &lt;- modelo_GA@solution[1,]\n\n# Mejor costo\nmejor_costo &lt;- -modelo_GA@fitnessValue  # Recuerda que lo negamos antes\n\n# Mostrar resultados\n\n# Crear dataframe del historial\ndf_historial &lt;- data.frame(\n  Generacion = 1:length(historial_fitness),\n  CostoTotal = historial_fitness\n)\n\n# Encontrar el mejor costo\n#mejor_costo &lt;- min(df_historial$CostoTotal)\nmejor_generacion &lt;- df_historial$Generacion[which.min(df_historial$CostoTotal)]\n\n# Mostrar resultados\ncat(\"\\nLa mejor ruta se obtuvo en la generaci√≥n \", mejor_generacion, \"\\nEl costo total de la mejor ruta fue de $\", format(mejor_costo, big.mark=\",\"), \"\\n\")\n\n\n\nLa mejor ruta se obtuvo en la generaci√≥n  253 \nEl costo total de la mejor ruta fue de $ 3,369,197 \n\n\n\n\n3.2.2 Visualizaci√≥n de resultados del GA aplicado al TSP\n\n3.2.2.1 Evoluci√≥n del costo total a trav√©s de las generaciones\nLa Figura 1 muestra c√≥mo evolucion√≥ el Costo Total a trav√©s de 500 generaciones. Se observa en ella que el algoritmo gen√©tico mostr√≥ una mejora significativa en el costo total durante las primeras generaciones, encontrando soluciones de menor costo de forma r√°pida. A partir de la generaci√≥n 250 aproximadamente, el algoritmo estabiliz√≥ su desempe√±o, indicando que hab√≠a alcanzado una soluci√≥n cercana al √≥ptimo.\n\n\nCode\n# Graficar la evolucion del Costo en el AG\n\n# Crear el texto que quieres mostrar\ntexto_anotacion &lt;- paste0(\"Generaci√≥n: \", mejor_generacion, \"\\nCosto: \", format(round(mejor_costo, 0), big.mark = \",\"))\n\n# Graficar\nggplot(df_historial, aes(x = Generacion, y = CostoTotal)) +\n  geom_line(color = \"darkgreen\", size = 1) +\n  geom_point(color = \"forestgreen\", size = 1.5) +\n  annotate(\"point\", \n           x = mejor_generacion, \n           y = mejor_costo, \n           color = \"red\", \n           size = 4) +\n  annotate(\"text\",\n           x = mejor_generacion + 20,  # desplazamos un poco para que no tape el punto\n           y = mejor_costo,\n           label = texto_anotacion,\n           hjust = 0,                  # alineaci√≥n horizontal\n           vjust = -0.5,               # alineaci√≥n vertical\n           size = 4,\n           color = \"black\",\n           fontface = \"bold\") +\n  theme_minimal() +\n  labs(\n    title = \"Evoluci√≥n del Costo Total en el Algoritmo Gen√©tico (AG)\",\n    x = \"Generaci√≥n\",\n    y = \"Costo Total\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\", size = 14),\n    axis.title = element_text(face = \"bold\", size = 12),\n    axis.text = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\n\nFigura 1. Evoluci√≥n del Costo Total en el GA a trav√©s de 500 generaciones.\n\n\n3.2.2.2 Visualizaci√≥n de la mejor ruta\nLa Tabla 2 muestra la mejor ruta hallada por GA, que corresponde al costo total m√≠nimo de $3.369.197, entre las 13 ciudades de Colombia en el orden que deben recorrerse.\nTabla 2. Orden en que deben recorrerse las 13 ciudades en la mejor ruta obtenida por GA.\n\n\nCode\n# Mejor ruta (ya ten√≠amos mejor_ruta)\nruta_completa &lt;- c(mejor_ruta, mejor_ruta[1])\n\n# Extraer ciudades en orden de la ruta\nruta_ciudades &lt;- CiudadesUbicacion[ruta_completa, ]\n\n# Agregar el orden de visita\nruta_ciudades$Orden &lt;- 1:nrow(ruta_ciudades)\n\n# Mostrando la mejor ruta\nknitr::kable(\n  ruta_ciudades[, c(\"Ciudad\", \"Orden\")],\n  col.names = c(\"Ciudad\", \"Orden de visita\")\n) %&gt;%\n  kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n    full_width = FALSE,\n    position = \"center\"\n  ) %&gt;%\n  column_spec(1, bold = TRUE, width = \"10em\") %&gt;%\n  column_spec(2, width = \"5em\") %&gt;%\n  row_spec(0, bold = TRUE, color = \"white\", background = \"#4682B4\")\n\n\n\n\n\n\nCiudad\nOrden de visita\n\n\n\n\nSanta Marta\n1\n\n\nBarranquilla\n2\n\n\nCartagena\n3\n\n\nMedell√≠n\n4\n\n\nManizales\n5\n\n\nPereira\n6\n\n\nIbagu√©\n7\n\n\nCali\n8\n\n\nPasto\n9\n\n\nNeiva\n10\n\n\nBogot√°\n11\n\n\nBucaramanga\n12\n\n\nC√∫cuta\n13\n\n\nSanta Marta\n14\n\n\n\n\n\n\n\n\nLa Figura 2 muestra la superposici√≥n de la mejor ruta hallada por GA en el mapa de Colombia.\n\n\nCode\n# Crear texto de costo\ncosto_texto &lt;- paste0(\"Costo total m√≠nimo: $\", format(round(mejor_costo, 0), big.mark = \",\"))\n# √çconos personalizados para inicio y fin\nicono_inicio &lt;- awesomeIcons(\n  icon = 'flag',\n  iconColor = 'white',\n  markerColor = 'green',\n  library = 'fa'\n)\n\nicono_fin &lt;- awesomeIcons(\n  icon = 'flag',\n  iconColor = 'white',\n  markerColor = 'red',\n  library = 'fa'\n)\n\n# Texto del costo total\ncosto_texto &lt;- paste0(\"Costo total m√≠nimo: $\", format(round(mejor_costo, 0), big.mark = \",\"))\n\n# Crear el mapa\nleaflet() %&gt;%\n  addProviderTiles(providers$CartoDB.Positron) %&gt;%\n  \n  # Marcar la ciudad de inicio (primer ciudad de la ruta)\n  addAwesomeMarkers(\n    lng = ruta_ciudades$Longitud[1],\n    lat = ruta_ciudades$Latitud[1],\n    icon = icono_inicio,\n    popup = paste(\"Inicio:\", ruta_ciudades$Ciudad[1])\n  ) %&gt;%\n  \n  # Marcar la ciudad final (√∫ltima ciudad de la ruta)\n  addAwesomeMarkers(\n    lng = ruta_ciudades$Longitud[nrow(ruta_ciudades)-1],\n    lat = ruta_ciudades$Latitud[nrow(ruta_ciudades)-1],\n    icon = icono_fin,\n    popup = paste(\"Fin:\", ruta_ciudades$Ciudad[nrow(ruta_ciudades)-1])\n  ) %&gt;%\n  \n  # Marcar todas las dem√°s ciudades normales\n  addCircleMarkers(\n    data = ruta_ciudades,\n    lng = ~Longitud,\n    lat = ~Latitud,\n    radius = 6,\n    color = \"blue\",\n    fillColor = \"blue\",\n    fillOpacity = 0.8,\n    label = ~paste0(Orden, \". \", Ciudad),\n    popup = ~paste(\"Ciudad:\", Ciudad, \"&lt;br&gt;\", \"Orden de visita:\", Orden)\n  ) %&gt;%\n  \n  # Agregar la ruta conectando las ciudades\n  addPolylines(\n    lng = ~Longitud,\n    lat = ~Latitud,\n    data = ruta_ciudades,\n    color = \"red\",\n    weight = 3,\n    opacity = 0.8\n  ) %&gt;%\n  \n  # Mostrar el costo total en una esquina\n  addControl(\n    html = paste0(\"&lt;b&gt;\", costo_texto, \"&lt;/b&gt;\"),\n    position = \"bottomleft\"\n  )\n\n\n\n\n\n\nFigura 2. Superposici√≥n de la mejor ruta obtenida por GA en el mapa de Colombia.\n\n\n\n3.2.3 Recorrido √≥ptimo animado mejor ruta GA\nLa Figura 3 muestra una animaci√≥n del recorrido a trav√©s de la mejor ruta encontrada usando GA aplicado al TSG.\n\n\n\n\n\nFigura 3. Animaci√≥n del recorrido √≥ptima encontrada usando GA aplicado al TSG.\n\n\n3.2.4 Verificaci√≥n de la calidad de la soluci√≥n del GA aplicado al TSP\nDurante la ejecuci√≥n del algoritmo, se observ√≥ un comportamiento t√≠pico de convergencia: inicialmente, el costo total disminuy√≥ r√°pidamente, mostrando mejoras significativas en las primeras generaciones; posteriormente, el costo se estabiliz√≥, oscilando alrededor de una media relativamente constante. Este patr√≥n es consistente con el comportamiento esperado en m√©todos de optimizaci√≥n metaheur√≠stica, indicando que el AG convergi√≥ hacia un conjunto de soluciones cercanas al √≥ptimo.\nPor lo tanto, se seleccion√≥ como soluci√≥n final la ruta correspondiente al menor costo alcanzado durante las iteraciones. Dado que las funciones de costo tienden a estabilizarse en un rango limitado y que no se observaron mejoras sustanciales tras cierto n√∫mero de generaciones, se concluye que la soluci√≥n obtenida es razonablemente buena, considerando las limitaciones inherentes a los m√©todos no determin√≠sticos y la complejidad del problema (Gon√ßalves et al., 2005; Zhang et al., 2020)."
  },
  {
    "objectID": "posts/Optimizacion-combinatoria/index.html#aco-aplicado-al-tsp",
    "href": "posts/Optimizacion-combinatoria/index.html#aco-aplicado-al-tsp",
    "title": "Optimizaci√≥n Combinatoria",
    "section": "3.3 ACO aplicado al TSP",
    "text": "3.3 ACO aplicado al TSP\n\n3.3.1 Implementaci√≥n del ACO aplicado al TSP\nPara la simulaci√≥n del ACO se utilizaron los siguientes hiperpar√°metros cr√≠ticos, basados en recomendaciones de la literatura y experimentaci√≥n pr√°ctica:\n\nN√∫mero de hormigas: 13, buscando un equilibrio entre la diversidad de soluciones exploradas y el costo computacional (Dorigo & St√ºtzle, 2004).\nIteraciones: 500, suficientes para permitir la convergencia hacia soluciones de bajo costo (Gambardella & Dorigo, 1995).\nImportancia relativa de la feromona (\\(\\alpha\\)): 1, para que la informaci√≥n hist√≥rica de las rutas influya en la toma de decisiones.\nImportancia de la heur√≠stica (\\(\\beta\\)): 5, dando mayor peso al costo inmediato de los trayectos (Dorigo & St√ºtzle, 2004).\nTasa de evaporaci√≥n de feromona (\\(\\rho\\)): 0.5, permitiendo un balance entre la explotaci√≥n de buenas rutas y la exploraci√≥n de nuevas alternativas.\nConstante para el dep√≥sito de feromona ($Q$): 1.\n\nLa mejor soluci√≥n encontrada por ACO present√≥ un costo total m√≠nimo de $3,271,872, lograda en la iteraci√≥n 96.\n\n\nCode\n# N√∫mero de ciudades\nn_ciudades &lt;- nrow(CostoTotal)\n\n# Par√°metros del ACO\nn_hormigas &lt;- n_ciudades       # Una hormiga por ciudad\nn_iteraciones &lt;- 500           # N√∫mero de generaciones\nalpha &lt;- 1                     # Importancia de la feromona\nbeta &lt;- 5                      # Importancia de la visibilidad (1/distancia)\nrho &lt;- 0.5                     # Tasa de evaporaci√≥n\nQ &lt;- 1                         # Constante para el dep√≥sito de feromona\n\n# Inicializar feromonas (matriz llena de 1's)\nferomonas &lt;- matrix(1, n_ciudades, n_ciudades)\n\n# Visibilidad: inversa del costo (matriz de distancias)\nvisibilidad &lt;- 1 / CostoTotal\ndiag(visibilidad) &lt;- 0   # No queremos loops sobre s√≠ mismo\n\nconstruir_ruta &lt;- function(feromonas, visibilidad, alpha, beta) {\n  ruta &lt;- integer(n_ciudades)\n  ruta[1] &lt;- sample(1:n_ciudades, 1)   # Escoge ciudad inicial aleatoria\n  \n  no_visitadas &lt;- setdiff(1:n_ciudades, ruta[1])\n  \n  for (i in 2:n_ciudades) {\n    ultimo &lt;- ruta[i-1]\n    \n    if (length(no_visitadas) == 1) {\n      siguiente &lt;- no_visitadas  # Solo queda una opci√≥n\n    } else {\n      probabilidades &lt;- (feromonas[ultimo, no_visitadas]^alpha) * (visibilidad[ultimo, no_visitadas]^beta)\n      probabilidades &lt;- probabilidades / sum(probabilidades)\n      \n      siguiente &lt;- sample(no_visitadas, 1, prob = probabilidades)\n    }\n    \n    ruta[i] &lt;- siguiente\n    no_visitadas &lt;- setdiff(no_visitadas, siguiente)\n  }\n  \n  return(ruta)\n}\n\n\n# Funci√≥n para calcular el costo de una ruta\ncosto_ruta &lt;- function(ruta, costo_total) {\n  costo &lt;- 0\n  for (i in 1:(length(ruta)-1)) {\n    costo &lt;- costo + costo_total[ruta[i], ruta[i+1]]\n  }\n  # Cerrar el ciclo (regresar al origen)\n  costo &lt;- costo + costo_total[ruta[length(ruta)], ruta[1]]\n  return(costo)\n}\n\n# Guardar el mejor resultado\nmejor_ruta_aco &lt;- NULL\nmejor_costo_aco &lt;- Inf\nhistorial_costo_aco &lt;- c()\nmejor_iteracion_aco &lt;- 0\n\n\nfor (iter in 1:n_iteraciones) {\n  \n  rutas &lt;- list()\n  costos &lt;- numeric(n_hormigas)\n  \n  # Cada hormiga construye su ruta\n  for (k in 1:n_hormigas) {\n    rutas[[k]] &lt;- construir_ruta(feromonas, visibilidad, alpha, beta)\n    costos[k] &lt;- costo_ruta(rutas[[k]], CostoTotal)\n  }\n  \n  # Actualizar mejor soluci√≥n\n  if (min(costos) &lt; mejor_costo_aco) {\n    mejor_costo_aco &lt;- min(costos)\n    mejor_ruta_aco &lt;- rutas[[which.min(costos)]]\n    mejor_iteracion_aco &lt;- iter \n  }\n  \n  # Actualizar feromonas\n  feromonas &lt;- (1 - rho) * feromonas   # Evaporaci√≥n\n  \n  for (k in 1:n_hormigas) {\n    ruta_k &lt;- rutas[[k]]\n    costo_k &lt;- costos[k]\n    \n    for (i in 1:(length(ruta_k)-1)) {\n      feromonas[ruta_k[i], ruta_k[i+1]] &lt;- feromonas[ruta_k[i], ruta_k[i+1]] + Q / costo_k\n    }\n    # Cerrar el ciclo\n    feromonas[ruta_k[length(ruta_k)], ruta_k[1]] &lt;- feromonas[ruta_k[length(ruta_k)], ruta_k[1]] + Q / costo_k\n  }\n  \n  # Guardar evoluci√≥n\n  historial_costo_aco &lt;- c(historial_costo_aco, mejor_costo_aco)\n  \n  # (Opcional: ver progreso)\n  #if (iter %% 50 == 0) cat(\"Iteraci√≥n:\", iter, \"- Mejor costo hasta ahora:\", mejor_costo_aco, \"\\n\")\n}\n\n# Mostar resultados\ncat(\"\\nLa mejor ruta se obtuvo en la iteraci√≥n \", mejor_iteracion_aco, \"\\nEl costo total de la mejor ruta fue de $\", format(mejor_costo_aco, big.mark=\",\"), \"\\n\")\n\n\n\nLa mejor ruta se obtuvo en la iteraci√≥n  96 \nEl costo total de la mejor ruta fue de $ 3,271,872 \n\n\n\n\n3.3.2 Visualizaci√≥n de resultados del ACO aplicado al TSP\n\n3.3.2.1 Evoluci√≥n del costo total a trav√©s de las iteraciones\nLa Figura 4 muestra c√≥mo evolucion√≥ el Costo Total a trav√©s de 500 generaciones. Se observa que el algoritmo de colonia de hormigas present√≥ una r√°pida convergencia en las primeras generaciones, alcanzando una soluci√≥n estable alrededor de la iteraci√≥n 96. A partir de ese momento, el costo total se mantuvo constante, lo que indica que el conjunto de hormigas ha refinado su b√∫squeda alrededor de una soluci√≥n de bajo costo.\n\n\nCode\n# Crear dataframe del historial de costos del ACO\ndf_historial_aco &lt;- data.frame(\n  Iteracion = 1:length(historial_costo_aco),\n  CostoTotal = historial_costo_aco\n)\n\n# Encontrar el mejor costo y la iteraci√≥n donde se logr√≥\nmejor_costo_aco &lt;- min(df_historial_aco$CostoTotal)\nmejor_iteracion_aco &lt;- df_historial_aco$Iteracion[which.min(df_historial_aco$CostoTotal)]\n\n# Crear el texto para la anotaci√≥n\ntexto_anotacion_aco &lt;- paste0(\n  \"Iteraci√≥n: \", mejor_iteracion_aco, \n  \"\\nCosto: \", format(round(mejor_costo_aco, 0), big.mark = \",\")\n)\n\n# Graficar la evoluci√≥n del costo en el ACO\nggplot(df_historial_aco, aes(x = Iteracion, y = CostoTotal)) +\n  geom_line(color = \"darkgreen\", size = 1) +\n  geom_point(color = \"forestgreen\", size = 1.5) +\n  annotate(\"point\", \n           x = mejor_iteracion_aco, \n           y = mejor_costo_aco, \n           color = \"red\", \n           size = 4) +\n  annotate(\"text\",\n           x = mejor_iteracion_aco + 20,  # desplazar el texto para que no tape el punto\n           y = mejor_costo_aco,\n           label = texto_anotacion_aco,\n           hjust = 0,\n           vjust = -0.5,\n           size = 4,\n           color = \"black\",\n           fontface = \"bold\") +\n  theme_minimal() +\n  labs(\n    title = \"Evoluci√≥n del Costo Total en el Algoritmo de Colonia de Hormigas (ACO)\",\n    x = \"Iteraci√≥n\",\n    y = \"Costo Total\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\", size = 14),\n    axis.title = element_text(face = \"bold\", size = 12),\n    axis.text = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\n\nFigura 4. Evoluci√≥n del Costo Total en el ACO a trav√©s de 500 iteraciones.\n\n\n3.3.2.2 Visualizaci√≥n de la mejor ruta\nLa Tabla 3 muestra la mejor ruta hallada por ACO, que corresponde al costo total m√≠nimo de $3.271.872, entre las 13 ciudades de Colombia en el orden que deben recorrerse.\nTabla 3. Orden en que deben recorrerse las 13 ciudades en la mejor ruta obtenida por ACO.\n\n\nCode\n# Ruta completa (cerrando el ciclo)\nruta_completa_aco &lt;- c(mejor_ruta_aco, mejor_ruta_aco[1])\n\n# Extraer ciudades seg√∫n el orden\nruta_ciudades_aco &lt;- CiudadesUbicacion[ruta_completa_aco, ]\n\n# Agregar orden de visita\nruta_ciudades_aco$Orden &lt;- 1:nrow(ruta_ciudades_aco)\n\n# Mostrar la mejor ruta en una tabla\nknitr::kable(ruta_ciudades_aco[, c(\"Ciudad\", \"Orden\")], \n             col.names = c(\"Ciudad\", \"Orden de visita\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = FALSE, position = \"center\") %&gt;%\n  column_spec(1, bold = TRUE, width = \"10em\") %&gt;%\n  column_spec(2, width = \"5em\") %&gt;%\n  row_spec(0, bold = TRUE, color = \"white\", background = \"#4682B4\")\n\n\n\n\n\n\nCiudad\nOrden de visita\n\n\n\n\nPasto\n1\n\n\nNeiva\n2\n\n\nIbagu√©\n3\n\n\nBogot√°\n4\n\n\nBucaramanga\n5\n\n\nC√∫cuta\n6\n\n\nSanta Marta\n7\n\n\nBarranquilla\n8\n\n\nCartagena\n9\n\n\nMedell√≠n\n10\n\n\nManizales\n11\n\n\nPereira\n12\n\n\nCali\n13\n\n\nPasto\n14\n\n\n\n\n\n\n\n\nLa Figura 5 muestra la superposici√≥n de la mejor ruta hallada por ACO en el mapa de Colombia.\n\n\nCode\n# Texto para mostrar el costo total\ncosto_aco_texto &lt;- paste0(\"Costo total (ACO): $\", format(round(mejor_costo_aco, 0), big.mark = \",\"))\n\n# √çconos personalizados\nicono_inicio &lt;- awesomeIcons(icon = 'flag', markerColor = 'green', iconColor = 'white', library = 'fa')\nicono_fin    &lt;- awesomeIcons(icon = 'flag', markerColor = 'red', iconColor = 'white', library = 'fa')\n\n# Crear el mapa\nleaflet() %&gt;%\n  addProviderTiles(providers$CartoDB.Positron) %&gt;%\n  \n  # Marcar ciudad de inicio\n  addAwesomeMarkers(\n    lng = ruta_ciudades_aco$Longitud[1],\n    lat = ruta_ciudades_aco$Latitud[1],\n    icon = icono_inicio,\n    popup = paste(\"Inicio:\", ruta_ciudades_aco$Ciudad[1])\n  ) %&gt;%\n  \n  # Marcar ciudad final (√∫ltima antes de cerrar el ciclo)\n  addAwesomeMarkers(\n    lng = ruta_ciudades_aco$Longitud[nrow(ruta_ciudades_aco) - 1],\n    lat = ruta_ciudades_aco$Latitud[nrow(ruta_ciudades_aco) - 1],\n    icon = icono_fin,\n    popup = paste(\"Fin:\", ruta_ciudades_aco$Ciudad[nrow(ruta_ciudades_aco) - 1])\n  ) %&gt;%\n  \n  # Puntos azules para las dem√°s ciudades\n  addCircleMarkers(\n    data = ruta_ciudades_aco,\n    lng = ~Longitud,\n    lat = ~Latitud,\n    radius = 6,\n    color = \"blue\",\n    fillOpacity = 0.8,\n    label = ~paste0(Orden, \". \", Ciudad),\n    popup = ~paste(\"Ciudad:\", Ciudad, \"&lt;br&gt;\", \"Orden:\", Orden)\n  ) %&gt;%\n  \n  # Ruta roja\n  addPolylines(\n    data = ruta_ciudades_aco,\n    lng = ~Longitud,\n    lat = ~Latitud,\n    color = \"red\",\n    weight = 3,\n    opacity = 0.8\n  ) %&gt;%\n  \n  # Costo total\n  addControl(\n    html = paste0(\"&lt;b&gt;Costo total ACO: $\", format(round(mejor_costo_aco, 0), big.mark = \",\"), \"&lt;/b&gt;\"),\n    position = \"bottomleft\"\n  )\n\n\n\n\n\n\nFigura 5. Superposici√≥n de la mejor ruta obtenida por ACO en el mapa de Colombia.\n\n\n\n3.3.3 Recorrido √≥ptimo animado mejor ruta ACO\nLa Figura 6 muestra una animaci√≥n del recorrido a trav√©s de la mejor ruta encontrada usando ACO aplicado al TSG.\n\n\n\n\n\nFigura 6. Animaci√≥n del recorrido √≥ptima encontrada usando ACO aplicado al TSG.\n\n\n3.3.4 Verificaci√≥n de la calidad de la soluci√≥n del ACO aplicado al TSP\nAunque los algoritmos metaheur√≠sticos no garantizan la optimalidad global, el comportamiento observado en la evoluci√≥n del costo sugiere que el algoritmo de colonia de hormigas (ACO) fue eficiente para encontrar una soluci√≥n competitiva al problema del viajante bajo condiciones realistas.\nEl ACO se aplic√≥ para resolver una instancia del problema del viajante, con el objetivo de minimizar el costo total de recorrer todas las ciudades y regresar al punto de partida. Dado que el n√∫mero de rutas posibles crece factorialmente con la cantidad de ciudades, una evaluaci√≥n exhaustiva por fuerza bruta es impracticable, lo que hace esencial analizar la calidad de la soluci√≥n obtenida a partir de los resultados emp√≠ricos del algoritmo.\nDurante las 500 iteraciones ejecutadas, el ACO mostr√≥ un patr√≥n t√≠pico de convergencia eficiente: el costo total disminuy√≥ r√°pidamente en las primeras iteraciones y se estabiliz√≥ alrededor de la iteraci√≥n 90. A partir de ese punto, el algoritmo mantuvo consistentemente la mejor soluci√≥n, lo que indica que las feromonas guiaron a las hormigas hacia una ruta s√≥lida, iterativamente reforzada como la mejor alternativa encontrada.\nEste patr√≥n de estabilizaci√≥n sugiere que el algoritmo alcanz√≥ un √≥ptimo local robusto. Si bien los m√©todos metaheur√≠sticos no garantizan encontrar la soluci√≥n √≥ptima global, la combinaci√≥n de una r√°pida convergencia, la estabilidad mantenida durante m√°s del 90% de las iteraciones y la coherencia en los resultados permiten concluir que la soluci√≥n obtenida es razonablemente buena en t√©rminos de eficiencia y costo.\nEl valor final alcanzado fue de $3,271,872, el cual se mantuvo inalterado en todas las iteraciones posteriores a la convergencia. Este comportamiento, junto con la tendencia descendente y estable de la funci√≥n objetivo, respalda la confiabilidad y solidez de la soluci√≥n obtenida mediante este enfoque bioinspirado."
  },
  {
    "objectID": "posts/Optimizacion-combinatoria/index.html#comparaci√≥n-entre-el-ga-y-aco-aplicados-al-tsg",
    "href": "posts/Optimizacion-combinatoria/index.html#comparaci√≥n-entre-el-ga-y-aco-aplicados-al-tsg",
    "title": "Optimizaci√≥n Combinatoria",
    "section": "3.4 Comparaci√≥n entre el GA y ACO aplicados al TSG",
    "text": "3.4 Comparaci√≥n entre el GA y ACO aplicados al TSG\nTanto el Algoritmo Gen√©tico (GA) como la Colonia de Hormigas (ACO) son enfoques metaheur√≠sticos inspirados en procesos naturales, aplicados en este trabajo a la resoluci√≥n del Problema del Viajante de Comercio (TSP). Ambos buscan encontrar rutas √≥ptimas minimizando el costo total del recorrido, que considera tiempo de desplazamiento, consumo de combustible y peajes. Aunque ambos m√©todos son de naturaleza estoc√°stica y no garantizan la optimalidad global, presentan diferencias notables en su enfoque, comportamiento y resultados.\nDesde el punto de vista computacional, el GA emplea operadores de evoluci√≥n gen√©tica -como selecci√≥n, cruce y mutaci√≥n- para explorar el espacio de soluciones, generando diversidad entre generaciones y favoreciendo combinaciones prometedoras. Por su parte, el ACO simula el comportamiento colectivo de las hormigas depositando y evaporando feromonas, construyendo soluciones de manera probabil√≠stica e incremental, guiadas por la experiencia acumulada.\nEn cuanto a los resultados obtenidos, ambos algoritmos convergieron a soluciones estables en un n√∫mero razonable de iteraciones. El ACO se destac√≥ por su r√°pida convergencia, alcanzando su mejor soluci√≥n alrededor de la iteraci√≥n 96 y manteni√©ndola constante durante el resto del proceso. El GA, en cambio, mostr√≥ una mejora m√°s progresiva y continua, permitiendo peque√±as optimizaciones incluso en etapas avanzadas del ciclo evolutivo.\nEn t√©rminos de calidad de la soluci√≥n, ambos m√©todos arrojaron rutas de costo muy similar, aunque no necesariamente id√©nticas. Esto sugiere que, pese a sus diferencias internas, cada algoritmo fue capaz de explorar zonas similares del espacio de soluciones, lo que refuerza la solidez de los resultados encontrados. Adem√°s, la convergencia de ambos m√©todos hacia soluciones estables ofrece evidencia emp√≠rica de que dichas soluciones se ubican en regiones de alta calidad dentro del espacio del problema.\nEn cuanto a interpretabilidad y ajuste, el GA ofrece una mayor flexibilidad en la manipulaci√≥n de operadores gen√©ticos y estrategias de cruce, mientras que el ACO se beneficia de una din√°mica colectiva m√°s estable una vez ajustados correctamente sus par√°metros (\\(\\alpha\\), \\(\\beta\\), evaporaci√≥n y n√∫mero de hormigas).\nAmbos algoritmos resultaron efectivos en la resoluci√≥n del problema propuesto, y la comparaci√≥n de sus resultados evidencia que, con configuraciones adecuadas, tanto el enfoque evolutivo como el bioinspirado pueden alcanzar soluciones de alta calidad. La elecci√≥n entre uno u otro depender√° del contexto, la facilidad de ajuste, la sensibilidad a los par√°metros y el tipo de convergencia deseado en problemas similares.\nEn resumen, ambos algoritmos permiten abordar el TSP de manera eficiente, evitando el alto costo computacional de los m√©todos exactos. La calidad de las soluciones es elevada, considerando la complejidad combinatoria del problema. La representaci√≥n gr√°fica de las rutas facilita la validaci√≥n y comunicaci√≥n de los resultados. La elecci√≥n entre GA y ACO depender√° de las caracter√≠sticas espec√≠ficas del problema, la facilidad de ajuste de par√°metros y el tipo de convergencia deseado.\nLa Tabla 4 presenta un resumen comparativo de las caracter√≠sticas de las simulaciones realizadas con GA y ACO para resolver el TSG.\nTabla 4. Comparaci√≥n de caracter√≠sticas y resultados: GA vs.¬†ACO aplicados al TSG.\n\n\nCode\ntabla_comp &lt;- data.frame(\n  \"Criterio\" = c(\n    \"Inspiraci√≥n\",\n    \"Construcci√≥n de soluciones\",\n    \"Velocidad de convergencia\",\n    \"Diversidad de soluciones\",\n    \"Sensibilidad a par√°metros\",\n    \"Estabilidad de resultados\",\n    \"Mejor iteraci√≥n lograda\",\n    \"Costo total alcanzado\",\n    \"Interpretabilidad\",\n    \"Fortalezas\",\n    \"Debilidades\"\n  ),\n  \"Algoritmo Gen√©tico (GA)\" = c(\n    \"Evoluci√≥n natural (selecci√≥n, cruza, mutaci√≥n)\",\n    \"Recombina soluciones completas para generar nuevas poblaciones\",\n    \"Moderada (mejora progresiva en varias etapas)\",\n    \"Alta diversidad gracias a mutaciones y recombinaci√≥n\",\n    \"Alta: requiere ajuste fino de cruza, mutaci√≥n y tama√±o de poblaci√≥n\",\n    \"Puede oscilar en fases avanzadas (dependiendo del azar y cruce)\",\n    \"Iteraci√≥n 253\",\n    \"~$3.369.197\",\n    \"Alta: permite seguimiento de operadores y evoluci√≥n\",\n    \"Explora m√°s ampliamente el espacio de soluciones\",\n    \"Requiere control de diversidad para evitar estancamiento\"\n  ),\n  \"Colonia de Hormigas (ACO)\" = c(\n    \"Comportamiento colectivo de hormigas y feromonas\",\n    \"Construye rutas paso a paso con base en probabilidad\",\n    \"Alta (mejora r√°pida en primeras iteraciones, estabilizaci√≥n temprana)\",\n    \"Menor diversidad, favorece la explotaci√≥n de buenas soluciones\",\n    \"Media-alta: depende de Œ±, Œ≤, evaporaci√≥n, n√∫mero de hormigas\",\n    \"Alta estabilidad tras converger a una buena ruta\",\n    \"Iteraci√≥n 96\",\n    \"~$3.271.872\",\n    \"Media: soluciones emergen de din√°mica colectiva\",\n    \"Explota rutas prometedoras r√°pidamente y converge de forma robusta\",\n    \"Puede converger prematuramente a √≥ptimos locales\"\n  ),\n  check.names = FALSE  # &lt;- ¬°Esto es lo importante!\n)\n\nkable(tabla_comp, \"html\", caption = \"Tabla 4. Comparaci√≥n de caracter√≠sticas y resultados: GA vs. ACO aplicados al TSP.\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), \n                full_width = FALSE, \n                position = \"center\") %&gt;%\n  column_spec(1, bold = TRUE, width = \"17em\") %&gt;%\n  column_spec(2, width = \"20em\") %&gt;%\n  column_spec(3, width = \"20em\") %&gt;%\n  row_spec(0, bold = TRUE, color = \"white\", background = \"#4682B4\")\n\n\n\n\nTabla 4. Comparaci√≥n de caracter√≠sticas y resultados: GA vs. ACO aplicados al TSP.\n\n\nCriterio\nAlgoritmo Gen√©tico (GA)\nColonia de Hormigas (ACO)\n\n\n\n\nInspiraci√≥n\nEvoluci√≥n natural (selecci√≥n, cruza, mutaci√≥n)\nComportamiento colectivo de hormigas y feromonas\n\n\nConstrucci√≥n de soluciones\nRecombina soluciones completas para generar nuevas poblaciones\nConstruye rutas paso a paso con base en probabilidad\n\n\nVelocidad de convergencia\nModerada (mejora progresiva en varias etapas)\nAlta (mejora r√°pida en primeras iteraciones, estabilizaci√≥n temprana)\n\n\nDiversidad de soluciones\nAlta diversidad gracias a mutaciones y recombinaci√≥n\nMenor diversidad, favorece la explotaci√≥n de buenas soluciones\n\n\nSensibilidad a par√°metros\nAlta: requiere ajuste fino de cruza, mutaci√≥n y tama√±o de poblaci√≥n\nMedia-alta: depende de Œ±, Œ≤, evaporaci√≥n, n√∫mero de hormigas\n\n\nEstabilidad de resultados\nPuede oscilar en fases avanzadas (dependiendo del azar y cruce)\nAlta estabilidad tras converger a una buena ruta\n\n\nMejor iteraci√≥n lograda\nIteraci√≥n 253\nIteraci√≥n 96\n\n\nCosto total alcanzado\n~$3.369.197\n~$3.271.872\n\n\nInterpretabilidad\nAlta: permite seguimiento de operadores y evoluci√≥n\nMedia: soluciones emergen de din√°mica colectiva\n\n\nFortalezas\nExplora m√°s ampliamente el espacio de soluciones\nExplota rutas prometedoras r√°pidamente y converge de forma robusta\n\n\nDebilidades\nRequiere control de diversidad para evitar estancamiento\nPuede converger prematuramente a √≥ptimos locales"
  }
]