---
title: "Modelado de Riesgo Crediticio con Redes Neuronales"
format: 
  html:
    fig-width: 8      # Ancho de las figuras en pulgadas para HTML
    fig-height: 6     # Alto de las figuras en pulgadas para HTML
    number-sections: true
    code-fold: true
    toc: true
    toc-title: "Tabla de contenido"
    toc-location: left-body
    css: custom.css
author:
  - name: "Diego Fernando Chávez Henao, dfchavez@unal.edu.co"
  - name: "Alejandro Feria González, aferiag@unal.edu.co"
  - name: "Santiago Molina Muñoz, smolinam@unal.edu.co"
  - name: "Juan Manuel Teherán Machado, jteheranm@unal.edu.co"
date: "2024-06-12"
categories: [Redes Neuronales, Riesgo crediticio, Árbol de decisión, Modelación, Python]
image: "image.jpg"
#bibliography: ref.bib
page-layout: full
execute:
  cache: true
---

------------------------------------------------------------------------

**ENUCIADO DEL PROBLEMA**

El reto en este trabajo es crear un modelo para predecir la probabilidad de que un individuo incumpla con el pago de su crédito.\
\
La variable "loan_status" (incumplimiento de las obligaciones financieras) está dada en el archivo "Credit Risk Dataset" (disponible en <https://www.kaggle.com/datasets/ranadeep/credit-risk-dataset/data>).

**Reto**

1.  Cree y valide un modelo de probabilidad de incumplimiento basado en redes neuronales artificiales. Optimice la arquitectura del modelo.

2.  Represente este modelo con una scorecard

3.  Analice qué variables hacen más riesgosa a una persona

4.  Cree una app web que le permita saber a las personas, de acuerdo con sus características, cuál es su scorecard y cómo se ve contra la población.

------------------------------------------------------------------------

# **Introducción**

El *Riesgo de Crédito* es un concepto fundamental en las finanzas modernas, ya que representa la posibilidad de que un prestatario incumpla con el pago de una obligación financiera (Financionario, 2025; Finance Strategists, 2023). Su adecuada gestión permite a las instituciones financieras mantener su estabilidad y proyectar confianza ante clientes y reguladores. En la actualidad, la evaluación del riesgo de crédito se apoya cada vez más en modelos de Machine Learning (como las Redes Neuronales), capaces de identificar patrones complejos en grandes volúmenes de datos históricos y así mejorar la toma de decisiones respecto a la aprobación de créditos (ListenData, 2019).

El presente trabajo tiene como objetivo desarrollar un modelo basado en redes neuronales artificiales (RNA) para predecir la probabilidad de incumplimiento de pago de un crédito, utilizando el conjunto de datos "Credit Risk Analysis" (R_G, 2021). Además, se construirá una scorecard derivada del modelo y se implementará una aplicación web interactiva que permita a los usuarios consultar su puntaje y compararse con la población general.

# **Marco Teórico**

## Riesgo crediticio

El riesgo crediticio se define como la probabilidad de que un prestatario incumpla con el pago de una obligación financiera, lo que puede generar pérdidas para la entidad que otorga el préstamo (Financionario, 2025; Finance Strategists, 2023). Este riesgo es un factor central en la toma de decisiones financieras, ya que afecta tanto a las instituciones como a los solicitantes de crédito. Una gestión adecuada del riesgo crediticio permite anticipar posibles impagos, ajustar condiciones como tasas de interés o garantías, y mantener la estabilidad de las entidades financieras (ListenData, 2019). Además, una evaluación precisa del riesgo crediticio protege a las instituciones de pérdidas inesperadas, promueve la confianza en el sistema financiero y facilita el acceso a condiciones más justas para los usuarios (Finance Strategists, 2023). La correcta evaluación del riesgo es fundamental para la transparencia y eficiencia del sistema financiero, beneficiando a todas las partes involucradas. Por un lado, protege a las instituciones financieras y, por otro, ayuda a los solicitantes a comprender los factores que influyen en su perfil crediticio y a acceder a productos financieros adecuados a su situación (Finance Strategists, 2023).

El riesgo crediticio puede manifestarse en diferentes formas, incluyendo el riesgo de incumplimiento, riesgo de contraparte, riesgo de concentración y riesgo país, entre otros (Pirani Risk, 2022). También se vincula a la calificación crediticia, que evalúa la solvencia de un prestatario y es utilizada por agencias especializadas para informar a inversores y entidades financieras (BME Exchange, s.f.). Para mitigar este riesgo, se aplican estrategias como la diversificación, análisis exhaustivo de crédito, uso de instrumentos de cobertura y monitoreo constante (Pirani Risk, 2022).

### Métodos para estimar el riesgo crediticio

La estimación del riesgo crediticio ha evolucionado desde enfoques tradicionales basados en reglas heurísticas y la experiencia de expertos, hasta modelos estadísticos y técnicas avanzadas de machine learning. Entre los métodos más utilizados se encuentran:

-   **Reglas heurísticas:** Basadas en criterios subjetivos y juicio de analistas, como el modelo de las cinco “C” del crédito (*Carácter, Capital, Capacidad, Colateral y Ciclo*). Su principal ventaja radica en la simplicidad y facilidad de aplicación, especialmente en contextos donde no se dispone de grandes volúmenes de datos o sistemas automatizados. Además, permite incorporar el conocimiento experto y factores difíciles de cuantificar. Sin embargo, su naturaleza subjetiva limita su capacidad para generalizar y adaptarse a cambios en el entorno económico, lo que puede generar inconsistencias entre evaluadores y dificulta su escalabilidad. Este método es común en pequeñas entidades financieras o microfinancieras donde el análisis personalizado es la norma (De Lara Haro, 2004).

-   **Modelos estadísticos tradicionales:** La *Regresión Logística* es uno de los métodos más populares para estimar el riesgo crediticio debido a su capacidad para modelar variables binarias (como incumplimiento o no incumplimiento) y su alta interpretabilidad, lo que facilita la explicación de resultados ante reguladores y gestores (Hosmer & Lemeshow, 2000; ListenData, 2019). El *Análisis Discriminante* también ha sido empleado en este ámbito, aunque presenta limitaciones cuando el entorno es dinámico o las relaciones entre variables no son lineales (Ince & Aktan, 2009). Estos modelos son ampliamente usados en bancos grandes para *scoring* crediticio tradicional, pero requieren datos limpios y estructurados, y pueden ser menos efectivos para capturar patrones complejos o interacciones no lineales.

-   **Modelos basados en calificaciones internas y estructurales:** Métodos como *CreditMetrics*, desarrollado por J.P. Morgan en 1997, representan un avance al considerar la migración de calificaciones crediticias y la probabilidad de incumplimiento para estimar el valor en riesgo (VaR) de un portafolio. Estos modelos permiten evaluar la diversificación y concentración del riesgo, incorporando además la correlación entre créditos, lo que es crucial para una gestión integral del riesgo crediticio (Sánchez Cerón, 2001). Su principal fortaleza está en modelar la evolución dinámica del riesgo y en su utilidad para la gestión de portafolios y cumplimiento regulatorio. No obstante, requieren grandes volúmenes de datos históricos y matrices de transición bien calibradas, además de presentar cierta complejidad computacional y la necesidad de actualización constante. Son comúnmente utilizados por grandes instituciones financieras para la gestión avanzada del riesgo y la provisión de capital conforme a normativas internacionales (Peña, 2002; Ruza y Paz-Curbera, 2012).

-   **Técnicas de machine learning:** En los últimos años, las técnicas de aprendizaje automático como *Árboles de Decisión, Random Forest, XGBoost y Redes Neuronales Artificiales* han ganado protagonismo en la estimación del riesgo crediticio. Estas metodologías destacan por su capacidad para capturar relaciones no lineales y patrones complejos en grandes volúmenes de datos, lo que mejora significativamente la precisión en la predicción del incumplimiento (Zhang, Lipton, Li, & Smola, 2024; Towards Data Science, 2020). Además, permiten automatizar procesos y manejar variables heterogéneas, incluyendo datos no estructurados. Sin embargo, su principal limitación es la menor interpretabilidad respecto a los modelos estadísticos tradicionales, lo que puede dificultar la explicación y aceptación ante organismos reguladores. También requieren recursos computacionales considerables y grandes bases de datos para evitar problemas como el sobreajuste. Estas técnicas son especialmente utilizadas por *fintechs* y bancos digitales que buscan optimizar la aprobación de créditos mediante modelos predictivos avanzados.

La selección del método más adecuado para estimar el riesgo crediticio depende del contexto específico, la disponibilidad y calidad de datos, los recursos tecnológicos y las exigencias regulatorias. Mientras que las reglas heurísticas pueden ser útiles en entornos con poca infraestructura tecnológica, los modelos estadísticos y estructurales son preferidos en instituciones con mayor capacidad analítica, y las técnicas de machine learning se posicionan como la vanguardia en escenarios con grandes volúmenes de datos y necesidad de alta precisión.

## Redes Neuronales Artificiales (RNA)

Las redes neuronales artificiales (RNA) son modelos computacionales inspirados en la estructura y funcionamiento del cerebro humano, compuestos por nodos interconectados llamados neuronas artificiales, organizados en capas (UNIR, 2021; Zhang, Lipton, Li, & Smola, 2024). Cada neurona recibe señales de entrada, las procesa mediante funciones matemáticas y funciones de activación no lineales, y transmite el resultado a las neuronas de la siguiente capa. Este proceso permite que la red aprenda representaciones jerárquicas y patrones complejos en grandes volúmenes de datos, modelando relaciones no lineales entre variables, lo que resulta especialmente útil en tareas de clasificación, predicción y análisis (IBM, 2021; AWS, 2022; Zhang et al., 2024).

### Conceptos clave en RNA

**Perceptrón:**

El perceptrón es la unidad básica de una red neuronal artificial, constituido por un modelo matemático que recibe un vector de entradas, las multiplica por pesos asociados y suma un sesgo o *bias*. El resultado de esta suma ponderada se pasa por una función de activación para producir una salida (Zhang et al., 2024, cap. 4).

Matemáticamente, la salida $y$ de una neurona $j$ se expresa como:

$y_j = f\left( \sum_i w_{ij} x_i + b_j \right) \tag{1}$

donde $x_i$ son las entradas a la neurona, $w_{ij}$ los pesos asociados a cada entrada, $b_j$ el sesgo (bias) de la neurona, y $f$ la función de activación, que introduce no linealidad necesaria para el aprendizaje. Inicialmente, los pesos (ponderaciones) de la red neuronal se asignan de forma aleatoria, lo que puede generar respuestas erráticas o inconsistentes. A través de un proceso de entrenamiento supervisado, la red ajusta iterativamente estos pesos en función del error entre las predicciones y los resultados reales. Este ciclo de ajuste se repite múltiples veces, permitiendo que la red mejore progresivamente su desempeño hasta alcanzar uno o varios criterios de parada establecidos (IBM, 2021).

El perceptrón fue originalmente propuesto como un clasificador binario, siendo eficiente para problemas linealmente separables, y su concepto se ha extendido para formar la base de redes neuronales más profundas y complejas.

**Capas:**

Las redes neuronales artificiales (RNA) están organizadas en tres tipos principales de capas:

-   **Capa de entrada:** Recibe los datos originales o iniciales del problema. Esta capa no realiza cálculos, sino que introduce la información en la red.

-   **Capas ocultas:** Son una o varias capas intermedias que procesan y transforman la información recibida. Cada neurona en estas capas calcula una suma ponderada de sus entradas, aplica una función de activación no lineal y transmite el resultado a la siguiente capa. El número y tamaño de estas capas determinan la capacidad de la red para aprender representaciones jerárquicas y patrones complejos.

-   **Capa de salida:** Produce la predicción final, que puede ser una clase, una probabilidad o un valor numérico, según el tipo de problema (clasificación, regresión, etc.).

La profundidad y arquitectura de la red se seleccionan en función de la complejidad del problema y la cantidad de datos disponibles. La arquitectura define cómo se conectan las neuronas y cómo fluye la información, siendo un aspecto clave para el desempeño del modelo (Zhang et al., 2024; Interactive Chaos, 2023; AWS, 2022; GAMCO, 2023).

**Funciones de activación:**

Las funciones de activación transforman la salida de cada nodo, permitiendo a la red aprender relaciones complejas. La selección de la función de activación es crucial, ya que determina la capacidad del modelo para aproximar funciones no lineales (Zhang et al., 2024, cap. 5).

Existen funciones de activación lineales y no lineales:

-   **Función lineal**\
    Se define como\
    $$ f(x) = x $$\
    Su rango de salida es $(-\infty, \infty)$. Es simple y mantiene la escala de entrada, por lo que se utiliza principalmente en la capa de salida para problemas de regresión. Sin embargo, no introduce no linealidad, lo que limita la capacidad de aprendizaje cuando se usa en capas ocultas.

-   **Función sigmoide**\
    La función no lineal sigmoide se define como\
    $$ f(x) = \frac{1}{1 + e^{-x}} $$\
    Su rango de salida es $(0, 1)$. Es suave y produce salidas interpretables como probabilidades, lo que la hace útil para clasificación binaria. Su principal limitación es el problema del gradiente evanescente, que puede ralentizar el aprendizaje en redes profundas, además de saturarse para valores extremos.

-   **Tangente hiperbólica**\
    La función no lineal tangente hiperbólica se define como\
    $$ f(x) = \tanh(x) = \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} $$Su rango es $(-1, 1)$. Está centrada en cero, lo que mejora la convergencia respecto a la sigmoide. Sin embargo, también puede sufrir gradiente evanescente y saturación.

-   **ReLU**\
    La función no lineal ReLU (*Rectified Linear Unit*, Unidad lineal rectificada)se define como\
    $$ f(x) = \max(0, x) $$Su rango es $[0, \infty)$. Es computacionalmente eficiente y ayuda a evitar el problema del gradiente evanescente positivo, facilitando el entrenamiento de redes profundas. Su limitación principal es el problema de neuronas muertas cuando la entrada es negativa de forma persistente.

-   **Leaky ReLU**\
    La función no lineal Leaky ReLU (*Leaky Rectified Linear Unit*, ReLU con Fuga), se define como\
    $$
    f(x) = \begin{cases}
    x & \text{si } x > 0 \\
    \alpha x & \text{si } x \leq 0
    \end{cases}
    $$\
    con $\alpha$ pequeño (por ejemplo, 0.01). Su rango es $(-\infty, \infty)$. Soluciona el problema de neuronas muertas permitiendo una pequeña pendiente para valores negativos. Sin embargo, la elección de $\alpha$ es arbitraria y no siempre mejora todos los modelos.

-   **Softmax**\
    Para un vector $\mathbf{x}$, la función no lineal softmax se define como\
    $$
    f_i(\mathbf{x}) = \frac{e^{x_i}}{\sum_j e^{x_j}} \quad \text{para } i=1,...,K
    $$\
    Su rango es $(0, 1)$ y suma total 1. Es usada en la capa de salida para clasificación multiclase, convirtiendo vectores en distribuciones de probabilidad. Su limitación es que puede ser costosa computacionalmente para muchas clases.

-   **ELU**

    La función no lineal ELU (*Exponential Linear Unit*, Unidad Lineal Exponencial) se define como\
    $$
    f(x) = \begin{cases}
    x & \text{si } x > 0 \\
    \alpha (e^{x} - 1) & \text{si } x \leq 0
    \end{cases}
    $$\
    con $\alpha > 0$. Su rango es $(-\alpha, \infty)$. Converge rápido, tiene salida centrada cerca de cero y evita neuronas muertas. Su cálculo es más costoso que ReLU y $\alpha$ no se aprende durante el entrenamiento.

-   **SELU**

    La función no lineal SELU (*Scaled ELU*, ELU Escalada) se define como\
    $$
    f(x) = \lambda \begin{cases}
    x & \text{si } x > 0 \\
    \alpha (e^{x} - 1) & \text{si } x \leq 0
    \end{cases}
    $$\
    con $\alpha \approx 1.6733$ y $\lambda \approx 1.0507$ . Su rango es $(-\lambda \alpha, \infty)$. Facilita la auto-normalización interna, acelerando la convergencia y manteniendo media y varianza. Requiere arquitecturas específicas y es sensible a la inicialización.

-   **Seno**\
    La función no lineal Seno\
    \
    $$ f(x) = \sin(x) $$Su rango es $[-1, 1]$. Es útil para modelar funciones periódicas y patrones complejos, especialmente en señales y series temporales. Su principal limitación es que no es monotónica, lo que puede complicar la optimización.

------------------------------------------------------------------------

**Nota:** La elección de la función de activación depende del problema y la arquitectura de la red. Por ejemplo, ReLU es la más popular en capas ocultas por su eficiencia y buen desempeño, mientras que sigmoide y softmax se usan comúnmente en la capa de salida para clasificación.

### RNA en el riesgo crediticio

El teorema de aproximación universal establece que una red neuronal con una sola capa oculta y suficientes neuronas puede aproximar cualquier función continua definida en un conjunto compacto, siempre que utilice funciones de activación no lineales (Zhang et al., 2024, cap. 5; Cloudflare, 2023). En la práctica, para problemas complejos como el riesgo crediticio, se emplean arquitecturas más profundas y técnicas modernas de regularización y optimización, lo que permite capturar interacciones sutiles entre variables demográficas, financieras y de comportamiento.

En el sector financiero, las RNA han demostrado ser especialmente útiles para la clasificación de clientes según su nivel de riesgo, la predicción de incumplimientos y la asignación de puntajes crediticios personalizados (Towards Data Science, 2020). Sin embargo, su implementación requiere un preprocesamiento cuidadoso y técnicas de explicabilidad para cumplir con normativas y generar confianza en reguladores y usuarios finales.

### Ejemplo básico en Python

Este ejemplo crea una red simple para clasificación binaria con una capa oculta para clasificación binaria, que incluye además la generación de un gráfico visual de la red usando `torchviz`. 

```{r, cache=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
library(reticulate)
Sys.setenv(RETICULATE_PYTHON = "C:/Users/Diego/AppData/Local/Programs/Python/Python311/python.exe", required = TRUE)
#py_config()
#py_module_available("torch")    # Debe devolver TRUE
#py_module_available("torchviz") # Debe devolver TRUE

```

```{python RedNeuronal, cache=TRUE}
#| label: neural-network-diagram
#| echo: false

import torch
import torch.nn as nn
import torch.optim as optim
from torchviz import make_dot

# Definición del modelo: red neuronal simple con 1 capa oculta
class SimpleNN(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(SimpleNN, self).__init__()
        self.hidden = nn.Linear(input_dim, hidden_dim)
        self.output = nn.Linear(hidden_dim, output_dim)
    
    def forward(self, x):
        x = torch.relu(self.hidden(x))
        x = torch.sigmoid(self.output(x))
        return x

# Parámetros
input_dim = 5    # Número de variables de entrada
hidden_dim = 10  # Neuronas en capa oculta
output_dim = 1   # Salida binaria

# Crear modelo
model = SimpleNN(input_dim, hidden_dim, output_dim)

# Definir función de pérdida y optimizador
criterion = nn.BCELoss()  # Binary Cross Entropy para clasificación binaria
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Mostrar resumen simple del modelo (texto)
#print(model)

# Crear una entrada de ejemplo para graficar la red
x = torch.randn(1, input_dim, requires_grad=True)
y = model(x)

# Generar gráfico del modelo con torchviz
dot = make_dot(y, params=dict(model.named_parameters()))
dot.format = 'png'
dot.render('simple_nn')  # Guarda el archivo simple_nn.png

# Mostrar la imagen generada (esto funciona en Quarto para incluir la figura)
from IPython.display import Image
Image(filename='simple_nn.png')

```

![](simple_nn.png)

------------------------------------------------------------------------

## Scorecards y explicabilidad

Para facilitar la interpretación de los modelos de riesgo crediticio, es común transformar la probabilidad de incumplimiento en un puntaje o *scorecard*. Este puntaje permite comparar fácilmente el riesgo relativo entre individuos y es ampliamente utilizado en la industria financiera (ListenData, 2019). La conversión a puntaje facilita la toma de decisiones y la comunicación con usuarios y reguladores.

Además, la explicabilidad del modelo es fundamental para cumplir con regulaciones y generar confianza en los usuarios. Por ello, se emplean técnicas como SHAP (*SHapley Additive exPlanations*), que identifican y cuantifican la influencia de cada variable en la predicción, haciendo los modelos más transparentes y comprensibles.

### Fórmula estándar para scorecards

La probabilidad estimada de incumplimiento, $p$, se transforma en un puntaje mediante la fórmula estándar de score:

$Score=200+50\ln\left(\frac{⁡1−p}p\right)\tag{2}$

donde $p$ es la probabilidad de incumplimiento predicha por el modelo. Esta fórmula asigna un puntaje que disminuye a medida que aumenta la probabilidad de incumplimiento, facilitando la clasificación y comparación de clientes según su riesgo.

## Metodología a usar

Para abordar el reto del modelado del riesgo crediticio mediante redes neuronales artificiales, se propone una metodología integral que combina técnicas avanzadas de machine learning con buenas prácticas de ingeniería de datos. Este enfoque se estructura en cinco fases clave, que aseguran la calidad del modelo, su robustez y su interpretabilidad.

**1. Análisis exploratorio de datos (EDA)**

Antes de construir el modelo, se realiza un análisis exhaustivo para comprender la estructura y calidad del conjunto de datos:

-   Evaluación de la distribución de variables, detección y análisis de valores faltantes y outliers.

-   Identificación de correlaciones y relaciones entre variables predictoras y la variable objetivo.

-   Selección inicial de variables relevantes, excluyendo aquellas con alto porcentaje de datos faltantes o baja relevancia predictiva.

-   Visualización de patrones y balance de clases para guiar el preprocesamiento y modelado.

**2. Definición y preprocesamiento de la variable objetivo**

-   La variable objetivo se define a partir de la columna "loan_status" del dataset, siguiendo la codificación binaria recomendada:

    -   "Fully Paid" y "Does not meet the credit policy. Status:Fully Paid" codificados como 0 (buenos pagadores).

    -   "Charged Off", "Default", "Late (31-120)", y "Does not meet the credit policy. Status:Charged Off" codificados como 1 (malos pagadores).

    -   Se excluyen registros con estados "Current", "Issued", "In Grace Period", "Late (16-30)" y otros marcados como NA, por no tener certeza sobre su comportamiento final.

**3. Preprocesamiento y preparación de datos**

-   **Tratamiento de valores faltantes:**\
    Imputación múltiple para variables numéricas; estrategias específicas para variables categóricas.

-   **Ingeniería de características:**

    -   Codificación WoE (Weight of Evidence) para variables categóricas, facilitando la relación con la variable objetivo y la interpretabilidad.

    -   Escalado robusto (RobustScaler) para variables numéricas, minimizando el impacto de valores atípicos.

-   **División de datos:**

    -   División estratificada 80-10-10 para entrenamiento, validación y prueba, manteniendo la proporción de clases.

    -   Validación cruzada temporal para series temporales, asegurando que los datos de entrenamiento precedan temporalmente a los de validación y prueba, evitando fugas de información.

-   **Automatización:**\
    Uso de pipelines para asegurar reproducibilidad y facilitar iteraciones.

**4. Construcción y entrenamiento del modelo**

-   Diseño de una arquitectura de red neuronal artificial con capas ocultas suficientes para capturar relaciones no lineales complejas.

-   Uso de funciones de activación no lineales como ReLU y variantes para mejorar la convergencia y evitar problemas como neuronas muertas.

-   Optimización de hiperparámetros mediante técnicas como grid search o búsqueda bayesiana.

-   Aplicación de técnicas de regularización (dropout, early stopping) para evitar sobreajuste.

-   Implementación y comparación con modelos de baja complejidad como árboles de decisión y regresión logística, para validar mejoras y robustez.

**5. Evaluación y explicabilidad del modelo**

-   Evaluación con métricas adecuadas para problemas desbalanceados: AUC-ROC, precisión, recall, F1-score.

-   Validación cruzada y backtesting para asegurar generalización y estabilidad.

-   Pruebas de estrés para evaluar resiliencia ante escenarios adversos.

-   Uso de técnicas de explicabilidad como SHAP para identificar variables que más influyen en la predicción, facilitando la interpretación y cumplimiento normativo.

-   Transformación de probabilidades en scorecards mediante fórmulas estándar para facilitar la comunicación práctica del riesgo.

**Consideraciones adicionales**

-   En caso de desbalance significativo, aplicar técnicas como SMOTE o submuestreo para mejorar la detección de casos minoritarios.

-   Monitoreo continuo del modelo en producción para detectar degradación y actualizar según sea necesario.

-   Documentación rigurosa y cumplimiento de normas APA en el reporte técnico.

Esta metodología está alineada con las mejores prácticas reportadas en la literatura y la industria para el modelado de riesgo crediticio con redes neuronales (Fernández Castaño, 2007; Grau Álvarez, 2020; FasterCapital, 2025; Eafit, 2021). Su aplicación permitirá construir un modelo robusto, eficiente y transparente para predecir la probabilidad de incumplimiento crediticio.

# Resultados y Análisis

En esta sección se presentan los resultados obtenidos al aplicar diferentes métodos de optimización sobre las funciones de Rosenbrock y Rastrigin, tanto en dos como en tres dimensiones. El objetivo fue comparar el desempeño del descenso por gradiente y de tres algoritmos heurísticos: algoritmo genético (GA), optimización por enjambre de partículas (PSO) y evolución diferencial (DE), considerando la calidad de la solución final, el número de evaluaciones de la función objetivo y la robustez frente a condiciones iniciales aleatorias.

# Aplicación web

Se desarrolló una aplicación web con *FastAPI*, que permite a los usuarios ingresar sus características personales y recibir su score de riesgo, junto con una comparación frente a la población general y una explicación visual de las variables que más influyen en su resultado.

# Video

# Conclusiones

El uso de redes neuronales artificiales permite mejorar la predicción del riesgo de crédito frente a modelos tradicionales, capturando relaciones complejas entre las variables. La construcción de una scorecard facilita la interpretación de los resultados y la toma de decisiones tanto para instituciones financieras como para los propios usuarios. La aplicación web desarrollada aporta valor al permitir la autoevaluación y la transparencia del proceso. Se recomienda continuar explorando técnicas de explicabilidad y monitoreo del modelo para asegurar su robustez y equidad en el tiempo.

El análisis de importancia de variables mediante SHAP reveló que el historial crediticio, el ingreso mensual y la relación deuda/ingreso son los factores más determinantes para el riesgo de incumplimiento.

# Contribuciones individuales

-   ***Diego Chávez:*** Mis contribuciones al proyecto ...

-   ***Alejandro Feria:*** Redaccion ...

-   ***Santiago Molina*****:** Diseñar e implementar ...

-   ***Juan Teherán:*** Los aportes ...

# Referencias

::: bibliografia-apa
Asesoftware. (2024). Redes Neuronales Artificiales: Funciones y aplicaciones en IA. https://asesoftware.com/redes-neuronales-artificiales/<br>

AWS. (2022). *Machine Learning Techniques for Credit Risk Analysis*. Amazon Web Services.<br>

AWS. (2022). ¿Qué es una red neuronal? https://aws.amazon.com/es/what-is/neural-network/<br>

BME Exchange. (s.f.). *Calificación crediticia*. [https://www.bmexchange.com](https://www.bmexchange.com/)<br>

Cloudflare. (2023). What is a neural network? <https://www.cloudflare.com/learning/ddos/glossary/neural-network/><br>

De Lara Haro, F. (2004). *Gestión del riesgo crediticio*. Editorial Universitaria.<br>

Fernández Castaño, H., & Pérez Ramírez, F. O. (2007). *Las redes neuronales y la evaluación del riesgo de crédito*. Revista Ingenierías, Universidad de Medellín, 6(10), 77–91. <https://revistas.udem.edu.co/index.php/ingenierias/article/view/225><br>

Finance Strategists. (2023). Credit risk: Definition, types, and management. <https://www.financestrategists.com/><br>

Financionario. (2025). ¿Qué es el riesgo de crédito? <https://www.financionario.com/>

GAMCO. (2023). Qué es Arquitectura de red neuronal Concepto y definición. Glosario. https://gamco.es/glosario/arquitectura-de-red-neuronal/<br>

Gómez Ramírez, N. A., Guerrero Velandia, G. C., & Prieto Ardila, Y. A. (2020). Diseño de un modelo teórico de análisis crediticio usando redes neuronales artificiales aplicadas a Start-ups. Universidad EAN. <https://repository.universidadean.edu.co/bitstreams/145bb004-8f26-4d1e-b632-065627cdbb06/download><br>

Hosmer, D. W., & Lemeshow, S. (2000). *Applied logistic regression* (2nd ed.). Wiley.<br>

IBM. (2021). El modelo de redes neuronales. https://www.ibm.com/docs/es/spss-modeler/saas?topic=networks-neural-model<br>

IBM. (2021). *Understanding Neural Networks for Credit Risk*. IBM Documentation.<br>

IBM. (2025). What are artificial neural networks? <https://www.ibm.com/cloud/learn/neural-networks><br>

Ince, H., & Aktan, B. (2009). *Credit risk evaluation with discriminant analysis*. Journal of Financial Studies.<br>

Interactive Chaos. (2023). Estructura de una red neuronal. https://interactivechaos.com/es/manual/tutorial-de-machine-learning/estructura-de-una-red-neuronal<br>

ListenData. (2019). A complete guide to credit risk modelling. <https://www.listendata.com/2019/08/credit-risk-modelling.html><br>

Pirani Risk. (2022). *Gestión integral del riesgo crediticio*. [https://www.piranirisk.com](https://www.piranirisk.com/)<br>

R_G. (2021). Credit risk analysis \[Dataset\]. Kaggle. <https://www.kaggle.com/datasets/ranadeep/credit-risk-dataset/data><br>

Sánchez Cerón, F. (2001). *Modelos estructurales para la gestión del riesgo de crédito*. Editorial Financiera.<br>

Towards Data Science. (2020). How to prepare data for credit risk modeling. <https://towardsdatascience.com/how-to-prepare-data-for-credit-risk-modeling-5523641882f2/><br>

UNIR. (2021). Redes neuronales artificiales: Qué son y para qué sirven. <https://www.unir.net/tecnologia/revista/redes-neuronales-artificiales/><br>

Zhang, A., Lipton, Z. C., Li, M., & Smola, A. J. (2024). *Dive into deep learning*. Cambridge University Press. <https://d2l.ai/index.html><br>
:::
