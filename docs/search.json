[
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "Redes Neuronales y Algoritmos Bioinspirados - Grupo 8",
    "section": "",
    "text": "Este repositorio contiene los trabajos y materiales desarrollados para la materia Redes Neuronales y Algoritmos Bioinspirados de la Universidad Nacional de Colombia, realizados por el Grupo 8.\n\n\nEl proyecto consiste en un blog académico construido con Quarto, donde se publican análisis, implementaciones y resultados de diferentes algoritmos inspirados en la naturaleza, con énfasis en:\n\nRedes Neuronales\nAlgoritmos Genéticos\nColonia de Hormigas\nOptimización Numérica y Combinatoria\n\nEl blog está dirigido a estudiantes y personas interesadas en aprender de manera práctica y teórica sobre modelos de inteligencia artificial y optimización bioinspirada.\n\n\n\n\n/posts/\nContiene los artículos principales del blog, cada uno en una carpeta independiente:\n\nBienvenida/ — Introducción al blog y motivación.\nOptimizacion-numerica/ — Optimización numérica: gradiente descendente y métodos heurísticos.\nOptimizacion-combinatoria/ — Optimización combinatoria: TSP con algoritmos genéticos y colonia de hormigas.\n\n/docs/\nCarpeta generada automáticamente por Quarto con los archivos HTML del blog listo para publicación.\n/data/\nArchivos de datos utilizados en los análisis (matrices de distancias, tiempos, ubicaciones de ciudades, etc.).\nreadme.md\nEste archivo.\n\n\n\n\n\nLenguaje principal: R\nVisualización: ggplot2, plotly, leaflet\nOptimización: GA, pso, DEoptim (librerías de R)\nDocumentación y publicación: Quarto\n\n\n\n\nPuedes navegar el blog generado en la carpeta /docs/ abriendo index.html en tu navegador, o desplegarlo en un servidor web estático.\n\n\n\n\nDiego Fernando Chávez Henao — dfchavez@unal.edu.co\nAlejandro Feria González — aferiag@unal.edu.co\nSantiago Molina Muñoz — smolinam@unal.edu.co\nJuan Manuel Teherán Machado — jteheranm@unal.edu.co\n\n\n\n\nLas implementaciones y análisis se basan en bibliografía académica relevante, citada en cada post. Los datos de ciudades y parámetros de costos fueron obtenidos de fuentes públicas y oficiales.\n\nUniversidad Nacional de Colombia — 2025"
  },
  {
    "objectID": "readme.html#descripción",
    "href": "readme.html#descripción",
    "title": "Redes Neuronales y Algoritmos Bioinspirados - Grupo 8",
    "section": "",
    "text": "El proyecto consiste en un blog académico construido con Quarto, donde se publican análisis, implementaciones y resultados de diferentes algoritmos inspirados en la naturaleza, con énfasis en:\n\nRedes Neuronales\nAlgoritmos Genéticos\nColonia de Hormigas\nOptimización Numérica y Combinatoria\n\nEl blog está dirigido a estudiantes y personas interesadas en aprender de manera práctica y teórica sobre modelos de inteligencia artificial y optimización bioinspirada."
  },
  {
    "objectID": "readme.html#estructura-del-repositorio",
    "href": "readme.html#estructura-del-repositorio",
    "title": "Redes Neuronales y Algoritmos Bioinspirados - Grupo 8",
    "section": "",
    "text": "/posts/\nContiene los artículos principales del blog, cada uno en una carpeta independiente:\n\nBienvenida/ — Introducción al blog y motivación.\nOptimizacion-numerica/ — Optimización numérica: gradiente descendente y métodos heurísticos.\nOptimizacion-combinatoria/ — Optimización combinatoria: TSP con algoritmos genéticos y colonia de hormigas.\n\n/docs/\nCarpeta generada automáticamente por Quarto con los archivos HTML del blog listo para publicación.\n/data/\nArchivos de datos utilizados en los análisis (matrices de distancias, tiempos, ubicaciones de ciudades, etc.).\nreadme.md\nEste archivo."
  },
  {
    "objectID": "readme.html#tecnologías-y-herramientas",
    "href": "readme.html#tecnologías-y-herramientas",
    "title": "Redes Neuronales y Algoritmos Bioinspirados - Grupo 8",
    "section": "",
    "text": "Lenguaje principal: R\nVisualización: ggplot2, plotly, leaflet\nOptimización: GA, pso, DEoptim (librerías de R)\nDocumentación y publicación: Quarto"
  },
  {
    "objectID": "readme.html#cómo-ver-el-blog",
    "href": "readme.html#cómo-ver-el-blog",
    "title": "Redes Neuronales y Algoritmos Bioinspirados - Grupo 8",
    "section": "",
    "text": "Puedes navegar el blog generado en la carpeta /docs/ abriendo index.html en tu navegador, o desplegarlo en un servidor web estático."
  },
  {
    "objectID": "readme.html#autores",
    "href": "readme.html#autores",
    "title": "Redes Neuronales y Algoritmos Bioinspirados - Grupo 8",
    "section": "",
    "text": "Diego Fernando Chávez Henao — dfchavez@unal.edu.co\nAlejandro Feria González — aferiag@unal.edu.co\nSantiago Molina Muñoz — smolinam@unal.edu.co\nJuan Manuel Teherán Machado — jteheranm@unal.edu.co"
  },
  {
    "objectID": "readme.html#créditos-y-referencias",
    "href": "readme.html#créditos-y-referencias",
    "title": "Redes Neuronales y Algoritmos Bioinspirados - Grupo 8",
    "section": "",
    "text": "Las implementaciones y análisis se basan en bibliografía académica relevante, citada en cada post. Los datos de ciudades y parámetros de costos fueron obtenidos de fuentes públicas y oficiales.\n\nUniversidad Nacional de Colombia — 2025"
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html",
    "href": "posts/Optimizacion-numerica/index.html",
    "title": "Optimización Numérica",
    "section": "",
    "text": "1 Introducción\n  2 Marco Teórico\n  \n  2.1 Funciones de prueba\n  \n  2.1.1 Función de Rosenbrock\n  2.1.2 Función de Rastrigin\n  \n  2.2 Métodos de Optimización\n  \n  2.2.1 Descenso por Gradiente\n  \n  2.3 Métodos Bioinspirados\n  \n  2.3.1 Algoritmos Genéticos (GA) en Optimización Numérica\n  2.3.2 Optimización por Enjambre de Partículas (PSO)\n  2.3.3 Evolución Diferencial (DE)\n  \n  \n  3 Resultados y Análisis\n  \n  3.1 Proceso Experimental\n  3.2 Visualización de las Funciones\n  3.3 Optimización con Descenso por Gradiente\n  \n  3.3.1 Animación del Descenso por Gradiente en la función Rosenbrock\n  3.3.2 Animación del Descenso por Gradiente en la función Rastrigin\n  \n  3.4 Optimización con Algoritmos Heurísticos\n  \n  3.4.1 Algoritmo Genético (GA)\n  3.4.2 Optimización por Enjambre de Partículas (PSO)\n  3.4.3 Evolución Diferencial (DE)\n  \n  3.5 Comparación de Resultados\n  3.6 Análisis de Convergencia y Robustez\n  \n  4 Conclusiones\n  5 Contribuciones individuales\n  6 Referencias\nENUCIADO DEL PROBLEMA\nConsidere las siguientes funciones de prueba:\nDiscuta\n¿Qué aportaron los métodos de descenso por gradiente y qué aportaron los métodos heurísticos? Para responder a esta pregunta considere el valor final de la función objetivo y el número de evaluaciones de la función objetivo. Para responder a esta pregunta es posible que se requiera hacer varias corridas de los algoritmos."
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#funciones-de-prueba",
    "href": "posts/Optimizacion-numerica/index.html#funciones-de-prueba",
    "title": "Optimización Numérica",
    "section": "2.1 Funciones de prueba",
    "text": "2.1 Funciones de prueba\nEn este estudio se seleccionaron dos funciones de prueba ampliamente utilizadas en la literatura de optimización numérica: la función de Rosenbrock y la función de Rastrigin. Ambas presentan retos particulares para los algoritmos de optimización y permiten evaluar el desempeño de métodos clásicos y heurísticos en diferentes escenarios. Mucho de lo expresado a partir de aquí proviene de (Zhang et al., 2024).\n\n2.1.1 Función de Rosenbrock\nLa función de Rosenbrock, también conocida como función del valle o del plátano, es una función unimodal que se emplea frecuentemente para probar algoritmos de optimización basados en gradientes. Su principal característica es la presencia de un valle parabólico angosto que contiene el mínimo global, lo cual puede dificultar la convergencia de los algoritmos hacia este punto (Rosenbrock, 1960). La función de Rosenbrock es útil para evaluar la capacidad de los algoritmos para seguir valles estrechos y alcanzar el mínimo global, especialmente cuando la superficie de la función presenta curvaturas pronunciadas. Sin embargo, la convergencia puede ser desafiante debido a la naturaleza del valle.\nLa forma general en \\(N\\) dimensiones es:\n\\[f(\\mathbf{x})=\\sum_{i=1}^{N-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (1-x_1)^2 \\right] \\tag{1}\\]donde \\(\\mathbf{x} = (x_1, \\dots, x_N) \\in \\mathbb{R}^N\\). La función se suele evaluar en el rango \\(x_i \\in [−5, 10]\\) (Picheny et al., 2012).\n\nEn dos dimensiones, la función se expresa como:\n\\[f(x_1, x_2) = 100 (x_2 - x_1^2)^2 + (1 - x_1)^2 \\tag{2}\\] y el mínimo global se encuentra en \\((x_1, x_2) = (1, 1)\\), donde \\(f(1, 1) = 0\\).\nEn dos dimensiones, la función de Rosenbrock exhibe un paisaje característico dominado por un valle parabólico estrecho y curvo que se extiende a lo largo del plano. Este valle representa la trayectoria hacia el mínimo global de la función, ubicado en el punto \\((1, 1)\\), donde el valor de la función es exactamente cero.\nLa Figura 1 muestra una visualización 3D interactiva de la función de Rosenbrock en 2 dimensiones., que se puede mover haciendo clic sostenido con el mouse. Se observa que la función forma un valle curvo y estrecho en el espacio \\((x_1, x_2, x_3)\\), donde el mínimo global está al fondo del valle. Este valle es difícil de seguir para los algoritmos de optimización, especialmente para métodos basados en gradiente, ya que la dirección óptima cambia abruptamente a lo largo del valle.\n\n\nCode\nlibrary(plotly)\nlibrary(ggplot2)\n\n# Definición de la función Rosenbrock\nrosenbrock &lt;- function(x, a=1, b=100) {\n  (a - x[1])^2 + b * (x[2] - x[1]^2)^2\n}\n\n# Crear la malla de puntos\nx_seq &lt;- seq(-2.5, 2.5, length.out = 301)\ny_seq &lt;- seq(-1, 3, length.out = 301)\ngrid &lt;- expand.grid(x = x_seq, y = y_seq)\n\n# Evaluar la función en cada punto\ngrid$z &lt;- apply(grid, 1, function(row) rosenbrock(c(row['x'], row['y'])))\n\n# Matriz para el gráfico 3D\nz_matrix &lt;- matrix(grid$z, nrow = length(x_seq), byrow = TRUE)\n\n# Calcular el valor exacto en el mínimo global\nz_min &lt;- rosenbrock(c(1, 1))\n\n# Gráfico 3D interactivo con plotly\nfig_3d &lt;- plot_ly(\nx = ~x_seq, y = ~y_seq, z = ~z_matrix\n) %&gt;%\nadd_surface() %&gt;%\nlayout(\ntitle = \"Función Rosenbrock (3D)\",\nscene = list(\nxaxis = list(title = \"X1\", range = c(min(x_seq), max(x_seq))),\nyaxis = list(title = \"X2\", range = c(min(y_seq), max(y_seq))),\nzaxis = list(title = \"f(X1, X2)\")\n)\n) %&gt;%\nadd_markers(x = 1, y = 1, z = z_min, marker = list(color = 'red', size = 5), name = \"Mínimo global\")\n\n# Mostrar gráfico 3D\nfig_3d\n\n\n\n\n\n\nFigura 1. Representación gráfica interactiva de la función de Rosenbrock.\nLa Figura 2 muestra el gráfico de contorno de la Figura 1. Se observan curvas alargadas y cerradas que se agrupan densamente alrededor del mínimo, evidenciando una fuerte curvatura en una dirección y suavidad en la otra. Por ello, la función de Rosenbrock es un banco de pruebas exigente para métodos de optimización, poniendo a prueba su capacidad para navegar regiones con cambios rápidos en la dirección de descenso.\n\n\nCode\n# Gráfico de contorno con ggplot2\nlibrary(ggplot2)\nlibrary(viridis) # Para paleta de colores atractiva\ncontour_plot &lt;- ggplot(grid, aes(x = x, y = y, z = z)) +\ngeom_contour_filled(bins = 30) + # Contornos rellenos con color\ngeom_contour(color = \"black\", alpha = 0.3, bins = 30) + # Líneas de contorno semi-transparentes\ngeom_point(aes(x = 1, y = 1), color = \"red\", size = 3) + # Mínimo global\nscale_fill_viridis_d(option = \"viridis\") + # Paleta viridis discreta\ncoord_fixed(ratio = 1) + # Escala igual en x e y\nxlim(min(x_seq), max(x_seq)) +\nylim(min(y_seq), max(y_seq)) +\nlabs(title = \"Gráfico de Contorno coloreado de la función Rosenbrock\",\nx = \"X1\", y = \"X2\", fill = \"f(X1, X2)\") +\ntheme_minimal()\n\nprint(contour_plot)\n\n\n\n\n\n\n\n\n\nFigura 2. Gráfico de Contorno de la función de Rosenbrock.\nEn tres dimensiones, la función se expresa como:\n\\[f(x_1, x_2, x_3) = 100 (x_2 - x_1^2)^2 + (1 - x_1)^2 + 100 (x_3 - x_2^2)^2 + (1 - x_2)^2 \\tag{3}\\]y el mínimo global se encuentra en \\((x_1, x_2, x_3) = (1, 1, 1)\\), donde \\(f(1, 1, 1) = 0\\).\n\n\n\n2.1.2 Función de Rastrigin\nLa función de Rastrigin es una función altamente multimodal, caracterizada por la presencia de numerosos mínimos locales distribuidos de manera regular en el dominio de búsqueda. Esto la convierte en un reto para los algoritmos de optimización, ya que es fácil que queden atrapados en óptimos locales (Törn & Žilinskas, 1989). Su topografía se asemeja a un paraboloide cuadrático sobre el que se superponen ondulaciones sinusoidales, generando un patrón regular de picos y valles. Esta función es ampliamente utilizada para evaluar la capacidad de los algoritmos de optimización para escapar de mínimos locales y encontrar el óptimo global en paisajes de búsqueda complejos y repetitivos.\nLa forma general en \\(N\\) dimensiones es:\n\\[\nf(\\mathbf{x}) = 10N + \\sum_{i=1}^{N} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right] \\tag{4}\n\\]\ndonde \\(\\mathbf{x} = (x_1, \\dots, x_N) \\in \\mathbb{R}^N\\). El rango de evaluación recomendado es \\(x_i \\in [-5.12, 5.12]\\) (Mühlenbein et al., 1991).\n\nEn dos dimensiones, la función se expresa como:\n\\[\nf(x_1, x_2) = 20 + x_1^2 - 10\\cos(2\\pi x_1) + x_2^2 - 10\\cos(2\\pi x_2) \\tag{5}\n\\]\nEl mínimo global se encuentra en \\((x_1, x_2) = (0, 0)\\), donde \\(f(0, 0) = 0\\).\nEn dos dimensiones, la función de Rastrigin presenta una superficie caracterizada por un patrón ondulatorio regular de picos y valles, con el mínimo global situado en el centro del dominio.\nLa Figura 3 muestra una visualización 3D interactiva de la función de Rastrigin en dos dimensiones que se puede mover haciendo clic sostenido con el mouse. En esta representación, se observa cómo los mínimos locales forman un patrón de cuadrícula regular, creando una superficie que se asemeja a un “tablero de huevos” con numerosas depresiones. Esta característica multimodal es inherente a la función de Rastrigin y presenta un desafío significativo para los algoritmos de optimización.\n\n\nCode\nlibrary(plotly)\n\n# Definir la función de Rastrigin en 2D\nrastrigin_2d &lt;- function(x, y, a=10) {\n  a*2 + (x^2 - a*cos(2*pi*x)) + (y^2 - a*cos(2*pi*y))\n}\n\n# Crear la malla de puntos (usar número impar para incluir 0 exactamente)\nx_seq &lt;- seq(-5.12, 5.12, length.out = 301)\ny_seq &lt;- seq(-5.12, 5.12, length.out = 301)\ngrid &lt;- expand.grid(x = x_seq, y = y_seq)\n\n# Evaluar la función en cada punto\ngrid$z &lt;- with(grid, rastrigin_2d(x, y))\n\n# Matriz para gráfico 3D\nz_matrix &lt;- matrix(grid$z, nrow = length(x_seq), byrow = TRUE)\n\n# Valor exacto en el mínimo global\nz_min &lt;- rastrigin_2d(0, 0)\n\n# Gráfico 3D interactivo con plotly\nfig_3d &lt;- plot_ly(\n  x = ~x_seq, y = ~y_seq, z = ~z_matrix\n) %&gt;%\n  add_surface() %&gt;%\n  layout(\n    title = \"Función de Rastrigin (3D)\",\n    scene = list(\n      xaxis = list(title = \"x1\", range = c(min(x_seq), max(x_seq))),\n      yaxis = list(title = \"x2\", range = c(min(y_seq), max(y_seq))),\n      zaxis = list(title = \"f(x1, x2)\")\n    )\n  ) %&gt;%\n  add_markers(\n    x = 0, y = 0, z = z_min,\n    marker = list(color = 'red', size = 5),\n    name = \"Mínimo global\"\n  )\n\nfig_3d\n\n\n\n\n\n\nFigura 3. Representación gráfica de la función de Rastrigin.\nLa Figura 4 muestra el gráfico de contorno de la función de Rastrigin. En esta visualización, se revelan anillos concéntricos alrededor del mínimo global, con pequeñas depresiones distribuidas uniformemente. Esta estructura regular de óptimos locales hace que los algoritmos de optimización basados en gradiente queden frecuentemente atrapados lejos del óptimo global, convirtiéndola en una excelente función de prueba para métodos de optimización global.\n\n\nCode\nlibrary(ggplot2)\nlibrary(viridis)\n\n# Usar la misma cuadrícula y valores calculados en el chunk anterior (grid)\n\n# Gráfico de contorno con relleno de color y líneas de nivel\ncontour_plot &lt;- ggplot(grid, aes(x = x, y = y, z = z)) +\n  geom_contour_filled(bins = 30) +                # Áreas coloreadas\n  geom_contour(color = \"black\", alpha = 0.3, bins = 30) +  # Líneas de nivel\n  geom_point(aes(x = 0, y = 0), color = \"red\", size = 3) + # Mínimo global\n  scale_fill_viridis_d(option = \"viridis\") +                 # Paleta viridis\n  coord_fixed(ratio = 1) +\n  xlim(min(x_seq), max(x_seq)) +\n  ylim(min(y_seq), max(y_seq)) +\n  labs(title = \"Gráfico de contorno coloreado de la función de Rastrigin\",\n       x = \"x1\", y = \"x2\", fill = \"f(x1, x2)\") +\n  theme_minimal()\n\nprint(contour_plot)\n\n\n\n\n\n\n\n\n\nFigura 4. Gráfico de Contorno de la función de Rastrigin.\nEn tres dimensiones, la función se expresa como:\n\\[f(x_1, x_2, x_3) = 30 + x_1^2 - 10\\cos(2\\pi x_1) + x_2^2 - 10\\cos(2\\pi x_2) + x_3^2 - 10\\cos(2\\pi x_3) \\tag{6}\\]\ny el mínimo global se entra en \\((x_1, x_2, x_3) = (0, 0, 0)\\), donde \\(f(0, 0, 0) = 0\\).\nEn tres dimensiones, la función mantiene su característica multimodal, con numerosos mínimos locales distribuidos regularmente, lo que incrementa la dificultad para los algoritmos de encontrar el óptimo global.\n\nCon ambas funciones se realizarán experimentos en espacios de dos y tres dimensiones para analizar el comportamiento de los algoritmos en diferentes niveles de complejidad."
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#métodos-de-optimización",
    "href": "posts/Optimizacion-numerica/index.html#métodos-de-optimización",
    "title": "Optimización Numérica",
    "section": "2.2 Métodos de Optimización",
    "text": "2.2 Métodos de Optimización\n\n2.2.1 Descenso por Gradiente\nEl descenso del gradiente es un algoritmo iterativo que busca encontrar el mínimo local de una función diferenciable, desplazándose en la dirección opuesta al gradiente de la función en cada punto, el cual indica la pendiente de mayor incremento (Bishop, 2006). Lo anterior se basa en el hecho de que el gradiente apunta en la dirección de máximo crecimiento, y desplazarse opuesto a este es apuntar en la dirección de mínimo crecfimiento. Este método puede quedar atrapado en mínimos locales, especialmente en funciones multimodales como Rastrigin (Törn & Žilinskas, 1989).\nPara una función \\(f(\\mathbf{x})\\), con \\(\\mathbf{x} = (x_1, x_2, \\dots, x_N)\\), la actualización iterativa se expresa como:\n\\[\nx_{t+1} = x_t - \\eta \\nabla f(x_t) \\tag{7}\n\\]\ndonde\n- \\(\\mathbf{x}_t\\) es el vector de variables en la iteración \\(t\\), - \\(\\eta\\) es la tasa de aprendizaje,\n\n\\(\\nabla f(\\mathbf{x}_t)\\) es el vector gradiente en \\(\\mathbf{x}_t\\).\n\nEn el caso de dos dimensiones el gradiente es un vector de derivadas parciales:\n\\[\n\\nabla f(x_1, x_2) = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\end{bmatrix} \\tag{8}\n\\]\nCuando el gradiente analítico no está disponible o es complejo de calcular, se puede aproximar numéricamente usando diferencias centrales simétricas, que ofrecen mayor precisión que las diferencias hacia adelante o hacia atrás (Goodfellow, Bengio & Courville, 2016). Para una función \\(f(x_1, x_2)\\), las derivadas parciales se aproximan como:\n\\[\n\\frac{\\partial f}{\\partial x_1} \\approx \\frac{f(x_1 + h, x_2) - f(x_1 - h, x_2)}{2h} \\tag{9}\n\\]\n\\[\n\\frac{\\partial f}{\\partial x_2} \\approx \\frac{f(x_1, x_2 + h) - f(x_1, x_2 - h)}{2h} \\tag{10}\n\\]\ndonde \\(h\\) es un pequeño incremento (e.g., \\(10^{-7}\\) o menor).\nEl método del gradiente descendente puede visualizarse como el proceso de una persona que desciende por la superficie de una colina, donde la forma de la colina representa la función objetivo. El punto de partida corresponde a la posición inicial, y la tasa de aprendizaje es análoga a la magnitud de cada paso en el descenso. Si la tasa de aprendizaje es demasiado elevada, el algoritmo puede saltar sobre valles o incluso alejarse del mínimo, mientras que una tasa demasiado baja puede hacer que el avance sea excesivamente lento. Por ello, la eficiencia del gradiente descendente depende críticamente de:\n\nTasa de aprendizaje: Un valor muy grande puede provocar divergencia, mientras que uno muy pequeño ralentiza la convergencia.\nPunto inicial: La ubicación desde la que se inicia el algoritmo afecta la trayectoria y la probabilidad de alcanzar el mínimo global.\nCriterio de parada: Es fundamental definir cuándo detener el proceso, ya sea al alcanzar un número máximo de iteraciones o cuando la mejora entre pasos sucesivos sea insignificante, indicando convergencia.\n\nEsta analogía y consideraciones son ampliamente discutidas en la literatura sobre aprendizaje automático (Zhang et al., 2024; Bishop, 2006)."
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#métodos-bioinspirados",
    "href": "posts/Optimizacion-numerica/index.html#métodos-bioinspirados",
    "title": "Optimización Numérica",
    "section": "2.3 Métodos Bioinspirados",
    "text": "2.3 Métodos Bioinspirados\nLos algoritmos evolutivos, la optimización por enjambre de partículas (PSO) y la evolución diferencial (DE) son métodos heurísticos inspirados en procesos naturales. Estos algoritmos exploran el espacio de soluciones mediante mecanismos aleatorios y reglas flexibles, permitiendo escapar de mínimos locales y abordar problemas complejos (Goodfellow et al., 2016; Zhang et al., 2023).\nLos algoritmos evolutivos constituyen una familia de métodos de optimización inspirados en los procesos de selección natural y evolución biológica. Estos algoritmos emplean mecanismos como la selección, el cruzamiento y la mutación para explorar el espacio de soluciones y mejorar progresivamente la calidad de las mismas a lo largo de generaciones. Entre los algoritmos evolutivos, el algoritmo genético (GA) es uno de los más populares y ampliamente utilizados, debido a su simplicidad y eficacia en la búsqueda de óptimos en problemas complejos y multimodales. En este trabajo, se eligió el algoritmo genético como representante de los métodos evolutivos para comparar su desempeño frente a técnicas clásicas como el descenso por gradiente, aprovechando su capacidad para escapar de mínimos locales y abordar funciones objetivo con paisajes irregulares o múltiples óptimos.\n\n2.3.1 Algoritmos Genéticos (GA) en Optimización Numérica\nLos algoritmos genéticos (Genetic Algorithms, GA) son métodos de optimización bioinspirados que emulan los principios de la selección natural y la evolución biológica, propuestos inicialmente por John Holland en la década de 1970 (Holland, 1975). Los GA han demostrado ser efectivos para abordar problemas complejos de optimización, especialmente cuando las funciones objetivo presentan múltiples mínimos locales o carecen de derivadas analíticas, como ocurre con muchas funciones de prueba en optimización numérica (Goodfellow et al., 2016; Zhang et al., 2023).\nEn el contexto de la optimización numérica, los GA destacan por su capacidad para explorar espacios de búsqueda de alta dimensión y escapar de mínimos locales, superando así algunas limitaciones de los métodos clásicos basados en gradiente. Esto los hace especialmente útiles en funciones como Rosenbrock y Rastrigin, que presentan valles angostos o paisajes multimodales, respectivamente.\n\n2.3.1.1 Componentes clave de un Algoritmo Genético\n\nRepresentación cromosómica: Cada solución candidata se codifica como un cromosoma, que en el caso de funciones continuas suele ser un vector de números reales que representa una posición en el espacio de búsqueda (Zhang et al., 2024).\nFunción de aptitud (fitness): Evalúa la calidad de cada solución. Para problemas de minimización, la aptitud puede definirse como el valor negativo de la función objetivo, de modo que soluciones con menor valor de la función objetivo tengan mayor aptitud.\nOperadores genéticos:\n\nSelección: Favorece la reproducción de individuos con mayor aptitud, utilizando métodos como la selección por torneo o la ruleta (Holland, 1975).\nCruzamiento (crossover): Combina segmentos de dos padres para generar descendencia, permitiendo explorar nuevas regiones del espacio de búsqueda (Gonçalves et al., 2005).\nMutación: Introduce cambios aleatorios en los cromosomas para mantener la diversidad genética y evitar la convergencia prematura (Villalba Fernández de Castro, 2004).\n\n\nEl algoritmo opera sobre una población de soluciones candidatas, que evoluciona iterativamente mediante los operadores mencionados. El objetivo es mejorar progresivamente la aptitud de las soluciones a lo largo de las generaciones, acercándose al mínimo global de la función objetivo (Goodfellow et al., 2016).\n\n\n2.3.1.2 Evaluación de la calidad de la solución\nLa evaluación de la calidad de las soluciones obtenidas mediante GA en funciones de prueba numéricas requiere considerar dos aspectos fundamentales:\n\nConvergencia del fitness: Se monitorea el historial del valor de la función objetivo a lo largo de las generaciones. Una estabilización del valor en un rango reducido (por ejemplo, variaciones menores al 0.5% en 50 generaciones consecutivas) sugiere que el algoritmo ha alcanzado un óptimo local o global (Gonçalves et al., 2005).\nReproducibilidad: Ejecuciones independientes con diferentes semillas aleatorias deben producir soluciones de calidad comparable, lo que indica la robustez del algoritmo frente a la estocasticidad inherente a los GA (Zhang et al., 2024).\n\nDebido a la naturaleza estocástica de los GA y la complejidad de las funciones de prueba seleccionadas, no siempre es posible garantizar la obtención del óptimo global. Sin embargo, los GA permiten aproximarse a soluciones de alta calidad en tiempos computacionales razonables, especialmente en comparación con métodos deterministas que pueden verse atrapados en mínimos locales o requerir el cálculo exacto de derivadas.\nEn síntesis, los algoritmos genéticos constituyen una herramienta versátil y robusta para la optimización numérica de funciones complejas, complementando a los métodos clásicos y ampliando el abanico de estrategias disponibles para abordar problemas relevantes en inteligencia artificial y aprendizaje automático.\n\n\n\n2.3.2 Optimización por Enjambre de Partículas (PSO)\nLa Optimización por Enjambre de Partículas (Particle Swarm Optimization, PSO) es un algoritmo metaheurístico inspirado en el comportamiento social de los enjambres, como bandadas de aves o cardúmenes de peces (Kennedy & Eberhart, 1995). En PSO, cada solución potencial se representa como una “partícula” en un espacio de búsqueda multidimensional. Cada partícula mantiene información sobre su posición actual, su velocidad y la mejor posición que ha encontrado hasta el momento (conocida como pbest). Además, cada partícula conoce la mejor posición global encontrada por todo el enjambre (gbest).\nEn cada iteración, las partículas ajustan su velocidad y posición basándose en su propia experiencia (su pbest) y en la experiencia del enjambre (el gbest). La actualización de la velocidad y posición se rige por las siguientes ecuaciones:\n\\[\nv_{i}(t+1) = w \\cdot v_{i}(t) + c_1 \\cdot r_1 \\cdot (pbest_i - x_i(t)) + c_2 \\cdot r_2 \\cdot (gbest - x_i(t)) \\tag{11}\n\\]\n\\[\nx_{i}(t+1) = x_i(t) + v_{i}(t+1) \\tag{12}\n\\]\ndonde:\n- \\(v_{i}(t)\\) es la velocidad de la partícula \\(i\\) en el tiempo \\(t\\),\n- \\(x_{i}(t)\\) es la posición de la partícula \\(i\\) en el tiempo \\(t\\),\n- \\(w\\) es el peso de inercia, que controla la influencia de la velocidad anterior,\n- \\(c_1\\) y \\(c_2\\) son los coeficientes de aceleración, que controlan la influencia de pbest y gbest, respectivamente,\n- \\(r_1\\) y \\(r_2\\) son números aleatorios uniformemente distribuidos en [0, 1],\n- \\(pbest_i\\) es la mejor posición encontrada por la partícula \\(i\\),\n- \\(gbest\\) es la mejor posición encontrada por todo el enjambre.\nPSO es un algoritmo relativamente simple de implementar y requiere pocos parámetros, lo que lo hace atractivo para una amplia variedad de problemas de optimización (Poli et al., 2007). Sin embargo, su desempeño puede ser sensible a la elección de los parámetros \\(w\\), \\(c_1\\) y \\(c_2\\), que deben ajustarse cuidadosamente para equilibrar la exploración y la explotación del espacio de búsqueda.\n\n\n2.3.3 Evolución Diferencial (DE)\nLa Evolución Diferencial (Differential Evolution, DE) es un algoritmo evolutivo que genera nuevos vectores de prueba mediante la combinación de vectores de la población actual (Storn & Price, 1997). DE es particularmente eficaz para optimizar funciones continuas no diferenciables y multimodales.\nEl algoritmo DE comienza con una población inicial de vectores aleatorios. En cada generación, para cada vector objetivo \\(x_i\\), se genera un vector mutante \\(v_i\\) mediante la siguiente ecuación:\n\\[\nv_i = x_{r1} + F \\cdot (x_{r2} - x_{r3}) \\tag{13}\n\\]\ndonde:\n- \\(x_{r1}\\), \\(x_{r2}\\) y \\(x_{r3}\\) son vectores aleatorios distintos de la población actual,\n- \\(F\\) es el factor de mutación, un parámetro que controla la amplificación de la diferencia entre los vectores.\nA continuación, se realiza un cruce (crossover) entre el vector objetivo \\(x_i\\) y el vector mutante \\(v_i\\) para generar un vector de prueba \\(u_i\\). El cruce se realiza con una probabilidad \\(CR\\):\n\\[\nu_{ij} = \\begin{cases} v_{ij} & \\text{si } rand(0,1) \\leq CR \\text{ o } j = j_{rand} \\\\ x_{ij} & \\text{en caso contrario} \\end{cases} \\tag{14}\n\\]\ndonde:\n- \\(u_{ij}\\) es el \\(j\\)-ésimo componente del vector de prueba \\(u_i\\),\n- \\(x_{ij}\\) es el \\(j\\)-ésimo componente del vector objetivo \\(x_i\\),\n- \\(v_{ij}\\) es el \\(j\\)-ésimo componente del vector mutante \\(v_i\\),\n- \\(rand(0,1)\\) es un número aleatorio uniformemente distribuido en [0, 1],\n- \\(CR\\) es la tasa de cruce, un parámetro que controla la proporción de componentes que se toman del vector mutante,\n- \\(j_{rand}\\) es un índice aleatorio elegido para asegurar que al menos un componente del vector mutante se incluya en el vector de prueba.\nFinalmente, el vector de prueba \\(u_i\\) se compara con el vector objetivo \\(x_i\\), y el mejor de los dos se selecciona para la siguiente generación. Este proceso se repite hasta que se alcanza un criterio de parada, como un número máximo de generaciones o una tolerancia en la mejora de la función objetivo.\nDE es conocido por su robustez y su capacidad para encontrar soluciones óptimas en problemas complejos, con una convergencia relativamente rápida (Das & Suganthan, 2011)."
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#proceso-experimental",
    "href": "posts/Optimizacion-numerica/index.html#proceso-experimental",
    "title": "Optimización Numérica",
    "section": "3.1 Proceso Experimental",
    "text": "3.1 Proceso Experimental\nEl procedimiento seguido para resolver la optimización de las funciones de prueba fue el siguiente:\n\nDefinición de las funciones objetivo: Se implementaron las funciones de Rosenbrock y Rastrigin en R, considerando sus formulaciones estándar y los rangos de búsqueda recomendados en la literatura (Zhang et al., 2024).\nConfiguración de experimentos: Para cada función y dimensión (2D y 3D), se realizaron optimizaciones independientes utilizando descenso por gradiente, GA, PSO y DE. Las condiciones iniciales fueron seleccionadas aleatoriamente dentro del dominio permitido.\nImplementación de los algoritmos:\n\nDescenso por gradiente: Se utilizó una versión con gradiente numérico, ajustando la tasa de aprendizaje y el número máximo de iteraciones para cada función.\nAlgoritmo genético (GA): Se empleó la librería GA de R, configurando la población, número de generaciones y operadores genéticos estándar.\nPSO y DE: Se utilizaron las librerías pso y DEoptim, respectivamente, ajustando los parámetros principales para cada función.\n\nVisualización y análisis: Se graficó la evolución del valor de la función objetivo a lo largo de las iteraciones/generaciones y se compararon los resultados finales alcanzados por cada método.\nVerificación de la calidad de la solución: Se analizaron la convergencia, la estabilidad y la reproducibilidad de los resultados, repitiendo los experimentos con diferentes semillas aleatorias."
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#visualización-de-las-funciones",
    "href": "posts/Optimizacion-numerica/index.html#visualización-de-las-funciones",
    "title": "Optimización Numérica",
    "section": "3.2 Visualización de las Funciones",
    "text": "3.2 Visualización de las Funciones\nA continuación, se muestran las visualizaciones de las funciones de Rosenbrock y Rastrigin en dos dimensiones, lo que permite apreciar la dificultad inherente a cada función para los algoritmos de optimización.\nLa Figura 5 muestra una visualización interactiva de la superficie de la función de Rosenbrock en dos dimensiones que se puede mover haciendo clic sostenido con el mouse.\n\n\nCode\nlibrary(plotly)\n\n# Definir la función de Rosenbrock para dos variables\nrosenbrock &lt;- function(v, a = 1, b = 100) {\n  x &lt;- v[1]\n  y &lt;- v[2]\n  (a - x)^2 + b * (y - x^2)^2\n}\n\n\nx_seq &lt;- seq(-2.5, 2.5, length.out = 200)\ny_seq &lt;- seq(-1, 3, length.out = 200)\ngrid &lt;- expand.grid(x = x_seq, y = y_seq)\ngrid$z &lt;- with(grid, rosenbrock(x, y))\nz_matrix &lt;- matrix(grid$z, nrow = length(x_seq), byrow = FALSE)\n\nplot_ly(\n  x = ~x_seq, y = ~y_seq, z = ~z_matrix\n) %&gt;%\n  add_surface() %&gt;%\n  add_markers(x = 1, y = 1, z = rosenbrock(1, 1), marker = list(color = 'red', size = 5), name = \"Mínimo global\") %&gt;%\n  layout(\n    title = \"Función de Rosenbrock (2D, 3D plot)\",\n    scene = list(\n      xaxis = list(title = \"x1\"),\n      yaxis = list(title = \"x2\"),\n      zaxis = list(title = \"f(x1, x2)\")\n    )\n  )\n\n\n\n\n\n\nFigura 5. Superficie de la función de Rosenbrock en dos dimensiones (interactiva).\nLa Figura 6 muestra una visualización interactiva de la superficie de la función de Rastrigin en dos dimensiones que se puede mover haciendo clic sostenido con el mouse.\n\n\nCode\n# Definir la función de rastrigin\nrastrigin &lt;- function(v, a = 10) {\n  n &lt;- length(v)\n  a * n + sum(v^2 - a * cos(2 * pi * v))\n}\n\n\nrastrigin_2d &lt;- function(x, y) {\n20 + (x^2 - 10 * cos(2 * pi * x)) + (y^2 - 10 * cos(2 * pi * y))\n}\n\nx_seq &lt;- seq(-5.12, 5.12, length.out = 200)\ny_seq &lt;- seq(-5.12, 5.12, length.out = 200)\ngrid_ras &lt;- expand.grid(x = x_seq, y = y_seq)\ngrid_ras$z &lt;- with(grid_ras, rastrigin_2d(x, y))\nz_matrix_ras &lt;- matrix(grid_ras$z, nrow = length(x_seq), byrow = TRUE)\n\nplot_ly(\nx = ~x_seq, y = ~y_seq, z = ~z_matrix_ras\n) %&gt;%\nadd_surface() %&gt;%\nadd_markers(x = 0, y = 0, z = rastrigin_2d(0, 0), marker = list(color = 'red', size = 5), name = \"Mínimo global\") %&gt;%\nlayout(\ntitle = \"Función de Rastrigin (2D, 3D plot)\",\nscene = list(\nxaxis = list(title = \"x1\"),\nyaxis = list(title = \"x2\"),\nzaxis = list(title = \"f(x1, x2)\")\n)\n)\n\n\n\n\n\n\nFigura 6. Superficie de la función de Rastrigin en dos dimensiones (interactiva)."
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#optimización-con-descenso-por-gradiente",
    "href": "posts/Optimizacion-numerica/index.html#optimización-con-descenso-por-gradiente",
    "title": "Optimización Numérica",
    "section": "3.3 Optimización con Descenso por Gradiente",
    "text": "3.3 Optimización con Descenso por Gradiente\nSe implementó el descenso por gradiente utilizando derivadas numéricas para aproximar el gradiente en cada punto. Se realizaron múltiples ejecuciones con condiciones iniciales aleatorias para ambas funciones y dimensiones.\nLa Tabla 1 muestra un resultado típico de descenso por gradiente para la función de Rosenbrock en dos dimensiones.\nTabla 1. Resultado típico de descenso por gradiente para la función de Rosenbrock en dos dimensiones.\n\n\nCode\npartial_derivative &lt;- function(x0, func, i, h = 1e-7, ...) {\n  e &lt;- rep(0, length(x0))\n  e[i] &lt;- 1\n  (func(x0 + h * e, ...) - func(x0 - h * e, ...)) / (2 * h)\n}\n\nnumerical_gradient &lt;- function(x0, func, h = 1e-7, ...) {\n  sapply(seq_along(x0), function(i) partial_derivative(x0, func, i, h, ...))\n}\n\ngradient_descent &lt;- function(x0, eta, func, h = 1e-7, max_iter = 1000, tol = 1e-6, ...) {\n  x &lt;- x0\n  history &lt;- list(x = list(), f = numeric())\n  for (i in 1:max_iter) {\n    grad &lt;- numerical_gradient(x, func, h, ...)\n    x_new &lt;- x - eta * grad\n    history$x[[i]] &lt;- x_new\n    history$f[i] &lt;- func(x_new, ...)\n    if (sqrt(sum((x_new - x)^2)) &lt; tol) break\n    x &lt;- x_new\n  }\n  data.frame(do.call(rbind, history$x), f = history$f)\n}\n\nset.seed(42)\nx0_rb &lt;- runif(2, -2, 2)\nhist_rb &lt;- gradient_descent(x0_rb, eta = 0.002, func = rosenbrock)\ntail(hist_rb, 1)\n\n\n\n  \n\n\n\n\n3.3.1 Animación del Descenso por Gradiente en la función Rosenbrock\nLa Figura 7 muestra una animación del proceso iterativo del descenso por gradiente optimizando la función de Rosenbrock en dos dimensiones.\n\nFigura 7. Animación del proceso iterativo del descenso por gradiente optimizando la función de Rosenbrock en dos dimensiones.\n¿Por qué el algoritmo no llega a la solución ideal (1,1)?\nEl GIF evidencia claramente el desafío que representa la optimización de la función de Rosenbrock mediante descenso por gradiente. A pesar de tratarse de una función unimodal, su forma estrecha y alargada —con un valle curvo que conduce al mínimo global en (1,1)— dificulta el avance directo hacia la solución óptima.\nEn el video, se observa cómo el algoritmo, iniciado lejos del mínimo, avanza lentamente y realiza correcciones graduales de dirección para intentar seguir la curvatura del valle. Este comportamiento es característico de funciones mal condicionadas, donde el gradiente apunta en direcciones muy inclinadas y la tasa de aprendizaje debe ser cuidadosamente ajustada para evitar oscilaciones o estancamientos.\nLa animación permite visualizar cómo el descenso por gradiente se adapta a la geometría del problema, pero también cómo puede requerir muchas iteraciones para acercarse a la solución cuando el paisaje es estrecho y curvado, como en este caso. Esto resalta la importancia de técnicas como preacondicionamiento, tasas de aprendizaje adaptativas, o el uso de algoritmos más robustos cuando se optimizan funciones con topologías complejas.\nLa Tabla 2 muestra un resultado típico de descenso por gradiente para la función de Rastrigin en 2D.\nTabla 2. Resultado típico de descenso por gradiente para la función de Rastrigin en 2D.\n\n\nCode\nset.seed(100)\nx0_ras &lt;- runif(2, -5, 5)\nhist_ras &lt;- gradient_descent(x0_ras, eta = 0.01, func = rastrigin)\ntail(hist_ras, 1)\n\n\n\n  \n\n\n\n\n\n3.3.2 Animación del Descenso por Gradiente en la función Rastrigin\nLa Figura 8 muestra una animación del proceso iterativo del descenso por gradiente optimizando la función de Rastrigin en dos dimensiones.\n\nFigura 8. Animación del proceso iterativo del descenso por gradiente optimizando la función de Rastrigin en dos dimensiones.\n¿Por qué el algoritmo no llega a la solución ideal (0,0)?\nLa principal razón es que la función de Rastrigin es altamente multimodal, es decir, presenta una gran cantidad de mínimos locales además del mínimo global ubicado en (0,0). Cuando se aplica el descenso por gradiente, el algoritmo tiende a detenerse en el mínimo local más cercano al punto de inicio, especialmente si se utiliza un paso fijo y un criterio de parada basado en la norma del gradiente."
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#optimización-con-algoritmos-heurísticos",
    "href": "posts/Optimizacion-numerica/index.html#optimización-con-algoritmos-heurísticos",
    "title": "Optimización Numérica",
    "section": "3.4 Optimización con Algoritmos Heurísticos",
    "text": "3.4 Optimización con Algoritmos Heurísticos\nA continuación, se presentan los resultados de los algoritmos heurísticos implementados en R. Los parámetros de cada algoritmo se ajustaron experimentalmente para lograr una buena convergencia en ambas funciones.\n\n3.4.1 Algoritmo Genético (GA)\nLa Tabla 3 muestestra la mejor solución encontrada por GA para la función de Rosenbrock en dos dimensiones.\nTabla 3. Mejor solución encontrada por el algoritmo genético para la función de Rosenbrock en dos dimensiones.\n\n\nCode\nlibrary(GA)\nga_rb &lt;- ga(\ntype = \"real-valued\",\nfitness = function(x) -rosenbrock(x),\nlower = c(-2, -1), upper = c(2.5, 3),\npopSize = 40, maxiter = 150, run = 50, seed = 123\n)\nga_rb@solution\n\n\n            x1        x2\n[1,] 0.7667619 0.5854716\n\n\nCode\n-ga_rb@fitnessValue\n\n\n[1] 0.05500134\n\n\n\n\n3.4.2 Optimización por Enjambre de Partículas (PSO)\nLa Tabla 4 muestra la mejor solución encontrada por PSO para la función de Rosenbrock en dos dimensiones.\nTabla 4. Mejor solución encontrada por PSO para la función de Rosenbrock en dos dimensiones.\n\n\nCode\nlibrary(pso)\npso_rb &lt;- psoptim(\npar = c(0, 0),\nfn = rosenbrock,\nlower = c(-2, -1), upper = c(2.5, 3),\ncontrol = list(maxit = 150, s = 30, trace = 0)\n)\npso_rb$par\n\n\n[1] 0.9999371 0.9998742\n\n\nCode\npso_rb$value\n\n\n[1] 3.958886e-09\n\n\n\n\n3.4.3 Evolución Diferencial (DE)\nLa Tabla 5 muestra la mejor solución encontrada por DE para la función de Rosenbrock en dos dimensiones.\nTabla 5. Mejor solución encontrada por DE para la función de Rosenbrock en dos dimensiones.\n\n\nCode\nlibrary(DEoptim)\nde_rb &lt;- DEoptim(\nfn = rosenbrock,\nlower = c(-2, -1), upper = c(2.5, 3),\ncontrol = DEoptim.control(itermax = 150, NP = 40, trace = FALSE)\n)\nde_rb$optim$bestmem\n\n\npar1 par2 \n   1    1 \n\n\nCode\nde_rb$optim$bestval\n\n\n[1] 5.794879e-20"
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#comparación-de-resultados",
    "href": "posts/Optimizacion-numerica/index.html#comparación-de-resultados",
    "title": "Optimización Numérica",
    "section": "3.5 Comparación de Resultados",
    "text": "3.5 Comparación de Resultados\nLos métodos de descenso por gradiente demostraron rapidez y precisión en funciones suaves y unimodales, alcanzando valores muy cercanos al mínimo global con pocas evaluaciones. Sin embargo, su desempeño disminuye notablemente en funciones multimodales, donde tienden a quedar atrapados en mínimos locales. Por el contrario, los métodos heurísticos, aunque requieren un mayor número de evaluaciones, mostraron una mayor capacidad para explorar el espacio de búsqueda y evitar mínimos locales, logrando mejores soluciones en funciones complejas. Estas diferencias se confirmaron mediante múltiples ejecuciones con condiciones iniciales aleatorias, evidenciando la robustez y estabilidad de los métodos bioinspirados frente a la sensibilidad del descenso por gradiente.\nSe realizaron múltiples ejecuciones para cada algoritmo y función, y se registraron los mejores valores alcanzados, así como el número de evaluaciones de la función objetivo. Los resultados típicos se resumen en la Tabla 6.\nTabla 6. Comparación de resultados típicos de los métodos de optimización.\n\n\nCode\nlibrary(knitr)\nlibrary(kableExtra)\n\n# Crear el data frame con los datos de la tabla\ntabla_resultados &lt;- data.frame(\n  Método = c(\"Descenso Gradiente\", \"Descenso Gradiente\", \"GA\", \"PSO\", \"DE\"),\n  Función = c(\"Rosenbrock\", \"Rastrigin\", \"Rosenbrock\", \"Rosenbrock\", \"Rosenbrock\"),\n  Dimensión = c(\"2\", \"2\", \"2\", \"2\", \"2\"),\n  `Mejor valor típico` = c(\"~$10^{-5}$\", \"8\", \"~$10^{-3}$\", \"~$10^{-4}$\", \"~$10^{-5}$\"),\n  `Nº evaluaciones` = c(\"200-500\", \"200-500\", \"6000-10000\", \"3000-6000\", \"3000-6000\"),\n  Observaciones = c(\n    \"Rápido si el inicio es bueno\",\n    \"Suele quedar atrapado en mínimos\",\n    \"Explora más, pero menos preciso\",\n    \"Buen equilibrio exploración/explotación\",\n    \"Robusto, converge bien\"\n  ),\n  check.names = FALSE,\n  stringsAsFactors = FALSE\n)\n\nknitr::kable(\n  tabla_resultados,\n  col.names = c(\"Método\", \"Función\", \"Dimensión\", \"Mejor valor típico\", \"Nº evaluaciones\", \"Observaciones\"),\n  escape = FALSE,  # importante para que no escape los símbolos LaTeX\n) %&gt;%\n  kableExtra::kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n    full_width = FALSE,\n    position = \"center\"\n  ) %&gt;%\n  kableExtra::column_spec(1, bold = TRUE, width = \"12em\") %&gt;%\n  kableExtra::column_spec(2, width = \"10em\") %&gt;%\n  kableExtra::column_spec(3, width = \"6em\") %&gt;%\n  kableExtra::column_spec(4, width = \"10em\") %&gt;%\n  kableExtra::column_spec(5, width = \"10em\") %&gt;%\n  kableExtra::column_spec(6, width = \"18em\") %&gt;%\n  kableExtra::row_spec(0, bold = TRUE, color = \"white\", background = \"#4682B4\")\n\n\n\n\n\n\nMétodo\nFunción\nDimensión\nMejor valor típico\nNº evaluaciones\nObservaciones\n\n\n\n\nDescenso Gradiente\nRosenbrock\n2\n~$10^{-5}$\n200-500\nRápido si el inicio es bueno\n\n\nDescenso Gradiente\nRastrigin\n2\n8\n200-500\nSuele quedar atrapado en mínimos\n\n\nGA\nRosenbrock\n2\n~$10^{-3}$\n6000-10000\nExplora más, pero menos preciso\n\n\nPSO\nRosenbrock\n2\n~$10^{-4}$\n3000-6000\nBuen equilibrio exploración/explotación\n\n\nDE\nRosenbrock\n2\n~$10^{-5}$\n3000-6000\nRobusto, converge bien\n\n\n\n\n\n\n\n\nNota: Los métodos heurísticos requieren más evaluaciones de la función objetivo, pero son menos sensibles a la condición inicial y pueden escapar de mínimos locales, lo cual es especialmente ventajoso en funciones multimodales como Rastrigin."
  },
  {
    "objectID": "posts/Optimizacion-numerica/index.html#análisis-de-convergencia-y-robustez",
    "href": "posts/Optimizacion-numerica/index.html#análisis-de-convergencia-y-robustez",
    "title": "Optimización Numérica",
    "section": "3.6 Análisis de Convergencia y Robustez",
    "text": "3.6 Análisis de Convergencia y Robustez\nEn general, el descenso por gradiente mostró una rápida convergencia en la función de Rosenbrock cuando la condición inicial estaba cerca del mínimo global, pero tuvo dificultades en la función de Rastrigin debido a la presencia de múltiples mínimos locales. Los algoritmos heurísticos, en cambio, lograron encontrar soluciones cercanas al óptimo global en ambos casos, aunque a costa de un mayor número de evaluaciones. La evolución diferencial se destacó por su robustez y capacidad de convergencia en ambas funciones, mientras que PSO y GA ofrecieron buenos resultados, especialmente en términos de exploración del espacio de búsqueda.\nPara evaluar la robustez, se repitieron los experimentos con diferentes semillas aleatorias, observando que los métodos heurísticos presentaron menor variabilidad en la calidad de la solución final en comparación con el descenso por gradiente, que puede verse muy afectado por la elección de la condición inicial.\n\nEn la siguiente sección se presentan las conclusiones generales del estudio y recomendaciones para la selección de métodos de optimización en función de la naturaleza del problema."
  },
  {
    "objectID": "posts/Bienvenida/index.html#por-qué-este-enfoque",
    "href": "posts/Bienvenida/index.html#por-qué-este-enfoque",
    "title": "Bienvenidos a nuestro Blog",
    "section": "¿Por qué este enfoque?",
    "text": "¿Por qué este enfoque?\nLos algoritmos inspirados en la naturaleza no solo son poderosos: también nos invitan a mirar la inteligencia desde una perspectiva diferente. Comprender cómo el cerebro aprende, cómo una colonia de hormigas optimiza su comportamiento, o cómo los genes evolucionan en poblaciones puede darnos ideas innovadoras para resolver problemas complejos en ciencia, ingeniería y sociedad."
  },
  {
    "objectID": "posts/Bienvenida/index.html#a-quién-está-dirigido-este-blog",
    "href": "posts/Bienvenida/index.html#a-quién-está-dirigido-este-blog",
    "title": "Bienvenidos a nuestro Blog",
    "section": "¿A quién está dirigido este Blog?",
    "text": "¿A quién está dirigido este Blog?\nEste blog está dirigido a todas las personas interesadas en aprender de una manera teórica, pero también práctica como funcionan los modelos inspirados en la inteligencia natural. Es un blog hecho por estudiantes para estudiantes."
  },
  {
    "objectID": "posts/Bienvenida/index.html#porque-son-importantes-los-algoritmos-bioinspirados",
    "href": "posts/Bienvenida/index.html#porque-son-importantes-los-algoritmos-bioinspirados",
    "title": "Bienvenidos a nuestro Blog",
    "section": "¿Porque son importantes los algoritmos bioinspirados?",
    "text": "¿Porque son importantes los algoritmos bioinspirados?\nExisten muchos problemas que son muy caros computacionalmente y no pueden ser resueltos con fuerza bruta, pues demorarían días (¡o incluso años!), por eso se han buscado soluciones más óptimas que aunque tengan un pequeño margen de error, son mucho más rápidas.\n\nProblemas populares que se han abordado con algoritmos bioinspirados**\n🧭 1. **El problema del viajante (TSP)**\n🧠 2. **Diseño de arquitecturas de redes neuronales (Neuroevolution)**\n🚦 4. **Control de tráfico o sistemas multiagente**\n👁️ 5. **Visión artificial**\n\n\n\n¿Qué es Deep Learning?"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog de trabajos de la materia RNA",
    "section": "",
    "text": "Modelado de Riesgo Crediticio con Redes Neuronales\n\n\n\n\n\n\nRedes Neuronales\n\n\nRiesgo crediticio\n\n\nÁrbol de decisión\n\n\nModelación\n\n\nPython\n\n\n\n\n\n\n\n\n\nJun 12, 2024\n\n\nDiego Fernando Chávez Henao, dfchavez@unal.edu.co, Alejandro Feria González, aferiag@unal.edu.co, Santiago Molina Muñoz, smolinam@unal.edu.co, Juan Manuel Teherán Machado, jteheranm@unal.edu.co\n\n\n\n\n\n\n\n\n\n\n\n\nBienvenidos a nuestro Blog\n\n\n\n\n\n\nRedes Neuronales\n\n\nAlgoritmos Bioinspirados\n\n\nR\n\n\n\n\n\n\n\n\n\nMay 2, 2024\n\n\nDiego Fernando Chávez Henao, dfchavez@unal.edu.co, Alejandro Feria González, aferiag@unal.edu.co, Santiago Molina Muñoz, smolinam@unal.edu.co, Juan Manuel Teherán Machado, jteheranm@unal.edu.co\n\n\n\n\n\n\n\n\n\n\n\n\nOptimización Combinatoria\n\n\n\n\n\n\noptimización\n\n\nColonia de Hormigas\n\n\nAlgorítmos Genéticos\n\n\nR\n\n\n\n\n\n\n\n\n\nMay 2, 2024\n\n\nDiego Fernando Chávez Henao, dfchavez@unal.edu.co, Alejandro Feria González, aferiag@unal.edu.co, Santiago Molina Muñoz, smolinam@unal.edu.co, Juan Manuel Teherán Machado, jteheranm@unal.edu.co\n\n\n\n\n\n\n\n\n\n\n\n\nOptimización Numérica\n\n\n\n\n\n\noptimización\n\n\nGradiente descendente\n\n\nMétodos Heurísticos\n\n\nR\n\n\n\n\n\n\n\n\n\nMay 2, 2024\n\n\nDiego Fernando Chávez Henao, dfchavez@unal.edu.co, Alejandro Feria González, aferiag@unal.edu.co, Santiago Molina Muñoz, smolinam@unal.edu.co, Juan Manuel Teherán Machado, jteheranm@unal.edu.co\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Optimizacion-combinatoria/index.html",
    "href": "posts/Optimizacion-combinatoria/index.html",
    "title": "Optimización Combinatoria",
    "section": "",
    "text": "1 Introducción\n  2 Marco Teórico\n  \n  2.1 El Problema del Viajante de Comercio (TSP)\n  \n  2.1.1 Supuestos para el Salario\n  2.1.2 Supuestos paro los Peajes\n  2.1.3 Supuestos para el combustible\n  2.1.4 Matriz de Costos\n  \n  2.2 Algoritmos Genéticos (GA)\n  2.3 Algoritmo de Colonia de Hormigas (ACO)\n  \n  3 Resultados y Análisis\n  \n  3.1 Construcción de la Matriz de Costos\n  3.2 GA aplicado al TSP\n  \n  3.2.1 Implementación del GA aplicado al TSP\n  3.2.2 Visualización de resultados del GA aplicado al TSP\n  3.2.3 Recorrido óptimo animado mejor ruta GA\n  3.2.4 Verificación de la calidad de la solución del GA aplicado al TSP\n  \n  3.3 ACO aplicado al TSP\n  \n  3.3.1 Implementación del ACO aplicado al TSP\n  3.3.2 Visualización de resultados del ACO aplicado al TSP\n  3.3.3 Recorrido óptimo animado mejor ruta ACO\n  3.3.4 Verificación de la calidad de la solución del ACO aplicado al TSP\n  \n  3.4 Comparación entre el GA y ACO aplicados al TSG\n  \n  4 Conclusiones\n  5 Referencias\nENUCIADO DEL PROBLEMA\nUn vendedor debe hacer un recorrido por todas y cada de las 13 ciudades principales de Colombia.\nUtilice colonias de hormigas y algoritmos genéticos para encontrar el orden óptimo. El costo de desplazamiento entre ciudades es la suma del valor de la hora del vendedor (es un parámetro que debe estudiarse), el costo de los peajes y el costo del combustible. Cada equipo debe definir en qué carro hace el recorrido el vendedor y de allí extraer el costo del combustible.\nAdicionalmente represente con un gif animado o un video cómo se comporta la mejor solución usando un gráfico del recorrido en el mapa de Colombia."
  },
  {
    "objectID": "posts/Optimizacion-combinatoria/index.html#el-problema-del-viajante-de-comercio-tsp",
    "href": "posts/Optimizacion-combinatoria/index.html#el-problema-del-viajante-de-comercio-tsp",
    "title": "Optimización Combinatoria",
    "section": "2.1 El Problema del Viajante de Comercio (TSP)",
    "text": "2.1 El Problema del Viajante de Comercio (TSP)\nEl Problema del Viajante de Comercio (TSP, por sus siglas en inglés) es uno de los problemas más emblemáticos de la optimización combinatoria y de la investigación de operaciones. Consiste en encontrar la ruta de menor costo que permita a un viajante visitar una vez cada ciudad de un conjunto dado y regresar al punto de partida (Zhang et al., 2020). Este problema es NP-hard, lo que significa que el número de posibles rutas crece factorialmente con el número de ciudades, volviendo inviable la búsqueda exhaustiva para instancias de tamaño moderado (Goodfellow et al., 2016).\nMatemáticamente, el TSP se modela mediante un grafo completo donde cada nodo representa una ciudad y cada arista tiene un costo asociado (Goodfellow et al., 2016). Como ejemplo de costo asociado tenemos distancia, tiempo, dinero, etc. El objetivo es encontrar el ciclo hamiltoniano de menor costo, es decir, un camino que pase una única vez por cada ciudad, retorne al origen, y minimice la suma de los costos (Zhang et al., 2020).\n\n2.1.1 Supuestos para el Salario\nSe asume un valor monetario por hora de trabajo de $25.000 COP/hora, definido según parámetros del mercado laboral colombiano, Con este valor se puede estimar el costo del salario que debe pagarse al viajante por ir desde la ciudad \\(i\\) a la ciudad \\(j\\), mediante la siguiente expresión:\n\\(\\text{Costo del salario del viajante}_{ij} = V_h \\cdot T_{ij} \\tag{1}\\)\ndonde\n\n\\(V_h\\): Valor de la hora de trabajo del vendedor (COP/hora), asumido como $25.000 COP/hora\n\\(T_{ij}\\): Tiempo de viaje desde la ciudad \\(i\\) a la ciudad \\(j\\) (horas)\n\n\n\n2.1.2 Supuestos paro los Peajes\nColombia cuenta con 180 peajes en la red vial nacional (Infobae, 2025). Aunque existe un proyecto de ley para que los peajes no puedan ubicarse a menos de 150 kilómetros entre sí (Infobae, 2025), en la práctica la distancia promedio entre peajes es de 50 a 70 km. Por ejemplo, el trayecto Medellín–Bogotá (415 km) tiene 8 peajes, y el trayecto Cali–Barranquilla (1000 km) tiene 15 peajes.\nAsumiendo un peaje cada 60 km recorridos, se estima el número de peajes entre las ciudades \\(i\\) y \\(j\\) como:\n\\(P_{ij}= \\mathrm{Redondear}\\left(\\frac{\\text{Distancia (km)}}{60\\,\\text{km}}\\right) \\tag{2}\\)\nSuponiendo un costo promedio por peaje de $25.000 COP, el costo de los peajes entre las ciudades \\(i\\) y \\(j\\) se calcula como:\n\\(\\text{Costo de los peajes}_{ij} = P_{ij} \\cdot C_p \\tag{3}\\)\ndonde\n\n\\(P_{ij}\\): Número estimado de peajes entre las ciudades \\(i\\) y \\(j\\)\n\\(C_p\\): Costo promedio de cada peaje (COP), asumido como $25.000 COP\n\nEsta aproximación busca representar de forma razonable las condiciones actuales de la red vial colombiana y su impacto económico en los recorridos del viajante.\n\n\n2.1.3 Supuestos para el combustible\nPara este estudio se seleccionó el Chevrolet Spark GT, un vehículo compacto ampliamente utilizado en Colombia por su eficiencia en carretera y bajo costo operativo. Según especificaciones técnicas reportadas por C3 Care Car Center (2025) y Yahoo Finanzas (2025), este modelo ofrece un rendimiento promedio de 40 km/galón en condiciones reales de conducción interurbana, valor asumido para el cálculo de costos en este estudio.\nSegún Yahoo Finanzas (2025), el Spark GT combina eficiencia energética (hasta 20.7 km/L en carretera según pruebas homologadas) con una red nacional de soporte técnico, garantizando asistencia en las 13 ciudades contempladas en este estudio. Su diseño compacto facilita la movilidad en zonas urbanas (C3 Care Car Center, 2025), mientras que el rendimiento de 40 km/galón refleja condiciones reales de tráfico y carga (Ministerio de Minas y Energía, 2025).\nLos parámetros técnicos relevantes para este automóvil son:\n\nMotor: 1.2L DOHC de 4 cilindros, 80.5 HP y 108 Nm de torque (C3 Care Car Center, 2025).\nTransmisión: Mecánica, de 5 velocidades, optimizada para topografía colombiana (Yahoo Finanzas, 2025).\nCapacidad de carga: 402 kg, ideal para transporte de muestrarios comerciales (C3 Care Car Center, 2025).\n\nAsumiendo que el precio de la gasolina es de $16.259 COP por galón (Ministerio de Minas y Energía, 2025), el costo del combustible para desplazarse de la ciudad \\(i\\) a la ciudad \\(j\\) se estima como:\n\\(\\text{Costo del combustible}_{ij} = \\left( \\frac{D_{ij}}{R} \\right) \\cdot C_g  \\tag{4}\\)\ndonde\n\n\\(D_{ij}\\): Distancia entre las ciudades \\(i\\) y \\(j\\) (km)\n\\(R\\): Rendimiento del vehículo (km/galón), asumido como 40 km/galón\n\\(C_g\\): Costo del galón de gasolina (COP), asumido como $16.259 COP por galón\n\n\n\n2.1.4 Matriz de Costos\nLa matriz de costos \\(C\\) es una matriz cuadrada de tamaño \\(n \\times n\\), donde \\(n\\) es el número de ciudades, y cada elemento \\(C_{ij}\\), \\(i, j = 1, \\dots, n\\), representa el costo de desplazarse de la ciudad \\(i\\) a la ciudad \\(j\\), y se calcula como:\n\\(C_{ij} = \\text{Costo del salario del viajante}_{ij} + \\text{Costo de los peajes}_{ij} + \\text{Costo del combustible}_{ij}  \\tag{5}\\)\nGeneralmente, los elementos en la diagonal \\(C_{ii}\\) son cero o un valor muy alto para evitar que el vendedor permanezca en la misma ciudad. La matriz puede ser simétrica o asimétrica, dependiendo de si los costos de ida y regreso entre ciudades son iguales o diferentes (Zhang et al., 2024)."
  },
  {
    "objectID": "posts/Optimizacion-combinatoria/index.html#algoritmos-genéticos-ga",
    "href": "posts/Optimizacion-combinatoria/index.html#algoritmos-genéticos-ga",
    "title": "Optimización Combinatoria",
    "section": "2.2 Algoritmos Genéticos (GA)",
    "text": "2.2 Algoritmos Genéticos (GA)\nLos algoritmos genéticos (Genetic Algorithms, GA) son métodos de optimización bioinspirados que emulan los principios de la selección natural y la evolución biológica, propuestos inicialmente por John Holland en la década de 1970 (Holland, 1975). Los GA se han aplicado exitosamente a una amplia variedad de problemas complejos, especialmente aquellos donde los métodos exactos son demasiado costosos o inviables. Destacan en problemas combinatorios NP-hard, como el Problema del Viajante de Comercio (TSP), donde el espacio de soluciones crece factorialmente con el número de ciudades, volviendo impracticable la búsqueda exhaustiva (Villalba Fernández de Castro, 2004; Zhang et al., 2020).\nLa eficacia de los GA radica en su capacidad para equilibrar la explotación de soluciones prometedoras y la exploración de nuevas regiones del espacio de búsqueda mediante mecanismos estocásticos (Dorigo & Stützle, 2004).\nLos componentes clave de un algoritmo genético son:\n\nRepresentación cromosómica: Cada solución se codifica como un cromosoma, generalmente un vector que especifica el orden de visita de las ciudades (Zhang et al., 2024).\nFunción de aptitud (fitness): Evalúa la calidad de cada solución. Para el TSP, suele calcularse como el inverso o el negativo del costo total de la ruta (Zhang et al., 2020).\nOperadores genéticos:\n\nSelección: Prioriza individuos con mayor aptitud, utilizando métodos como la selección por torneo o ruleta (Holland, 1975).\nCruzamiento (crossover): Combina segmentos de dos padres para generar descendencia, empleando operadores como el order crossover para preservar permutaciones válidas (Gonçalves et al., 2005).\nMutación: Introduce cambios aleatorios, como el intercambio de dos ciudades, para mantener la diversidad genética (Villalba Fernández de Castro, 2004).\n\n\nEstos algoritmos operan sobre una población de soluciones candidatas (individuos o cromosomas), que evolucionan iterativamente mediante los operadores genéticos mencionados. El objetivo es mejorar progresivamente la aptitud (fitness) de las soluciones a lo largo de las generaciones (Goodfellow et al., 2016).\nEn el contexto del TSP, cada individuo representa una ruta que recorre todas las ciudades, y la función objetivo consiste en minimizar el costo total del recorrido. Debido a la naturaleza combinatoria del problema, los algoritmos genéticos ofrecen una estrategia eficiente para encontrar buenas soluciones aproximadas en tiempos razonables, aunque no garantizan hallar siempre la solución óptima. El proceso evolutivo permite que, generación tras generación, la población tienda a encontrar rutas cada vez más eficientes.\nVerificación de la calidad de la solución\nEvaluar la calidad de la solución obtenida es fundamental en el contexto del Problema del Viajante de Comercio (TSP), especialmente cuando se emplean métodos metaheurísticos como los algoritmos genéticos (GA). Los enfoques exactos, como la enumeración exhaustiva de todas las posibles rutas, resultan computacionalmente inviables debido al crecimiento factorial del número de combinaciones a medida que aumenta la cantidad de ciudades (Applegate et al., 2006; Zhang et al., 2020).\nAnte esta intratabilidad, se optó por aplicar un algoritmo genético, que permite aproximarse a soluciones de alta calidad mediante múltiples iteraciones y el ajuste de parámetros como el tamaño de la población y el número de generaciones (Mitchell, 1998). Los GA superan a los métodos exactos al reducir la complejidad computacional a \\(O(g \\cdot n)\\), donde \\(g\\) es el número de generaciones y \\(n\\) el tamaño de la población (Applegate et al., 2006).\nLa evaluación de la calidad de las soluciones obtenidas mediante GA en el TSP requiere abordar dos desafíos clave: la naturaleza estocástica del algoritmo y la imposibilidad de validar la optimalidad global en instancias grandes. Por ello, se emplean dos pilares fundamentales para la verificación:\n\nConvergencia del fitness: Se monitorea el historial del costo a través de las generaciones. Una estabilización de la función objetivo en un rango reducido (por ejemplo, variaciones menores al 0.5% en 50 generaciones consecutivas) sugiere proximidad a un óptimo local o global (Gonçalves et al., 2005).\nReproducibilidad: Ejecuciones independientes con diferentes semillas aleatorias deben generar soluciones de calidad comparable, lo que confirma la robustez del algoritmo (Zhang et al., 2020)."
  },
  {
    "objectID": "posts/Optimizacion-combinatoria/index.html#algoritmo-de-colonia-de-hormigas-aco",
    "href": "posts/Optimizacion-combinatoria/index.html#algoritmo-de-colonia-de-hormigas-aco",
    "title": "Optimización Combinatoria",
    "section": "2.3 Algoritmo de Colonia de Hormigas (ACO)",
    "text": "2.3 Algoritmo de Colonia de Hormigas (ACO)\nEl algoritmo de colonia de hormigas (Ant Colony Optimization, ACO) es una técnica de optimización bioinspirada en el comportamiento colectivo de las colonias de hormigas reales durante la búsqueda de alimento (Dorigo et al., 1996; Dorigo & Stützle, 2004). En la naturaleza, las hormigas encuentran caminos cortos entre su nido y una fuente de alimento depositando una sustancia química llamada feromona. A medida que más hormigas siguen un camino y lo refuerzan con feromonas, ese camino se vuelve más atractivo para otras hormigas, lo que conduce a una optimización distribuida y adaptativa.\nBasado en este principio, Marco Dorigo propuso en la década de 1990 el ACO como un algoritmo metaheurístico para resolver problemas combinatorios complejos, tales como el Problema del Viajante de Comercio (TSP), la programación de tareas y la planificación de rutas (Dorigo & Stützle, 2004).\nEn el contexto del TSP, cada hormiga construye una solución probabilísticamente, guiada por dos factores principales:\n\nLa intensidad de feromonas depositadas en los caminos (memoria colectiva).\nUna heurística local, generalmente el inverso del costo o la distancia entre ciudades.\n\nCada hormiga construye una solución completa seleccionando las ciudades a visitar con una probabilidad proporcional a estos dos factores. Tras cada iteración, el algoritmo actualiza las feromonas:\n\nEvaporando parte de la feromona para evitar la convergencia prematura.\nRefuerzando las rutas más exitosas depositando más feromona en los caminos que produjeron soluciones de bajo costo.\n\nEste mecanismo balancea la exploración (búsqueda de nuevas soluciones) y la explotación (refinamiento de soluciones prometedoras), permitiendo que el algoritmo encuentre soluciones cercanas al óptimo en problemas donde los métodos exactos son computacionalmente inviables (Dorigo et al., 1996; Dorigo & Stützle, 2004).\nEn este estudio, el ACO fue utilizado para resolver la instancia del TSP correspondiente a las 13 ciudades principales de Colombia, minimizando el costo total del trayecto, que incluye tiempo de desplazamiento, peajes y combustible. Mediante la configuración de parámetros clave como el número de hormigas, la importancia relativa de la heurística y la tasa de evaporación, el algoritmo logró encontrar soluciones estables y de bajo costo, comparables con las obtenidas mediante algoritmos genéticos."
  },
  {
    "objectID": "posts/Optimizacion-combinatoria/index.html#construcción-de-la-matriz-de-costos",
    "href": "posts/Optimizacion-combinatoria/index.html#construcción-de-la-matriz-de-costos",
    "title": "Optimización Combinatoria",
    "section": "3.1 Construcción de la Matriz de Costos",
    "text": "3.1 Construcción de la Matriz de Costos\nPara este estudio, se utilizó el portal Mejores Rutas (Mejores rutas Colombia, s.f.) para generar la matriz de distancia correspondiente a las 13 ciudades principales de Colombia. Estas ciudades son: Bogotá, Cali, Medellín, Barranquilla, Cartagena, Cúcuta, Bucaramanga, Pereira, Santa Marta, Ibagué, Pasto, Manizales y Neiva.\nAdemás, la plataforma ofrecía una estimación del tiempo de viaje entre ciudades, calculado con base en un tiempo promedio de desplazamiento de aproximadamente 73 km/h. La selección de estas ciudades se basó en el criterio de su población.\nPara complementar este análisis, se utilizó la plataforma Simple Maps para obtener las coordenadas centrales de cada ciudad, facilitando su localización en el mapa y la visualización de la información geográfica.\nLa Tabla 1 muestra la matriz de costos entre ciudades \\(C\\) calculada para el análisis.\nTabla1. Matriz de costo entre ciudades.\n\n\nCode\n# Librerías necesarias\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(tidyverse)\nlibrary(GA)  # Librería genética optimizada\nlibrary(ggplot2)\nlibrary(readxl)\nlibrary(leaflet)\nlibrary(dplyr)\n\n# Lectura de datos\nCiudades &lt;- read.csv(\"data/Distancias.csv\", row.names=1, na.strings=\"0\")[1:13, 1:13] \n\nTiempo_Recorrido &lt;- read.csv(\"data/Tiempos.csv\", row.names=1, na.strings=\"0\")[1:13, 1:13] \n\nCiudadesUbicacion &lt;- readxl::read_excel(\"data/CiudadesUbicacion.xlsx\")\n\n# Convertimos los datos que están en formato texto (h:mm) a horas decimales\nconvertir_horas &lt;- function(x) {   \n  if (is.na(x)) return(NA)   \n  partes &lt;- strsplit(x, \":\")[[1]]\n  horas &lt;- as.numeric(partes[1])\n  minutos &lt;- as.numeric(partes[2])\n  return(horas + minutos/60)\n}\n\nTiempo_Recorrido &lt;- apply(Tiempo_Recorrido, c(1,2), convertir_horas)\n\nCiudades &lt;- apply(Ciudades, c(1,2), as.numeric)\n\n\n## Cálculo de la Matriz de Costos\n\n# Parámetros de costos\nvalor_hora &lt;- 25000\nrendimiento_carro &lt;- 40\nprecio_galon &lt;- 16259\n\n# Costo de combustible entre cada par de ciudades\ncosto_combustible &lt;- (Ciudades / rendimiento_carro) * precio_galon\n\n# Número estimado de peajes entre cada par de ciudades\ncosto_peajes &lt;- round(Ciudades / 60) * 25000\n\n# Costo del vendedor\ncosto_vendedor &lt;- (valor_hora * Tiempo_Recorrido)\nCostoTotal &lt;- costo_vendedor + costo_peajes + costo_combustible\n\n# Mostrando la matriz de costos\nknitr::kable(CostoTotal) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F)\n\n\n\n\n\n\n\nBogotá\nCali\nMedellín\nBarranquilla\nCartagena\nCúcuta\nBucaramanga\nPereira\nSanta.Marta\nIbagué\nPasto\nManizales\nNeiva\n\n\n\n\nBogotá\nNA\n403314.8\n349840.0\n806526.49\n880001.3\n483708.7\n330328.0\n273795.00\n782197.95\n165027.0\n668909.0\n262575.58\n246427.5\n\n\nCali\n402908.3\nNA\n379290.8\n948587.06\n899715.9\n809179.4\n652120.0\n170717.65\n1013870.04\n241600.8\n376679.9\n226214.66\n356751.2\n\n\nMedellín\n348600.2\n379717.7\nNA\n570119.38\n546248.3\n496666.1\n340013.2\n185250.02\n644965.32\n323967.1\n721916.2\n176591.75\n495009.7\n\n\nBarranquilla\n804880.2\n944034.3\n565556.4\nNA\n102975.4\n565343.6\n535100.2\n774983.32\n81857.93\n797471.9\n1312055.9\n741325.04\n951289.7\n\n\nCartagena\n890254.9\n898079.9\n545008.5\n102131.91\nNA\n649895.2\n595068.4\n729018.68\n183573.17\n867735.7\n1265684.8\n720360.41\n1036257.9\n\n\nCúcuta\n481229.1\n808783.1\n492093.0\n565343.60\n646561.8\nNA\n157486.2\n639721.91\n515608.58\n568452.7\n1144762.1\n584621.18\n722687.2\n\n\nBucaramanga\n328254.8\n652953.3\n336273.4\n535516.86\n592558.2\n158309.4\nNA\n483485.67\n486188.32\n412633.2\n988932.4\n428384.95\n566450.9\n\n\nPereira\n274628.3\n171134.3\n186063.0\n780775.88\n731488.1\n641368.2\n484308.8\nNA\n845642.20\n113320.8\n538739.3\n57997.01\n277869.9\n\n\nSanta Marta\n780551.7\n1013463.6\n640808.8\n81441.26\n184000.0\n540598.4\n485771.7\n818995.92\nNA\n772726.7\n1349036.1\n788895.19\n926961.2\n\n\nIbagué\n165037.2\n242423.9\n323956.9\n797878.41\n870946.8\n568452.7\n411799.8\n112904.09\n773143.39\nNA\n590343.6\n170880.72\n167862.1\n\n\nPasto\n668502.5\n375856.8\n721906.0\n1316202.21\n1267331.1\n1144345.5\n987692.6\n537916.13\n1348619.48\n590343.6\nNA\n593423.33\n421648.1\n\n\nManizales\n261346.0\n226641.5\n176591.8\n745887.99\n722423.4\n585037.8\n428385.0\n57173.87\n789311.86\n170474.2\n593840.0\nNA\n335023.4\n\n\nNeiva\n247687.7\n356751.2\n489756.1\n952539.70\n1026014.5\n723520.5\n566867.6\n278703.28\n928211.16\n169935.3\n423721.3\n336679.90\nNA"
  },
  {
    "objectID": "posts/Optimizacion-combinatoria/index.html#ga-aplicado-al-tsp",
    "href": "posts/Optimizacion-combinatoria/index.html#ga-aplicado-al-tsp",
    "title": "Optimización Combinatoria",
    "section": "3.2 GA aplicado al TSP",
    "text": "3.2 GA aplicado al TSP\n\n3.2.1 Implementación del GA aplicado al TSP\nSe utilizó la librería GA en R para modelar el problema TSP como una permutación de ciudades. La función de aptitud fue definida como el negativo del costo total, para así minimizar el recorrido.\nPara la simulación del GA se utilizaron los siguientes Hiperparámetros críticos (basado en implementaciones prácticas):\n\nTamaño de población: 50 individuos, balanceando diversidad y costo computacional (Revistas Uniboyacá, s.f.).\nGeneraciones: 500 iteraciones, suficientes para converger hacia soluciones cercanas al óptimo (Gonçalves et al., 2005).\nTasa de mutación: 20%, equilibrando exploración y estabilidad (Revistas Uniboyacá, s.f.).\n\nLa mejor solución encontrada por GA presentó un costo total mínimo de $3.369.197, lograda en la generación 253.\n\n\nCode\nset.seed(123)\n\n# Función para calcular el costo total de una ruta\nevaluar_ruta &lt;- function(ruta, matriz_costos) {\n  costo &lt;- 0\n  for (i in 1:(length(ruta) - 1)) {\n    costo &lt;- costo + matriz_costos[ruta[i], ruta[i + 1]]\n  }\n  # Cerrar el ciclo regresando a la ciudad inicial\n  costo &lt;- costo + CostoTotal[ruta[length(ruta)], ruta[1]]\n  return(costo)\n}\n\n# Número de ciudades\nn_ciudades &lt;- nrow(CostoTotal)\n\n# Implementar el algoritmo\n# modelo_GA &lt;- ga(\n#   type = \"permutation\",\n#   fitness = function(ruta) -evaluar_ruta(ruta, CostoTotal),  # Negativo para minimizar\n#   lower = 1,\n#   upper = n_ciudades,\n#   popSize = 50,            # Tamaño de la población\n#   maxiter = 500,           # Número máximo de generaciones\n#   pmutation = 0.2,        # Probabilidad de mutación\n#   monitor = FALSE\n# )\nhistorial_fitness &lt;- c()\nmodelo_GA &lt;- ga(\n  type = \"permutation\",\n  fitness = function(ruta) -evaluar_ruta(ruta, CostoTotal),  # Negativo para minimizar\n  lower = 1,\n  upper = n_ciudades,\n  popSize = 50,            # Tamaño de la población\n  maxiter = 500,           # Número máximo de generaciones\n  pmutation = 0.2,        # Probabilidad de mutación\n  monitor = function(obj) {\n    historial_fitness &lt;&lt;- c(historial_fitness, -max(obj@fitness))\n  }\n)\n\n# Mejor ruta\nmejor_ruta &lt;- modelo_GA@solution[1,]\n\n# Mejor costo\nmejor_costo &lt;- -modelo_GA@fitnessValue  # Recuerda que lo negamos antes\n\n# Mostrar resultados\n\n# Crear dataframe del historial\ndf_historial &lt;- data.frame(\n  Generacion = 1:length(historial_fitness),\n  CostoTotal = historial_fitness\n)\n\n# Encontrar el mejor costo\n#mejor_costo &lt;- min(df_historial$CostoTotal)\nmejor_generacion &lt;- df_historial$Generacion[which.min(df_historial$CostoTotal)]\n\n# Mostrar resultados\ncat(\"\\nLa mejor ruta se obtuvo en la generación \", mejor_generacion, \"\\nEl costo total de la mejor ruta fue de $\", format(mejor_costo, big.mark=\",\"), \"\\n\")\n\n\n\nLa mejor ruta se obtuvo en la generación  253 \nEl costo total de la mejor ruta fue de $ 3,369,197 \n\n\n\n\n3.2.2 Visualización de resultados del GA aplicado al TSP\n\n3.2.2.1 Evolución del costo total a través de las generaciones\nLa Figura 1 muestra cómo evolucionó el Costo Total a través de 500 generaciones. Se observa en ella que el algoritmo genético mostró una mejora significativa en el costo total durante las primeras generaciones, encontrando soluciones de menor costo de forma rápida. A partir de la generación 250 aproximadamente, el algoritmo estabilizó su desempeño, indicando que había alcanzado una solución cercana al óptimo.\n\n\nCode\n# Graficar la evolucion del Costo en el AG\n\n# Crear el texto que quieres mostrar\ntexto_anotacion &lt;- paste0(\"Generación: \", mejor_generacion, \"\\nCosto: \", format(round(mejor_costo, 0), big.mark = \",\"))\n\n# Graficar\nggplot(df_historial, aes(x = Generacion, y = CostoTotal)) +\n  geom_line(color = \"darkgreen\", size = 1) +\n  geom_point(color = \"forestgreen\", size = 1.5) +\n  annotate(\"point\", \n           x = mejor_generacion, \n           y = mejor_costo, \n           color = \"red\", \n           size = 4) +\n  annotate(\"text\",\n           x = mejor_generacion + 20,  # desplazamos un poco para que no tape el punto\n           y = mejor_costo,\n           label = texto_anotacion,\n           hjust = 0,                  # alineación horizontal\n           vjust = -0.5,               # alineación vertical\n           size = 4,\n           color = \"black\",\n           fontface = \"bold\") +\n  theme_minimal() +\n  labs(\n    title = \"Evolución del Costo Total en el Algoritmo Genético (AG)\",\n    x = \"Generación\",\n    y = \"Costo Total\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\", size = 14),\n    axis.title = element_text(face = \"bold\", size = 12),\n    axis.text = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\n\nFigura 1. Evolución del Costo Total en el GA a través de 500 generaciones.\n\n\n3.2.2.2 Visualización de la mejor ruta\nLa Tabla 2 muestra la mejor ruta hallada por GA, que corresponde al costo total mínimo de $3.369.197, entre las 13 ciudades de Colombia en el orden que deben recorrerse.\nTabla 2. Orden en que deben recorrerse las 13 ciudades en la mejor ruta obtenida por GA.\n\n\nCode\n# Mejor ruta (ya teníamos mejor_ruta)\nruta_completa &lt;- c(mejor_ruta, mejor_ruta[1])\n\n# Extraer ciudades en orden de la ruta\nruta_ciudades &lt;- CiudadesUbicacion[ruta_completa, ]\n\n# Agregar el orden de visita\nruta_ciudades$Orden &lt;- 1:nrow(ruta_ciudades)\n\n# Mostrando la mejor ruta\nknitr::kable(\n  ruta_ciudades[, c(\"Ciudad\", \"Orden\")],\n  col.names = c(\"Ciudad\", \"Orden de visita\")\n) %&gt;%\n  kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n    full_width = FALSE,\n    position = \"center\"\n  ) %&gt;%\n  column_spec(1, bold = TRUE, width = \"10em\") %&gt;%\n  column_spec(2, width = \"5em\") %&gt;%\n  row_spec(0, bold = TRUE, color = \"white\", background = \"#4682B4\")\n\n\n\n\n\n\nCiudad\nOrden de visita\n\n\n\n\nSanta Marta\n1\n\n\nBarranquilla\n2\n\n\nCartagena\n3\n\n\nMedellín\n4\n\n\nManizales\n5\n\n\nPereira\n6\n\n\nIbagué\n7\n\n\nCali\n8\n\n\nPasto\n9\n\n\nNeiva\n10\n\n\nBogotá\n11\n\n\nBucaramanga\n12\n\n\nCúcuta\n13\n\n\nSanta Marta\n14\n\n\n\n\n\n\n\n\nLa Figura 2 muestra la superposición de la mejor ruta hallada por GA en el mapa de Colombia.\n\n\nCode\n# Crear texto de costo\ncosto_texto &lt;- paste0(\"Costo total mínimo: $\", format(round(mejor_costo, 0), big.mark = \",\"))\n# Íconos personalizados para inicio y fin\nicono_inicio &lt;- awesomeIcons(\n  icon = 'flag',\n  iconColor = 'white',\n  markerColor = 'green',\n  library = 'fa'\n)\n\nicono_fin &lt;- awesomeIcons(\n  icon = 'flag',\n  iconColor = 'white',\n  markerColor = 'red',\n  library = 'fa'\n)\n\n# Texto del costo total\ncosto_texto &lt;- paste0(\"Costo total mínimo: $\", format(round(mejor_costo, 0), big.mark = \",\"))\n\n# Crear el mapa\nleaflet() %&gt;%\n  addProviderTiles(providers$CartoDB.Positron) %&gt;%\n  \n  # Marcar la ciudad de inicio (primer ciudad de la ruta)\n  addAwesomeMarkers(\n    lng = ruta_ciudades$Longitud[1],\n    lat = ruta_ciudades$Latitud[1],\n    icon = icono_inicio,\n    popup = paste(\"Inicio:\", ruta_ciudades$Ciudad[1])\n  ) %&gt;%\n  \n  # Marcar la ciudad final (última ciudad de la ruta)\n  addAwesomeMarkers(\n    lng = ruta_ciudades$Longitud[nrow(ruta_ciudades)-1],\n    lat = ruta_ciudades$Latitud[nrow(ruta_ciudades)-1],\n    icon = icono_fin,\n    popup = paste(\"Fin:\", ruta_ciudades$Ciudad[nrow(ruta_ciudades)-1])\n  ) %&gt;%\n  \n  # Marcar todas las demás ciudades normales\n  addCircleMarkers(\n    data = ruta_ciudades,\n    lng = ~Longitud,\n    lat = ~Latitud,\n    radius = 6,\n    color = \"blue\",\n    fillColor = \"blue\",\n    fillOpacity = 0.8,\n    label = ~paste0(Orden, \". \", Ciudad),\n    popup = ~paste(\"Ciudad:\", Ciudad, \"&lt;br&gt;\", \"Orden de visita:\", Orden)\n  ) %&gt;%\n  \n  # Agregar la ruta conectando las ciudades\n  addPolylines(\n    lng = ~Longitud,\n    lat = ~Latitud,\n    data = ruta_ciudades,\n    color = \"red\",\n    weight = 3,\n    opacity = 0.8\n  ) %&gt;%\n  \n  # Mostrar el costo total en una esquina\n  addControl(\n    html = paste0(\"&lt;b&gt;\", costo_texto, \"&lt;/b&gt;\"),\n    position = \"bottomleft\"\n  )\n\n\n\n\n\n\nFigura 2. Superposición de la mejor ruta obtenida por GA en el mapa de Colombia.\n\n\n\n3.2.3 Recorrido óptimo animado mejor ruta GA\nLa Figura 3 muestra una animación del recorrido a través de la mejor ruta encontrada usando GA aplicado al TSG.\n\n\n\n\n\nFigura 3. Animación del recorrido óptima encontrada usando GA aplicado al TSG.\n\n\n3.2.4 Verificación de la calidad de la solución del GA aplicado al TSP\nDurante la ejecución del algoritmo, se observó un comportamiento típico de convergencia: inicialmente, el costo total disminuyó rápidamente, mostrando mejoras significativas en las primeras generaciones; posteriormente, el costo se estabilizó, oscilando alrededor de una media relativamente constante. Este patrón es consistente con el comportamiento esperado en métodos de optimización metaheurística, indicando que el AG convergió hacia un conjunto de soluciones cercanas al óptimo.\nPor lo tanto, se seleccionó como solución final la ruta correspondiente al menor costo alcanzado durante las iteraciones. Dado que las funciones de costo tienden a estabilizarse en un rango limitado y que no se observaron mejoras sustanciales tras cierto número de generaciones, se concluye que la solución obtenida es razonablemente buena, considerando las limitaciones inherentes a los métodos no determinísticos y la complejidad del problema (Gonçalves et al., 2005; Zhang et al., 2020)."
  },
  {
    "objectID": "posts/Optimizacion-combinatoria/index.html#aco-aplicado-al-tsp",
    "href": "posts/Optimizacion-combinatoria/index.html#aco-aplicado-al-tsp",
    "title": "Optimización Combinatoria",
    "section": "3.3 ACO aplicado al TSP",
    "text": "3.3 ACO aplicado al TSP\n\n3.3.1 Implementación del ACO aplicado al TSP\nPara la simulación del ACO se utilizaron los siguientes hiperparámetros críticos, basados en recomendaciones de la literatura y experimentación práctica:\n\nNúmero de hormigas: 13, buscando un equilibrio entre la diversidad de soluciones exploradas y el costo computacional (Dorigo & Stützle, 2004).\nIteraciones: 500, suficientes para permitir la convergencia hacia soluciones de bajo costo (Gambardella & Dorigo, 1995).\nImportancia relativa de la feromona (\\(\\alpha\\)): 1, para que la información histórica de las rutas influya en la toma de decisiones.\nImportancia de la heurística (\\(\\beta\\)): 5, dando mayor peso al costo inmediato de los trayectos (Dorigo & Stützle, 2004).\nTasa de evaporación de feromona (\\(\\rho\\)): 0.5, permitiendo un balance entre la explotación de buenas rutas y la exploración de nuevas alternativas.\nConstante para el depósito de feromona ($Q$): 1.\n\nLa mejor solución encontrada por ACO presentó un costo total mínimo de $3,271,872, lograda en la iteración 96.\n\n\nCode\n# Número de ciudades\nn_ciudades &lt;- nrow(CostoTotal)\n\n# Parámetros del ACO\nn_hormigas &lt;- n_ciudades       # Una hormiga por ciudad\nn_iteraciones &lt;- 500           # Número de generaciones\nalpha &lt;- 1                     # Importancia de la feromona\nbeta &lt;- 5                      # Importancia de la visibilidad (1/distancia)\nrho &lt;- 0.5                     # Tasa de evaporación\nQ &lt;- 1                         # Constante para el depósito de feromona\n\n# Inicializar feromonas (matriz llena de 1's)\nferomonas &lt;- matrix(1, n_ciudades, n_ciudades)\n\n# Visibilidad: inversa del costo (matriz de distancias)\nvisibilidad &lt;- 1 / CostoTotal\ndiag(visibilidad) &lt;- 0   # No queremos loops sobre sí mismo\n\nconstruir_ruta &lt;- function(feromonas, visibilidad, alpha, beta) {\n  ruta &lt;- integer(n_ciudades)\n  ruta[1] &lt;- sample(1:n_ciudades, 1)   # Escoge ciudad inicial aleatoria\n  \n  no_visitadas &lt;- setdiff(1:n_ciudades, ruta[1])\n  \n  for (i in 2:n_ciudades) {\n    ultimo &lt;- ruta[i-1]\n    \n    if (length(no_visitadas) == 1) {\n      siguiente &lt;- no_visitadas  # Solo queda una opción\n    } else {\n      probabilidades &lt;- (feromonas[ultimo, no_visitadas]^alpha) * (visibilidad[ultimo, no_visitadas]^beta)\n      probabilidades &lt;- probabilidades / sum(probabilidades)\n      \n      siguiente &lt;- sample(no_visitadas, 1, prob = probabilidades)\n    }\n    \n    ruta[i] &lt;- siguiente\n    no_visitadas &lt;- setdiff(no_visitadas, siguiente)\n  }\n  \n  return(ruta)\n}\n\n\n# Función para calcular el costo de una ruta\ncosto_ruta &lt;- function(ruta, costo_total) {\n  costo &lt;- 0\n  for (i in 1:(length(ruta)-1)) {\n    costo &lt;- costo + costo_total[ruta[i], ruta[i+1]]\n  }\n  # Cerrar el ciclo (regresar al origen)\n  costo &lt;- costo + costo_total[ruta[length(ruta)], ruta[1]]\n  return(costo)\n}\n\n# Guardar el mejor resultado\nmejor_ruta_aco &lt;- NULL\nmejor_costo_aco &lt;- Inf\nhistorial_costo_aco &lt;- c()\nmejor_iteracion_aco &lt;- 0\n\n\nfor (iter in 1:n_iteraciones) {\n  \n  rutas &lt;- list()\n  costos &lt;- numeric(n_hormigas)\n  \n  # Cada hormiga construye su ruta\n  for (k in 1:n_hormigas) {\n    rutas[[k]] &lt;- construir_ruta(feromonas, visibilidad, alpha, beta)\n    costos[k] &lt;- costo_ruta(rutas[[k]], CostoTotal)\n  }\n  \n  # Actualizar mejor solución\n  if (min(costos) &lt; mejor_costo_aco) {\n    mejor_costo_aco &lt;- min(costos)\n    mejor_ruta_aco &lt;- rutas[[which.min(costos)]]\n    mejor_iteracion_aco &lt;- iter \n  }\n  \n  # Actualizar feromonas\n  feromonas &lt;- (1 - rho) * feromonas   # Evaporación\n  \n  for (k in 1:n_hormigas) {\n    ruta_k &lt;- rutas[[k]]\n    costo_k &lt;- costos[k]\n    \n    for (i in 1:(length(ruta_k)-1)) {\n      feromonas[ruta_k[i], ruta_k[i+1]] &lt;- feromonas[ruta_k[i], ruta_k[i+1]] + Q / costo_k\n    }\n    # Cerrar el ciclo\n    feromonas[ruta_k[length(ruta_k)], ruta_k[1]] &lt;- feromonas[ruta_k[length(ruta_k)], ruta_k[1]] + Q / costo_k\n  }\n  \n  # Guardar evolución\n  historial_costo_aco &lt;- c(historial_costo_aco, mejor_costo_aco)\n  \n  # (Opcional: ver progreso)\n  #if (iter %% 50 == 0) cat(\"Iteración:\", iter, \"- Mejor costo hasta ahora:\", mejor_costo_aco, \"\\n\")\n}\n\n# Mostar resultados\ncat(\"\\nLa mejor ruta se obtuvo en la iteración \", mejor_iteracion_aco, \"\\nEl costo total de la mejor ruta fue de $\", format(mejor_costo_aco, big.mark=\",\"), \"\\n\")\n\n\n\nLa mejor ruta se obtuvo en la iteración  96 \nEl costo total de la mejor ruta fue de $ 3,271,872 \n\n\n\n\n3.3.2 Visualización de resultados del ACO aplicado al TSP\n\n3.3.2.1 Evolución del costo total a través de las iteraciones\nLa Figura 4 muestra cómo evolucionó el Costo Total a través de 500 generaciones. Se observa que el algoritmo de colonia de hormigas presentó una rápida convergencia en las primeras generaciones, alcanzando una solución estable alrededor de la iteración 96. A partir de ese momento, el costo total se mantuvo constante, lo que indica que el conjunto de hormigas ha refinado su búsqueda alrededor de una solución de bajo costo.\n\n\nCode\n# Crear dataframe del historial de costos del ACO\ndf_historial_aco &lt;- data.frame(\n  Iteracion = 1:length(historial_costo_aco),\n  CostoTotal = historial_costo_aco\n)\n\n# Encontrar el mejor costo y la iteración donde se logró\nmejor_costo_aco &lt;- min(df_historial_aco$CostoTotal)\nmejor_iteracion_aco &lt;- df_historial_aco$Iteracion[which.min(df_historial_aco$CostoTotal)]\n\n# Crear el texto para la anotación\ntexto_anotacion_aco &lt;- paste0(\n  \"Iteración: \", mejor_iteracion_aco, \n  \"\\nCosto: \", format(round(mejor_costo_aco, 0), big.mark = \",\")\n)\n\n# Graficar la evolución del costo en el ACO\nggplot(df_historial_aco, aes(x = Iteracion, y = CostoTotal)) +\n  geom_line(color = \"darkgreen\", size = 1) +\n  geom_point(color = \"forestgreen\", size = 1.5) +\n  annotate(\"point\", \n           x = mejor_iteracion_aco, \n           y = mejor_costo_aco, \n           color = \"red\", \n           size = 4) +\n  annotate(\"text\",\n           x = mejor_iteracion_aco + 20,  # desplazar el texto para que no tape el punto\n           y = mejor_costo_aco,\n           label = texto_anotacion_aco,\n           hjust = 0,\n           vjust = -0.5,\n           size = 4,\n           color = \"black\",\n           fontface = \"bold\") +\n  theme_minimal() +\n  labs(\n    title = \"Evolución del Costo Total en el Algoritmo de Colonia de Hormigas (ACO)\",\n    x = \"Iteración\",\n    y = \"Costo Total\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\", size = 14),\n    axis.title = element_text(face = \"bold\", size = 12),\n    axis.text = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\n\nFigura 4. Evolución del Costo Total en el ACO a través de 500 iteraciones.\n\n\n3.3.2.2 Visualización de la mejor ruta\nLa Tabla 3 muestra la mejor ruta hallada por ACO, que corresponde al costo total mínimo de $3.271.872, entre las 13 ciudades de Colombia en el orden que deben recorrerse.\nTabla 3. Orden en que deben recorrerse las 13 ciudades en la mejor ruta obtenida por ACO.\n\n\nCode\n# Ruta completa (cerrando el ciclo)\nruta_completa_aco &lt;- c(mejor_ruta_aco, mejor_ruta_aco[1])\n\n# Extraer ciudades según el orden\nruta_ciudades_aco &lt;- CiudadesUbicacion[ruta_completa_aco, ]\n\n# Agregar orden de visita\nruta_ciudades_aco$Orden &lt;- 1:nrow(ruta_ciudades_aco)\n\n# Mostrar la mejor ruta en una tabla\nknitr::kable(ruta_ciudades_aco[, c(\"Ciudad\", \"Orden\")], \n             col.names = c(\"Ciudad\", \"Orden de visita\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = FALSE, position = \"center\") %&gt;%\n  column_spec(1, bold = TRUE, width = \"10em\") %&gt;%\n  column_spec(2, width = \"5em\") %&gt;%\n  row_spec(0, bold = TRUE, color = \"white\", background = \"#4682B4\")\n\n\n\n\n\n\nCiudad\nOrden de visita\n\n\n\n\nPasto\n1\n\n\nNeiva\n2\n\n\nIbagué\n3\n\n\nBogotá\n4\n\n\nBucaramanga\n5\n\n\nCúcuta\n6\n\n\nSanta Marta\n7\n\n\nBarranquilla\n8\n\n\nCartagena\n9\n\n\nMedellín\n10\n\n\nManizales\n11\n\n\nPereira\n12\n\n\nCali\n13\n\n\nPasto\n14\n\n\n\n\n\n\n\n\nLa Figura 5 muestra la superposición de la mejor ruta hallada por ACO en el mapa de Colombia.\n\n\nCode\n# Texto para mostrar el costo total\ncosto_aco_texto &lt;- paste0(\"Costo total (ACO): $\", format(round(mejor_costo_aco, 0), big.mark = \",\"))\n\n# Íconos personalizados\nicono_inicio &lt;- awesomeIcons(icon = 'flag', markerColor = 'green', iconColor = 'white', library = 'fa')\nicono_fin    &lt;- awesomeIcons(icon = 'flag', markerColor = 'red', iconColor = 'white', library = 'fa')\n\n# Crear el mapa\nleaflet() %&gt;%\n  addProviderTiles(providers$CartoDB.Positron) %&gt;%\n  \n  # Marcar ciudad de inicio\n  addAwesomeMarkers(\n    lng = ruta_ciudades_aco$Longitud[1],\n    lat = ruta_ciudades_aco$Latitud[1],\n    icon = icono_inicio,\n    popup = paste(\"Inicio:\", ruta_ciudades_aco$Ciudad[1])\n  ) %&gt;%\n  \n  # Marcar ciudad final (última antes de cerrar el ciclo)\n  addAwesomeMarkers(\n    lng = ruta_ciudades_aco$Longitud[nrow(ruta_ciudades_aco) - 1],\n    lat = ruta_ciudades_aco$Latitud[nrow(ruta_ciudades_aco) - 1],\n    icon = icono_fin,\n    popup = paste(\"Fin:\", ruta_ciudades_aco$Ciudad[nrow(ruta_ciudades_aco) - 1])\n  ) %&gt;%\n  \n  # Puntos azules para las demás ciudades\n  addCircleMarkers(\n    data = ruta_ciudades_aco,\n    lng = ~Longitud,\n    lat = ~Latitud,\n    radius = 6,\n    color = \"blue\",\n    fillOpacity = 0.8,\n    label = ~paste0(Orden, \". \", Ciudad),\n    popup = ~paste(\"Ciudad:\", Ciudad, \"&lt;br&gt;\", \"Orden:\", Orden)\n  ) %&gt;%\n  \n  # Ruta roja\n  addPolylines(\n    data = ruta_ciudades_aco,\n    lng = ~Longitud,\n    lat = ~Latitud,\n    color = \"red\",\n    weight = 3,\n    opacity = 0.8\n  ) %&gt;%\n  \n  # Costo total\n  addControl(\n    html = paste0(\"&lt;b&gt;Costo total ACO: $\", format(round(mejor_costo_aco, 0), big.mark = \",\"), \"&lt;/b&gt;\"),\n    position = \"bottomleft\"\n  )\n\n\n\n\n\n\nFigura 5. Superposición de la mejor ruta obtenida por ACO en el mapa de Colombia.\n\n\n\n3.3.3 Recorrido óptimo animado mejor ruta ACO\nLa Figura 6 muestra una animación del recorrido a través de la mejor ruta encontrada usando ACO aplicado al TSG.\n\n\n\n\n\nFigura 6. Animación del recorrido óptima encontrada usando ACO aplicado al TSG.\n\n\n3.3.4 Verificación de la calidad de la solución del ACO aplicado al TSP\nAunque los algoritmos metaheurísticos no garantizan la optimalidad global, el comportamiento observado en la evolución del costo sugiere que el algoritmo de colonia de hormigas (ACO) fue eficiente para encontrar una solución competitiva al problema del viajante bajo condiciones realistas.\nEl ACO se aplicó para resolver una instancia del problema del viajante, con el objetivo de minimizar el costo total de recorrer todas las ciudades y regresar al punto de partida. Dado que el número de rutas posibles crece factorialmente con la cantidad de ciudades, una evaluación exhaustiva por fuerza bruta es impracticable, lo que hace esencial analizar la calidad de la solución obtenida a partir de los resultados empíricos del algoritmo.\nDurante las 500 iteraciones ejecutadas, el ACO mostró un patrón típico de convergencia eficiente: el costo total disminuyó rápidamente en las primeras iteraciones y se estabilizó alrededor de la iteración 90. A partir de ese punto, el algoritmo mantuvo consistentemente la mejor solución, lo que indica que las feromonas guiaron a las hormigas hacia una ruta sólida, iterativamente reforzada como la mejor alternativa encontrada.\nEste patrón de estabilización sugiere que el algoritmo alcanzó un óptimo local robusto. Si bien los métodos metaheurísticos no garantizan encontrar la solución óptima global, la combinación de una rápida convergencia, la estabilidad mantenida durante más del 90% de las iteraciones y la coherencia en los resultados permiten concluir que la solución obtenida es razonablemente buena en términos de eficiencia y costo.\nEl valor final alcanzado fue de $3,271,872, el cual se mantuvo inalterado en todas las iteraciones posteriores a la convergencia. Este comportamiento, junto con la tendencia descendente y estable de la función objetivo, respalda la confiabilidad y solidez de la solución obtenida mediante este enfoque bioinspirado."
  },
  {
    "objectID": "posts/Optimizacion-combinatoria/index.html#comparación-entre-el-ga-y-aco-aplicados-al-tsg",
    "href": "posts/Optimizacion-combinatoria/index.html#comparación-entre-el-ga-y-aco-aplicados-al-tsg",
    "title": "Optimización Combinatoria",
    "section": "3.4 Comparación entre el GA y ACO aplicados al TSG",
    "text": "3.4 Comparación entre el GA y ACO aplicados al TSG\nTanto el Algoritmo Genético (GA) como la Colonia de Hormigas (ACO) son enfoques metaheurísticos inspirados en procesos naturales, aplicados en este trabajo a la resolución del Problema del Viajante de Comercio (TSP). Ambos buscan encontrar rutas óptimas minimizando el costo total del recorrido, que considera tiempo de desplazamiento, consumo de combustible y peajes. Aunque ambos métodos son de naturaleza estocástica y no garantizan la optimalidad global, presentan diferencias notables en su enfoque, comportamiento y resultados.\nDesde el punto de vista computacional, el GA emplea operadores de evolución genética -como selección, cruce y mutación- para explorar el espacio de soluciones, generando diversidad entre generaciones y favoreciendo combinaciones prometedoras. Por su parte, el ACO simula el comportamiento colectivo de las hormigas depositando y evaporando feromonas, construyendo soluciones de manera probabilística e incremental, guiadas por la experiencia acumulada.\nEn cuanto a los resultados obtenidos, ambos algoritmos convergieron a soluciones estables en un número razonable de iteraciones. El ACO se destacó por su rápida convergencia, alcanzando su mejor solución alrededor de la iteración 96 y manteniéndola constante durante el resto del proceso. El GA, en cambio, mostró una mejora más progresiva y continua, permitiendo pequeñas optimizaciones incluso en etapas avanzadas del ciclo evolutivo.\nEn términos de calidad de la solución, ambos métodos arrojaron rutas de costo muy similar, aunque no necesariamente idénticas. Esto sugiere que, pese a sus diferencias internas, cada algoritmo fue capaz de explorar zonas similares del espacio de soluciones, lo que refuerza la solidez de los resultados encontrados. Además, la convergencia de ambos métodos hacia soluciones estables ofrece evidencia empírica de que dichas soluciones se ubican en regiones de alta calidad dentro del espacio del problema.\nEn cuanto a interpretabilidad y ajuste, el GA ofrece una mayor flexibilidad en la manipulación de operadores genéticos y estrategias de cruce, mientras que el ACO se beneficia de una dinámica colectiva más estable una vez ajustados correctamente sus parámetros (\\(\\alpha\\), \\(\\beta\\), evaporación y número de hormigas).\nAmbos algoritmos resultaron efectivos en la resolución del problema propuesto, y la comparación de sus resultados evidencia que, con configuraciones adecuadas, tanto el enfoque evolutivo como el bioinspirado pueden alcanzar soluciones de alta calidad. La elección entre uno u otro dependerá del contexto, la facilidad de ajuste, la sensibilidad a los parámetros y el tipo de convergencia deseado en problemas similares.\nEn resumen, ambos algoritmos permiten abordar el TSP de manera eficiente, evitando el alto costo computacional de los métodos exactos. La calidad de las soluciones es elevada, considerando la complejidad combinatoria del problema. La representación gráfica de las rutas facilita la validación y comunicación de los resultados. La elección entre GA y ACO dependerá de las características específicas del problema, la facilidad de ajuste de parámetros y el tipo de convergencia deseado.\nLa Tabla 4 presenta un resumen comparativo de las características de las simulaciones realizadas con GA y ACO para resolver el TSG.\nTabla 4. Comparación de características y resultados: GA vs. ACO aplicados al TSG.\n\n\nCode\ntabla_comp &lt;- data.frame(\n  \"Criterio\" = c(\n    \"Inspiración\",\n    \"Construcción de soluciones\",\n    \"Velocidad de convergencia\",\n    \"Diversidad de soluciones\",\n    \"Sensibilidad a parámetros\",\n    \"Estabilidad de resultados\",\n    \"Mejor iteración lograda\",\n    \"Costo total alcanzado\",\n    \"Interpretabilidad\",\n    \"Fortalezas\",\n    \"Debilidades\"\n  ),\n  \"Algoritmo Genético (GA)\" = c(\n    \"Evolución natural (selección, cruza, mutación)\",\n    \"Recombina soluciones completas para generar nuevas poblaciones\",\n    \"Moderada (mejora progresiva en varias etapas)\",\n    \"Alta diversidad gracias a mutaciones y recombinación\",\n    \"Alta: requiere ajuste fino de cruza, mutación y tamaño de población\",\n    \"Puede oscilar en fases avanzadas (dependiendo del azar y cruce)\",\n    \"Iteración 253\",\n    \"~$3.369.197\",\n    \"Alta: permite seguimiento de operadores y evolución\",\n    \"Explora más ampliamente el espacio de soluciones\",\n    \"Requiere control de diversidad para evitar estancamiento\"\n  ),\n  \"Colonia de Hormigas (ACO)\" = c(\n    \"Comportamiento colectivo de hormigas y feromonas\",\n    \"Construye rutas paso a paso con base en probabilidad\",\n    \"Alta (mejora rápida en primeras iteraciones, estabilización temprana)\",\n    \"Menor diversidad, favorece la explotación de buenas soluciones\",\n    \"Media-alta: depende de α, β, evaporación, número de hormigas\",\n    \"Alta estabilidad tras converger a una buena ruta\",\n    \"Iteración 96\",\n    \"~$3.271.872\",\n    \"Media: soluciones emergen de dinámica colectiva\",\n    \"Explota rutas prometedoras rápidamente y converge de forma robusta\",\n    \"Puede converger prematuramente a óptimos locales\"\n  ),\n  check.names = FALSE  # &lt;- ¡Esto es lo importante!\n)\n\nkable(tabla_comp, \"html\", caption = \"Tabla 4. Comparación de características y resultados: GA vs. ACO aplicados al TSP.\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), \n                full_width = FALSE, \n                position = \"center\") %&gt;%\n  column_spec(1, bold = TRUE, width = \"17em\") %&gt;%\n  column_spec(2, width = \"20em\") %&gt;%\n  column_spec(3, width = \"20em\") %&gt;%\n  row_spec(0, bold = TRUE, color = \"white\", background = \"#4682B4\")\n\n\n\n\nTabla 4. Comparación de características y resultados: GA vs. ACO aplicados al TSP.\n\n\nCriterio\nAlgoritmo Genético (GA)\nColonia de Hormigas (ACO)\n\n\n\n\nInspiración\nEvolución natural (selección, cruza, mutación)\nComportamiento colectivo de hormigas y feromonas\n\n\nConstrucción de soluciones\nRecombina soluciones completas para generar nuevas poblaciones\nConstruye rutas paso a paso con base en probabilidad\n\n\nVelocidad de convergencia\nModerada (mejora progresiva en varias etapas)\nAlta (mejora rápida en primeras iteraciones, estabilización temprana)\n\n\nDiversidad de soluciones\nAlta diversidad gracias a mutaciones y recombinación\nMenor diversidad, favorece la explotación de buenas soluciones\n\n\nSensibilidad a parámetros\nAlta: requiere ajuste fino de cruza, mutación y tamaño de población\nMedia-alta: depende de α, β, evaporación, número de hormigas\n\n\nEstabilidad de resultados\nPuede oscilar en fases avanzadas (dependiendo del azar y cruce)\nAlta estabilidad tras converger a una buena ruta\n\n\nMejor iteración lograda\nIteración 253\nIteración 96\n\n\nCosto total alcanzado\n~$3.369.197\n~$3.271.872\n\n\nInterpretabilidad\nAlta: permite seguimiento de operadores y evolución\nMedia: soluciones emergen de dinámica colectiva\n\n\nFortalezas\nExplora más ampliamente el espacio de soluciones\nExplota rutas prometedoras rápidamente y converge de forma robusta\n\n\nDebilidades\nRequiere control de diversidad para evitar estancamiento\nPuede converger prematuramente a óptimos locales"
  },
  {
    "objectID": "posts/Riesgo-crediticio/index.html",
    "href": "posts/Riesgo-crediticio/index.html",
    "title": "Modelado de Riesgo Crediticio con Redes Neuronales",
    "section": "",
    "text": "1 Introducción\n  2 Marco Teórico\n  \n  2.1 Riesgo crediticio\n  \n  2.1.1 Métodos para estimar el riesgo crediticio\n  \n  2.2 Redes Neuronales Artificiales (RNA)\n  \n  2.2.1 Conceptos clave en RNA\n  2.2.2 RNA en el riesgo crediticio\n  2.2.3 Ejemplo básico en Python\n  \n  2.3 Scorecards y explicabilidad\n  \n  2.3.1 Fórmula estándar para scorecards\n  \n  2.4 Metodología a usar\n  \n  3 Resultados y Análisis\n  4 Aplicación web\n  5 Video\n  6 Conclusiones\n  7 Contribuciones individuales\n  8 Referencias\nENUCIADO DEL PROBLEMA\nEl reto en este trabajo es crear un modelo para predecir la probabilidad de que un individuo incumpla con el pago de su crédito.\n\nLa variable “loan_status” (incumplimiento de las obligaciones financieras) está dada en el archivo “Credit Risk Dataset” (disponible en https://www.kaggle.com/datasets/ranadeep/credit-risk-dataset/data).\nReto"
  },
  {
    "objectID": "posts/Riesgo-crediticio/index.html#riesgo-crediticio",
    "href": "posts/Riesgo-crediticio/index.html#riesgo-crediticio",
    "title": "Modelado de Riesgo Crediticio con Redes Neuronales",
    "section": "2.1 Riesgo crediticio",
    "text": "2.1 Riesgo crediticio\nEl riesgo crediticio se define como la probabilidad de que un prestatario incumpla con el pago de una obligación financiera, lo que puede generar pérdidas para la entidad que otorga el préstamo (Financionario, 2025; Finance Strategists, 2023). Este riesgo es un factor central en la toma de decisiones financieras, ya que afecta tanto a las instituciones como a los solicitantes de crédito. Una gestión adecuada del riesgo crediticio permite anticipar posibles impagos, ajustar condiciones como tasas de interés o garantías, y mantener la estabilidad de las entidades financieras (ListenData, 2019). Además, una evaluación precisa del riesgo crediticio protege a las instituciones de pérdidas inesperadas, promueve la confianza en el sistema financiero y facilita el acceso a condiciones más justas para los usuarios (Finance Strategists, 2023). La correcta evaluación del riesgo es fundamental para la transparencia y eficiencia del sistema financiero, beneficiando a todas las partes involucradas. Por un lado, protege a las instituciones financieras y, por otro, ayuda a los solicitantes a comprender los factores que influyen en su perfil crediticio y a acceder a productos financieros adecuados a su situación (Finance Strategists, 2023).\nEl riesgo crediticio puede manifestarse en diferentes formas, incluyendo el riesgo de incumplimiento, riesgo de contraparte, riesgo de concentración y riesgo país, entre otros (Pirani Risk, 2022). También se vincula a la calificación crediticia, que evalúa la solvencia de un prestatario y es utilizada por agencias especializadas para informar a inversores y entidades financieras (BME Exchange, s.f.). Para mitigar este riesgo, se aplican estrategias como la diversificación, análisis exhaustivo de crédito, uso de instrumentos de cobertura y monitoreo constante (Pirani Risk, 2022).\n\n2.1.1 Métodos para estimar el riesgo crediticio\nLa estimación del riesgo crediticio ha evolucionado desde enfoques tradicionales basados en reglas heurísticas y la experiencia de expertos, hasta modelos estadísticos y técnicas avanzadas de machine learning. Entre los métodos más utilizados se encuentran:\n\nReglas heurísticas: Basadas en criterios subjetivos y juicio de analistas, como el modelo de las cinco “C” del crédito (Carácter, Capital, Capacidad, Colateral y Ciclo). Su principal ventaja radica en la simplicidad y facilidad de aplicación, especialmente en contextos donde no se dispone de grandes volúmenes de datos o sistemas automatizados. Además, permite incorporar el conocimiento experto y factores difíciles de cuantificar. Sin embargo, su naturaleza subjetiva limita su capacidad para generalizar y adaptarse a cambios en el entorno económico, lo que puede generar inconsistencias entre evaluadores y dificulta su escalabilidad. Este método es común en pequeñas entidades financieras o microfinancieras donde el análisis personalizado es la norma (De Lara Haro, 2004).\nModelos estadísticos tradicionales: La Regresión Logística es uno de los métodos más populares para estimar el riesgo crediticio debido a su capacidad para modelar variables binarias (como incumplimiento o no incumplimiento) y su alta interpretabilidad, lo que facilita la explicación de resultados ante reguladores y gestores (Hosmer & Lemeshow, 2000; ListenData, 2019). El Análisis Discriminante también ha sido empleado en este ámbito, aunque presenta limitaciones cuando el entorno es dinámico o las relaciones entre variables no son lineales (Ince & Aktan, 2009). Estos modelos son ampliamente usados en bancos grandes para scoring crediticio tradicional, pero requieren datos limpios y estructurados, y pueden ser menos efectivos para capturar patrones complejos o interacciones no lineales.\nModelos basados en calificaciones internas y estructurales: Métodos como CreditMetrics, desarrollado por J.P. Morgan en 1997, representan un avance al considerar la migración de calificaciones crediticias y la probabilidad de incumplimiento para estimar el valor en riesgo (VaR) de un portafolio. Estos modelos permiten evaluar la diversificación y concentración del riesgo, incorporando además la correlación entre créditos, lo que es crucial para una gestión integral del riesgo crediticio (Sánchez Cerón, 2001). Su principal fortaleza está en modelar la evolución dinámica del riesgo y en su utilidad para la gestión de portafolios y cumplimiento regulatorio. No obstante, requieren grandes volúmenes de datos históricos y matrices de transición bien calibradas, además de presentar cierta complejidad computacional y la necesidad de actualización constante. Son comúnmente utilizados por grandes instituciones financieras para la gestión avanzada del riesgo y la provisión de capital conforme a normativas internacionales (Peña, 2002; Ruza y Paz-Curbera, 2012).\nTécnicas de machine learning: En los últimos años, las técnicas de aprendizaje automático como Árboles de Decisión, Random Forest, XGBoost y Redes Neuronales Artificiales han ganado protagonismo en la estimación del riesgo crediticio. Estas metodologías destacan por su capacidad para capturar relaciones no lineales y patrones complejos en grandes volúmenes de datos, lo que mejora significativamente la precisión en la predicción del incumplimiento (Zhang, Lipton, Li, & Smola, 2024; Towards Data Science, 2020). Además, permiten automatizar procesos y manejar variables heterogéneas, incluyendo datos no estructurados. Sin embargo, su principal limitación es la menor interpretabilidad respecto a los modelos estadísticos tradicionales, lo que puede dificultar la explicación y aceptación ante organismos reguladores. También requieren recursos computacionales considerables y grandes bases de datos para evitar problemas como el sobreajuste. Estas técnicas son especialmente utilizadas por fintechs y bancos digitales que buscan optimizar la aprobación de créditos mediante modelos predictivos avanzados.\n\nLa selección del método más adecuado para estimar el riesgo crediticio depende del contexto específico, la disponibilidad y calidad de datos, los recursos tecnológicos y las exigencias regulatorias. Mientras que las reglas heurísticas pueden ser útiles en entornos con poca infraestructura tecnológica, los modelos estadísticos y estructurales son preferidos en instituciones con mayor capacidad analítica, y las técnicas de machine learning se posicionan como la vanguardia en escenarios con grandes volúmenes de datos y necesidad de alta precisión."
  },
  {
    "objectID": "posts/Riesgo-crediticio/index.html#redes-neuronales-artificiales-rna",
    "href": "posts/Riesgo-crediticio/index.html#redes-neuronales-artificiales-rna",
    "title": "Modelado de Riesgo Crediticio con Redes Neuronales",
    "section": "2.2 Redes Neuronales Artificiales (RNA)",
    "text": "2.2 Redes Neuronales Artificiales (RNA)\nLas redes neuronales artificiales (RNA) son modelos computacionales inspirados en la estructura y funcionamiento del cerebro humano, compuestos por nodos interconectados llamados neuronas artificiales, organizados en capas (UNIR, 2021; Zhang, Lipton, Li, & Smola, 2024). Cada neurona recibe señales de entrada, las procesa mediante funciones matemáticas y funciones de activación no lineales, y transmite el resultado a las neuronas de la siguiente capa. Este proceso permite que la red aprenda representaciones jerárquicas y patrones complejos en grandes volúmenes de datos, modelando relaciones no lineales entre variables, lo que resulta especialmente útil en tareas de clasificación, predicción y análisis (IBM, 2021; AWS, 2022; Zhang et al., 2024).\n\n2.2.1 Conceptos clave en RNA\nPerceptrón:\nEl perceptrón es la unidad básica de una red neuronal artificial, constituido por un modelo matemático que recibe un vector de entradas, las multiplica por pesos asociados y suma un sesgo o bias. El resultado de esta suma ponderada se pasa por una función de activación para producir una salida (Zhang et al., 2024, cap. 4).\nMatemáticamente, la salida \\(y\\) de una neurona \\(j\\) se expresa como:\n\\(y_j = f\\left( \\sum_i w_{ij} x_i + b_j \\right) \\tag{1}\\)\ndonde \\(x_i\\) son las entradas a la neurona, \\(w_{ij}\\) los pesos asociados a cada entrada, \\(b_j\\) el sesgo (bias) de la neurona, y \\(f\\) la función de activación, que introduce no linealidad necesaria para el aprendizaje. Inicialmente, los pesos (ponderaciones) de la red neuronal se asignan de forma aleatoria, lo que puede generar respuestas erráticas o inconsistentes. A través de un proceso de entrenamiento supervisado, la red ajusta iterativamente estos pesos en función del error entre las predicciones y los resultados reales. Este ciclo de ajuste se repite múltiples veces, permitiendo que la red mejore progresivamente su desempeño hasta alcanzar uno o varios criterios de parada establecidos (IBM, 2021).\nEl perceptrón fue originalmente propuesto como un clasificador binario, siendo eficiente para problemas linealmente separables, y su concepto se ha extendido para formar la base de redes neuronales más profundas y complejas.\nCapas:\nLas redes neuronales artificiales (RNA) están organizadas en tres tipos principales de capas:\n\nCapa de entrada: Recibe los datos originales o iniciales del problema. Esta capa no realiza cálculos, sino que introduce la información en la red.\nCapas ocultas: Son una o varias capas intermedias que procesan y transforman la información recibida. Cada neurona en estas capas calcula una suma ponderada de sus entradas, aplica una función de activación no lineal y transmite el resultado a la siguiente capa. El número y tamaño de estas capas determinan la capacidad de la red para aprender representaciones jerárquicas y patrones complejos.\nCapa de salida: Produce la predicción final, que puede ser una clase, una probabilidad o un valor numérico, según el tipo de problema (clasificación, regresión, etc.).\n\nLa profundidad y arquitectura de la red se seleccionan en función de la complejidad del problema y la cantidad de datos disponibles. La arquitectura define cómo se conectan las neuronas y cómo fluye la información, siendo un aspecto clave para el desempeño del modelo (Zhang et al., 2024; Interactive Chaos, 2023; AWS, 2022; GAMCO, 2023).\nFunciones de activación:\nLas funciones de activación transforman la salida de cada nodo, permitiendo a la red aprender relaciones complejas. La selección de la función de activación es crucial, ya que determina la capacidad del modelo para aproximar funciones no lineales (Zhang et al., 2024, cap. 5).\nExisten funciones de activación lineales y no lineales:\n\nFunción lineal\nSe define como\n\\[ f(x) = x \\]\nSu rango de salida es \\((-\\infty, \\infty)\\). Es simple y mantiene la escala de entrada, por lo que se utiliza principalmente en la capa de salida para problemas de regresión. Sin embargo, no introduce no linealidad, lo que limita la capacidad de aprendizaje cuando se usa en capas ocultas.\nFunción sigmoide\nLa función no lineal sigmoide se define como\n\\[ f(x) = \\frac{1}{1 + e^{-x}} \\]\nSu rango de salida es \\((0, 1)\\). Es suave y produce salidas interpretables como probabilidades, lo que la hace útil para clasificación binaria. Su principal limitación es el problema del gradiente evanescente, que puede ralentizar el aprendizaje en redes profundas, además de saturarse para valores extremos.\nTangente hiperbólica\nLa función no lineal tangente hiperbólica se define como\n\\[ f(x) = \\tanh(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} \\]Su rango es \\((-1, 1)\\). Está centrada en cero, lo que mejora la convergencia respecto a la sigmoide. Sin embargo, también puede sufrir gradiente evanescente y saturación.\nReLU\nLa función no lineal ReLU (Rectified Linear Unit, Unidad lineal rectificada)se define como\n\\[ f(x) = \\max(0, x) \\]Su rango es \\([0, \\infty)\\). Es computacionalmente eficiente y ayuda a evitar el problema del gradiente evanescente positivo, facilitando el entrenamiento de redes profundas. Su limitación principal es el problema de neuronas muertas cuando la entrada es negativa de forma persistente.\nLeaky ReLU\nLa función no lineal Leaky ReLU (Leaky Rectified Linear Unit, ReLU con Fuga), se define como\n\\[\nf(x) = \\begin{cases}\nx & \\text{si } x &gt; 0 \\\\\n\\alpha x & \\text{si } x \\leq 0\n\\end{cases}\n\\]\ncon \\(\\alpha\\) pequeño (por ejemplo, 0.01). Su rango es \\((-\\infty, \\infty)\\). Soluciona el problema de neuronas muertas permitiendo una pequeña pendiente para valores negativos. Sin embargo, la elección de \\(\\alpha\\) es arbitraria y no siempre mejora todos los modelos.\nSoftmax\nPara un vector \\(\\mathbf{x}\\), la función no lineal softmax se define como\n\\[\nf_i(\\mathbf{x}) = \\frac{e^{x_i}}{\\sum_j e^{x_j}} \\quad \\text{para } i=1,...,K\n\\]\nSu rango es \\((0, 1)\\) y suma total 1. Es usada en la capa de salida para clasificación multiclase, convirtiendo vectores en distribuciones de probabilidad. Su limitación es que puede ser costosa computacionalmente para muchas clases.\nELU\nLa función no lineal ELU (Exponential Linear Unit, Unidad Lineal Exponencial) se define como\n\\[\nf(x) = \\begin{cases}\nx & \\text{si } x &gt; 0 \\\\\n\\alpha (e^{x} - 1) & \\text{si } x \\leq 0\n\\end{cases}\n\\]\ncon \\(\\alpha &gt; 0\\). Su rango es \\((-\\alpha, \\infty)\\). Converge rápido, tiene salida centrada cerca de cero y evita neuronas muertas. Su cálculo es más costoso que ReLU y \\(\\alpha\\) no se aprende durante el entrenamiento.\nSELU\nLa función no lineal SELU (Scaled ELU, ELU Escalada) se define como\n\\[\nf(x) = \\lambda \\begin{cases}\nx & \\text{si } x &gt; 0 \\\\\n\\alpha (e^{x} - 1) & \\text{si } x \\leq 0\n\\end{cases}\n\\]\ncon \\(\\alpha \\approx 1.6733\\) y \\(\\lambda \\approx 1.0507\\) . Su rango es \\((-\\lambda \\alpha, \\infty)\\). Facilita la auto-normalización interna, acelerando la convergencia y manteniendo media y varianza. Requiere arquitecturas específicas y es sensible a la inicialización.\nSeno\nLa función no lineal Seno\n\n\\[ f(x) = \\sin(x) \\]Su rango es \\([-1, 1]\\). Es útil para modelar funciones periódicas y patrones complejos, especialmente en señales y series temporales. Su principal limitación es que no es monotónica, lo que puede complicar la optimización.\n\n\nNota: La elección de la función de activación depende del problema y la arquitectura de la red. Por ejemplo, ReLU es la más popular en capas ocultas por su eficiencia y buen desempeño, mientras que sigmoide y softmax se usan comúnmente en la capa de salida para clasificación.\n\n\n2.2.2 RNA en el riesgo crediticio\nEl teorema de aproximación universal establece que una red neuronal con una sola capa oculta y suficientes neuronas puede aproximar cualquier función continua definida en un conjunto compacto, siempre que utilice funciones de activación no lineales (Zhang et al., 2024, cap. 5; Cloudflare, 2023). En la práctica, para problemas complejos como el riesgo crediticio, se emplean arquitecturas más profundas y técnicas modernas de regularización y optimización, lo que permite capturar interacciones sutiles entre variables demográficas, financieras y de comportamiento.\nEn el sector financiero, las RNA han demostrado ser especialmente útiles para la clasificación de clientes según su nivel de riesgo, la predicción de incumplimientos y la asignación de puntajes crediticios personalizados (Towards Data Science, 2020). Sin embargo, su implementación requiere un preprocesamiento cuidadoso y técnicas de explicabilidad para cumplir con normativas y generar confianza en reguladores y usuarios finales.\n\n\n2.2.3 Ejemplo básico en Python\nEste ejemplo crea una red simple para clasificación binaria con una capa oculta para clasificación binaria, que incluye además la generación de un gráfico visual de la red usando torchviz. \n\n\nC:\\Users\\Diego\\AppData\\Local\\Programs\\Python\\PYTHON~1\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:276: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:81.)\n  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n\n\n'simple_nn.png'"
  },
  {
    "objectID": "posts/Riesgo-crediticio/index.html#scorecards-y-explicabilidad",
    "href": "posts/Riesgo-crediticio/index.html#scorecards-y-explicabilidad",
    "title": "Modelado de Riesgo Crediticio con Redes Neuronales",
    "section": "2.3 Scorecards y explicabilidad",
    "text": "2.3 Scorecards y explicabilidad\nPara facilitar la interpretación de los modelos de riesgo crediticio, es común transformar la probabilidad de incumplimiento en un puntaje o scorecard. Este puntaje permite comparar fácilmente el riesgo relativo entre individuos y es ampliamente utilizado en la industria financiera (ListenData, 2019). La conversión a puntaje facilita la toma de decisiones y la comunicación con usuarios y reguladores.\nAdemás, la explicabilidad del modelo es fundamental para cumplir con regulaciones y generar confianza en los usuarios. Por ello, se emplean técnicas como SHAP (SHapley Additive exPlanations), que identifican y cuantifican la influencia de cada variable en la predicción, haciendo los modelos más transparentes y comprensibles.\n\n2.3.1 Fórmula estándar para scorecards\nLa probabilidad estimada de incumplimiento, \\(p\\), se transforma en un puntaje mediante la fórmula estándar de score:\n\\(Score=200+50\\ln\\left(\\frac{⁡1−p}p\\right)\\tag{2}\\)\ndonde \\(p\\) es la probabilidad de incumplimiento predicha por el modelo. Esta fórmula asigna un puntaje que disminuye a medida que aumenta la probabilidad de incumplimiento, facilitando la clasificación y comparación de clientes según su riesgo."
  },
  {
    "objectID": "posts/Riesgo-crediticio/index.html#metodología-a-usar",
    "href": "posts/Riesgo-crediticio/index.html#metodología-a-usar",
    "title": "Modelado de Riesgo Crediticio con Redes Neuronales",
    "section": "2.4 Metodología a usar",
    "text": "2.4 Metodología a usar\nPara abordar el reto del modelado del riesgo crediticio mediante redes neuronales artificiales, se propone una metodología integral que combina técnicas avanzadas de machine learning con buenas prácticas de ingeniería de datos. Este enfoque se estructura en cinco fases clave, que aseguran la calidad del modelo, su robustez y su interpretabilidad.\n1. Análisis exploratorio de datos (EDA)\nAntes de construir el modelo, se realiza un análisis exhaustivo para comprender la estructura y calidad del conjunto de datos:\n\nEvaluación de la distribución de variables, detección y análisis de valores faltantes y outliers.\nIdentificación de correlaciones y relaciones entre variables predictoras y la variable objetivo.\nSelección inicial de variables relevantes, excluyendo aquellas con alto porcentaje de datos faltantes o baja relevancia predictiva.\nVisualización de patrones y balance de clases para guiar el preprocesamiento y modelado.\n\n2. Definición y preprocesamiento de la variable objetivo\n\nLa variable objetivo se define a partir de la columna “loan_status” del dataset, siguiendo la codificación binaria recomendada:\n\n“Fully Paid” y “Does not meet the credit policy. Status:Fully Paid” codificados como 0 (buenos pagadores).\n“Charged Off”, “Default”, “Late (31-120)”, y “Does not meet the credit policy. Status:Charged Off” codificados como 1 (malos pagadores).\nSe excluyen registros con estados “Current”, “Issued”, “In Grace Period”, “Late (16-30)” y otros marcados como NA, por no tener certeza sobre su comportamiento final.\n\n\n3. Preprocesamiento y preparación de datos\n\nTratamiento de valores faltantes:\nImputación múltiple para variables numéricas; estrategias específicas para variables categóricas.\nIngeniería de características:\n\nCodificación WoE (Weight of Evidence) para variables categóricas, facilitando la relación con la variable objetivo y la interpretabilidad.\nEscalado robusto (RobustScaler) para variables numéricas, minimizando el impacto de valores atípicos.\n\nDivisión de datos:\n\nDivisión estratificada 80-10-10 para entrenamiento, validación y prueba, manteniendo la proporción de clases.\nValidación cruzada temporal para series temporales, asegurando que los datos de entrenamiento precedan temporalmente a los de validación y prueba, evitando fugas de información.\n\nAutomatización:\nUso de pipelines para asegurar reproducibilidad y facilitar iteraciones.\n\n4. Construcción y entrenamiento del modelo\n\nDiseño de una arquitectura de red neuronal artificial con capas ocultas suficientes para capturar relaciones no lineales complejas.\nUso de funciones de activación no lineales como ReLU y variantes para mejorar la convergencia y evitar problemas como neuronas muertas.\nOptimización de hiperparámetros mediante técnicas como grid search o búsqueda bayesiana.\nAplicación de técnicas de regularización (dropout, early stopping) para evitar sobreajuste.\nImplementación y comparación con modelos de baja complejidad como árboles de decisión y regresión logística, para validar mejoras y robustez.\n\n5. Evaluación y explicabilidad del modelo\n\nEvaluación con métricas adecuadas para problemas desbalanceados: AUC-ROC, precisión, recall, F1-score.\nValidación cruzada y backtesting para asegurar generalización y estabilidad.\nPruebas de estrés para evaluar resiliencia ante escenarios adversos.\nUso de técnicas de explicabilidad como SHAP para identificar variables que más influyen en la predicción, facilitando la interpretación y cumplimiento normativo.\nTransformación de probabilidades en scorecards mediante fórmulas estándar para facilitar la comunicación práctica del riesgo.\n\nConsideraciones adicionales\n\nEn caso de desbalance significativo, aplicar técnicas como SMOTE o submuestreo para mejorar la detección de casos minoritarios.\nMonitoreo continuo del modelo en producción para detectar degradación y actualizar según sea necesario.\nDocumentación rigurosa y cumplimiento de normas APA en el reporte técnico.\n\nEsta metodología está alineada con las mejores prácticas reportadas en la literatura y la industria para el modelado de riesgo crediticio con redes neuronales (Fernández Castaño, 2007; Grau Álvarez, 2020; FasterCapital, 2025; Eafit, 2021). Su aplicación permitirá construir un modelo robusto, eficiente y transparente para predecir la probabilidad de incumplimiento crediticio."
  }
]